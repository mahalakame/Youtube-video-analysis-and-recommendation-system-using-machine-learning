,Video Title,Video ID,View Count,Duration,Description,Channel Title,Published Date,Trending Until
0,RLAIF  - RL from AI Feedback for Aligning Large Language Models LLMs,RFZvWVQyr2E,45,9:44,"From the authors:
‚Äú
Reinforcement learning from human feedback (RLHF) is effective at aligning large language models (LLMs) to human preferences, but gathering high-quality human preference labels is a key bottleneck. We conduct a head-to-head comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find that they result in similar improvements. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ‚àº70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF.
‚Äú
https://arxiv.org/pdf/2309.00267.pdf
https://huyenchip.com/2023/05/02/rlhf.html 

If you like such content please subscribe to the channel here: 
https://www.youtube.com/c/RitheshSreenivasan?sub_confirmation=1 

If you like to support me financially, It is totally optional and voluntary. Buy me a coffee here: https://www.buymeacoffee.com/rithesh",Rithesh Sreenivasan,2023-09-06T08:10:27Z,2023-09-06T11:45:19Z
1,Unlocking the Power of Large Language Models with Graph of Thoughts: A Game-Changing Framework,7OZhZujxFCo,4,1:55,"The post discusses a paper that introduces a framework called Graph of Thoughts (GoT) which enhances the capabilities of large language models (LLMs) by modeling information as a graph. The authors demonstrate that GoT outperforms existing methods on various tasks and can improve sorting quality while reducing costs. The framework is also extensible and can be used to develop new prompting schemes. A comment provides a link to the code for the paper.

üîó https://arxiv.org/abs/2308.09687

#AI #Language Model",AI Insight News,2023-09-06T07:04:17Z,2023-09-06T11:45:19Z
2,Beyond Right or Wrong: Leveraging Language Models to Enhance the Learning Process | Rose E. Wang,iNCqfvjQpWA,9,51:42,"Recent advances in natural language processing have stirred excitement about large language models (LLMs) used to provide equitable access to high-quality education. Current education paradigms have a strong focus on the product of learning‚Äîe.g., whether the student gets their answer correct. My research challenges those paradigms by leveraging LLMs to focus on the process‚Äîe.g., how are students arriving at their answer? I‚Äôm interested in using LLMs to understand and support both how teachers teach and how students learn.

In this talk, I will focus on understanding and supporting teachers‚Äô remediation process, i.e., how teachers respond to student mistakes. I will discuss one recent submission which explores the potential of LLMs to assist math tutors in remediating student mistakes. Our work presents ReMath, a benchmark co-developed with experienced math teachers, which provides a comprehensive deconstruction of their thought process for effective remediation. This benchmark encompasses three crucial tasks: (1) inferring the type of student error, (2) determining the appropriate strategy and intention to address the error, and (3) generating a response that incorporates this information. We evaluate the performance of state-of-the-art instruct-tuned and dialog models on ReMath. Our findings suggest that although models consistently improve upon original tutor responses, we cannot rely on models alone to remediate mistakes. Providing models with the error type (e.g., the student is guessing) and strategy (e.g., simplify the problem) leads to a 75% improvement in the response quality over models without that information. Nonetheless, despite the improvement, the quality of the best model‚Äôs responses still falls short of experienced math teachers. Our work sheds light on the potential and current limitations of using LLMs to provide high-quality learning experiences for both tutors and students at scale.

This workshop was conducted by Rose Wang, Stanford University


Learn more about WiDS Workshops: widsconference.org/workshops

#stanford #Algorithms #AI #bigdata #algorithmdesign #humanprocesses #python #wids #womenindata",Women in Data Science,2023-09-06T03:33:49Z,2023-09-06T11:45:19Z
3,Running Large Language Models (LLMs) locally and in a browser - mlc.ai or transformers.js,4QokaKepc6k,23,1:37,"Running large language models and transformer models locally in web browsers. Lot's of tools for doing this including mlc.ai, transformers.js, and webgpu.

#largelanguagemodels #rajistics #mlcai #transformersjs #webgpu #browswerai

MLC: https://mlc.ai/mlc-llm/

Backgrond by Andrea De Santis: https://unsplash.com/photos/a-large-group-of-red-and-white-masks-EMvUZHjbxtI
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚òÖ Rajistics Social Media ¬ª 
‚óè Home Page: http://www.rajivshah.com
‚óè LinkedIn: https://www.linkedin.com/in/rajistics/
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ","Rajistics - data science, AI, and machine learning",2023-09-06T00:44:04Z,2023-09-06T11:45:19Z
4,Panel discussion on the Reliability of Large Language Models,cQjG6QHzUxw,39,1:13,,EnCORE,2023-09-05T23:33:38Z,2023-09-06T11:45:19Z
5,03: Prompting and Zero-Shot Inference ‚Äì Large Language Models (NUS CS6101 NUS.WING),MHERkAFzjvE,42,2:32:56,"00:00 Intro
03:00 Projects
18:00 Week 02 Kahoot!
34:45 LECTURE START - What is Prompting? (Esther)
49:25 In Context Learning (Victor)
1:19:20 Zero-Shot, One-Shot and Few-Shot (Richmond)
1:32:00 Chain-of-Thought (Suveen)
1:48:00 Self-Consistency (Lawrence)
2:17:40 ReAct (Warren) 

Slides at http://bit.ly/cs6101-t2310-w03
Scribe Notes at http://bit.ly/cs6101-t2310-w03-scribe
Video at http://bit.ly/cs6101-t2310-w03-yt",Web IR / NLP Group at NUS,2023-09-05T21:37:12Z,2023-09-06T11:45:19Z
6,The Business Impact and Challenges of Using Large Language Models,MuizmSt3RsE,52,37:20,"Summary 
-------
Suhas Pai shares his experience and insights on the business impact of using large language models (LLMs) and the challenges involved in taking prototypes to production. He discusses the impact of LLMs in the business world, the trade-offs in text summarization, challenges in the finance industry, and addresses audience questions. He emphasizes the need for careful consideration of how LLMs can add value to a company's products and services. 

Topics: 
-------
 The Business Impact of LLMs 
  * Success in launching products utilizing GPT-4 
  * Differences between smaller custom models and larger models like GPT-4 
  * Importance of considering how LLMs can add value to a company's products and services 
 Balancing Trade-Offs in Text Summarization 
  * Complexities of text summarization 
  * Trade-offs in achieving effective and accurate summaries 
  * Criteria to consider: relevance, specificity, structure, factuality, coherence, succinctness, and length 
  * Challenges of extracting relevant details while removing redundant information 
  * Need to balance coherence and succinctness 
  * Limitations of language models in addressing trade-offs 
 Challenges and Limitations in the Finance Industry 
  * High threshold of trust in the finance industry 
  * Avoiding hallucinations or mistakes 
  * Difficulties in achieving a balance between different criteria in summarization 
  * Limitations of GPT-4 in domain-specific knowledge and reasoning abilities 
  * Importance of trust and accuracy in the finance industry 
 Q&A and Additional Insights 
  * Interplay between supervised fine-tuning and augmented generation 
  * Importance of evaluating reasoning capabilities in language models 
  * Approaches to address consistency in longer summarizations 
  * Engagement with the foundation model 
  * Challenges of cost and optimization in the summarization process",ML Explained - Aggregate Intellect - AI.SCIENCE,2023-09-05T20:16:01Z,2023-09-06T11:45:19Z
7,"2023-08-31 Using Large Language Models (LLMs) To Write Better Code w/Abigail Haddad, Data Science DC",MoQ9d5PLPDU,4,56:48,"In this session, Benjy Braun, VP of Data Solutions and Innovation, and Abigail Haddad, Lead Data Scientist from Capitol Technology Group will talk about using LLMs to make your code easier to understand and build on. We'll talk briefly about the concept of technical debt, LLMs, and coding with functions rather than procedurally before we take some bad code and improve it with help from LLMs.

To participate, please have the following set up ahead of time:

1. An environment for running notebooks in Python. This can be locally or using an online environment like Google Colab. You will not need a substantial amount of memory.
2. Access to an LLM like GPT-3.5 or GPT-4, Claude 2, or one that you're running locally, like Llama 2 or Code Llama. (The easiest way to get this is to sign up for an account at OpenAI or Anthropic.)

The git repo we'll be using (still in progress) is here: https://github.com/abigailhaddad/gw_talk",GW Coders,2023-09-05T19:07:07Z,2023-09-06T11:45:19Z
8,KDD 2023 - The Large Language Model Revolution: Implications from Chatbots and Tool-use to Reasoning,DHacEPuM4T4,44,1:12:16,"Ed Chi, Google DeepMind

Deep learning is a shock to our field in many ways, yet still many of us were surprised at the incredible performance of Large Language Models (LLMs). LLM uses new deep learning techniques with massively large data sets to understand, predict, summarize, and generate new content. LLMs like ChatGPT and Bard have seen a dramatic increase in their capabilities‚Äîgenerating text that is nearly indistinguishable from human-written text, translating languages with amazing accuracy, and answering your questions in an informative way. This has led to a number of exciting research directions for chatbots, tool-use, and reasoning: 

‚Äì Chatbots: LLM chatbots that are more engaging and informative than traditional chatbots. First, LLMs can understand the context of a conversation better than ever before, allowing them to provide more relevant and helpful responses. Second, LLMs enable more engaging conversations than traditional chatbots, because they can understand the nuances of human language and respond in a more natural way. For example, LLMs can make jokes, ask questions, and provide feedback. Finally, because LLM chatbots can hold conversations on a wide range of topics, they can eventually learn and adapt to the user‚Äôs individual preferences.",Association for Computing Machinery (ACM),2023-09-05T18:00:11Z,2023-09-06T11:45:19Z
9,"Federated learning for empowering large language models (paper_explanation)   Sep 5, 2023",uB3qpmBkYcs,0,7:49,preprint link: https://easychair.org/publications/preprint/LV6c,SOUMIK DEB NILOY,2023-09-05T17:15:02Z,2023-09-06T11:45:19Z
10,CodaMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models,DOuKHfNtT7M,31,21:37,"A recording of my talk on CodaMOSA. The talk contains the same content as the presentation at ICSE'23 in Melbourne, Australia, plus a few extras (the discussion of copied tests + readability of generated tests).

Find the full paper at https://www.carolemieux.com/codamosa_icse23.pdf, DOI: https://doi.org/10.1109/ICSE48619.2023.00085",Caroline Lemieux,2023-09-05T16:00:18Z,2023-09-06T11:45:19Z
11,Harnessing RAG with Open-Source Language Models,tPXwaehj7oQ,666,58:52,"Join us for an informative workshop led by James Briggs, Staff Developer Advocate at Pinecone, and AI Influencer Matthew Berman to explore how to apply AI in practice with open source LLMs and Retrieval Augmented Generation (RAG).

We‚Äôll learn about how (and how not) to implement RAG + open-source LLM pipelines. Covering the different open source LLMs available and their pros and cons. We‚Äôll also talk about context windows, chunking, and advanced retrieval methods.

Take advantage of the opportunity to leverage RAG and Open Source LLMs to advance your AI projects and step towards enhancing your projects with the knowledge that can drive tangible results.",Pinecone,2023-09-05T15:22:17Z,2023-09-06T11:45:19Z
12,Large Language Models Evaluation Metrics,0RM6C680fb4,26,14:56,Colab Notebook : https://colab.research.google.com/gist/Vishesht27/ad3adf653924809125ddd23ef9840bcc/llm_evaluation-metrics.ipynb,Tensordroid,2023-09-05T09:30:00Z,2023-09-06T11:45:19Z
13,GPT Masterclass: 4 Years of Prompt Engineering in 16 Minutes,aq7fnqzeaPc,11562,16:18,"Medium article: https://medium.com/@dave-shap/become-a-gpt-prompt-maestro-943986a93b81
Slide Deck: https://github.com/daveshap/YouTube_Slide_Decks/blob/main/Business%20and%20Product/LLM%20Prompt%20Taxonomy.pdf

Large language models (LLMs) like GPT-4 have shown impressive abilities to generate humanlike text, have conversations, and demonstrate knowledge across many domains. However, there is still confusion around exactly how LLMs work and what capabilities they currently possess. This passage aims to provide a high-level taxonomy of LLM abilities and limitations.

LLMs are deep learning neural networks trained on massive text datasets to predict the next word in a sequence. This allows them to build complex statistical representations of language and accumulate world knowledge from their training data. LLMs have no explicit rules or knowledge - their capabilities emerge from recognizing patterns. 

LLMs excel at reductive operations like summarization, distillation, and extraction which condense large inputs down by identifying salient information. Summarization produces concise overviews of documents. Distillation extracts key facts and principles. Extraction retrieves targeted information like names, dates, or figures.

Transformational techniques like paraphrasing, translation, and restructuring reshape text without losing meaning. Paraphrasing rewrites text with different words/phrasing while preserving meaning. Translation converts between languages. Restructuring improves logical flow and readability. Transformations leverage LLMs' understanding of linguistic conventions and narrative flow.

Generative tasks like drafting, planning, brainstorming, and amplifying synthesize new content from limited input. Drafting can expand prompts into coherent documents. Planning formulates step-by-step strategies to achieve goals based on parameters. Brainstorming produces creative possibilities from prompts. Amplification adds explanatory details to existing text. Generative abilities are more variable but rapidly improving.

Examined through Bloom's Taxonomy, LLMs exhibit skills from basic remembering of facts to highest-level creating original content. Their statistical learning acts as a knowledge repository to query. LLMs also demonstrate strong abilities in understanding concepts, applying knowledge, analyzing passages, and evaluating content. With the right prompting, they can create novel stories, articles, and dialogue.

LLMs have vast latent knowledge not contained in their explicit training. This includes memorized facts, general world knowledge, and learned cognitive skills for tasks like translation. Latent knowledge forms a dense reservoir that requires careful probing with prompts and techniques to extract. While promising, reliance on latent knowledge highlights LLMs' need to better index and activate their own internal knowledge.

Emergent capabilities like theory of mind, implied cognition, logical reasoning, and in-context learning have arisen from recognizing intricate patterns, not hardcoded rules. Theory of mind suggests models can distinguish their own and others' perspectives. Implied cognition points to dynamic reasoning when generating text. Logical reasoning abilities hint at inferring abstract principles from data. Rapid in-context learning demonstrates knowledge acquisition abilities.

Rather than a bug, LLMs' ability to fabricate plausible statements represents a core feature of intelligence. Humans also exhibit a spectrum from creativity to hallucination based on uncontrolled pattern generation. The ideal is not suppressing but responsibly directing generation. Research into alignment and ethics can allow beneficial creativity to flourish while minimizing harms. Maintaining factual grounding and conveying uncertainty are key precautions.

In summary, LLMs have diverse capabilities and limitations requiring continued research. With responsible development focused on augmenting human intelligence, LLMs offer exciting potential while managing risks. Their latent knowledge and emergent properties highlight promising directions to elevate reasoning, creativity, and understanding.",David Shapiro ~ AI,2023-09-05T09:25:29Z,2023-09-06T11:45:19Z
14,"Modeling Language: What You Need to Know | Hugh Seaton, CEO at The Link: The ConTech Crew 372",2A1qPxepd50,14,1:9:49,"üèóÔ∏è Learn more at http://thecontechcrew.com

--
In an industry where architects, engineers, contractors, and various stakeholders must work seamlessly together, miscommunications can lead to costly delays and errors.

Enter Large Language Models (LLMs)--groundbreaking AI technology that is set to transform how construction people collaborate.

In this week‚Äôs episode, my co-host Nathan Wood and I sit down with Hugh Seaton, construction technology enthusiast, book author, and CEO at The Link.

The Link is an AI-powered software dedicated to making construction documents consumable for owners, contractors, and everyone who needs access to these. Prior to starting The Link, Hugh served as a general manager at the Construction Specifications Institute.

Today, Hugh shares invaluable insights on the real power of LLMs, their impact on the construction industry, how to leverage them, and what the future looks like in construction with the rise of AI technology!

Make sure to tune in now. You don‚Äôt want to miss it!


üí°  Key Takeaways:

Introduction (00:00)
What is The Link? (05:03)
Hugh and his The Construction Technology Handbook (07:32)
Is the construction industry ready for AI? (09:38)
The availability and reliability of data (12:12)
Structured vs. semi-structured data and large language models explained (15:28)
How AI technology augments people‚Äôs jobs and not replace them (23:05)
How to manage risks in construction when using AI technology (24:56)
Strategies and competition in construction (28:00)
What the future looks like in construction (38:36)
How to better utilize AI technology in construction (41:55)
Episode wrap-up (45:05)
Construction technology news of the week (46:33)


üìö Additional Resources:

Listen to the show at http://thecontechcrew.com

Follow us on Twitter: https://twitter.com/thecontechcrew

‚Äì

Follow Hugh on LinkedIn: https://www.linkedin.com/in/hughseaton/

Visit The Link website for more: https://www.thelink.ai/

Listen to Hugh‚Äôs podcast: https://constructedfutures.com/

‚Äì

The ConTech Crew is a construction news podcast dedicated to keeping you up to date with all the latest in construction technology.

Give us a follow so you never miss an episode!

#ai #constructiontechnology #llm #Construction #News",The ConTech Crew,2023-09-05T09:00:01Z,2023-09-06T11:45:19Z
15,Introducing Fermyon Serverless AI - Execute inferencing on LLMs with no extra setup,01oOh3D9cVQ,243,2:21,"With Fermyon Serverless AI you can now execute inferencing on Large Language Models (LLMs) for Llama2 and CodeLlama models on state-of-the-art GPUs with no extra setup. Watch this video to learn more and how to get started.

00:00 Welcome
00:10 Generative AI & Large Language Model (LLM)
00:50 Putting LLM functionality in Fermyon's Serverless Framework
01:00 LLM functionality in your source code (alongside HTTP Request & Responses, Key-Value Stores and NoOps Databases)
01:33 Using Fermyon Serverless AI in Fermyon Cloud

AI Inferencing performs well on GPU infrastructure. However, the demand for GPUs is high; GPUs are scarce and expensive. Fermyon Serverless AI has solved this problem by offering 50 millisecond cold start times, over 100x faster than other on-demand AI infrastructure services. Fermyon Serverless AI (which is in private beta) brings a new tool to the full-stack developer‚Äôs toolbox. You can combine Fermyon‚Äôs NoOps SQL Database and Key-Value Storage to quickly build advanced AI-enabled serverless applications.

Sign up for private beta at https://developer.fermyon.com/cloud/serverless-ai

#ai  #llm  #serverless #genai",Fermyon,2023-09-05T09:00:01Z,2023-09-06T11:45:19Z
16,[arXiv 2023] Demo of PointLLM: Empowering Large Language Models to Understand Point Clouds,LHjAVFEzjdY,2,25,"PointLLM: Empowering Large Language Models to Understand Point Clouds
The Demo of PointLLM using Gradio. Try it at http://101.230.144.196. You can chat with PointLLM about the models of the Objaverse dataset or about your own point clouds!",Runsen Xu,2023-09-05T02:41:11Z,2023-09-06T11:45:19Z
17,Unraveling RAG: The Future of AI and Large Language Models,z_2KfFFcSzY,3,3:49,Welcome to our deep dive into the cutting-edge world of Retrieval Augmented Generation (RAG) in Artificial Intelligence! üöÄ,MsOrganicBytes,2023-09-05T02:22:31Z,2023-09-06T11:45:19Z
18,Can an AI Andrew Huberman Help You Crush Your Goals?,9lEh2KtugZM,41,17:28,"Unlock Your Potential with AI - Harness the Power of Large Language Models to Achieve Your Goals

In this video, I demonstrate how to leverage large language models like Anthropic's Claude to help you achieve your goals more efficiently. I show how Claude can summarize lengthy podcasts and videos to extract the key insights quickly.

But it goes beyond just summarizing. I give Claude the transcript of neuroscientist Andrew Huberman's podcast on goal-setting. I then have a conversation with Claude, asking it questions and getting personalized advice about achieving fitness goals - all in Huberman's voice and based on his teachings!

This allows me to get customized guidance and coaching from Claude ""channeling"" Huberman's expertise. I can keep coming back to this AI coach for accountability, motivation and to overcome obstacles on my journey.

Whether your goal is health, career, relationships or more - this technique allows you to harness the knowledge of the world's top experts via AI. Save time consuming content while still extracting the value. Augment your human brain with artificial intelligence.

The future of self-improvement is leveraging AI tools like Claude. Subscribe and stay tuned as I share more ways to use AI to unlock your potential and become the best version of yourself!

Follow me on...

Twitter:  https://twitter.com/andrey_seas
Linkedin:  https://www.linkedin.com/in/andreyseas/
Instagram:  https://www.instagram.com/andreyseasofficial/",Andrey Seas - AI For Personal Development,2023-09-05T02:11:08Z,2023-09-06T11:45:19Z
19,Gorilla Large Language Model Connected with Massive APIs,g4vaAXJeKps,28,53:21,"In Todays Reading Group We Go Over The Gorilla Large Language Model Connected with Massive APIs Paper

Paper Link: https://arxiv.org/abs/2305.15334

Transcript: https://drive.google.com/drive/folders/1BSE1zxT7YJ3M_5zdO-_b4J8BsUEPXWkc?usp=drive_link",AutoGPT,2023-09-04T19:46:39Z,2023-09-06T11:45:19Z
20,Large language models #LLM #artificialintelligence #machinelearning #chatgpt #bard AI,aIygGkCZuLo,24,52,,AIB Insights,2023-09-04T18:25:22Z,2023-09-06T11:45:19Z
21,YaRN: Efficient Context Window Extension of Large Language Models,B07MNiKVIkA,201,27:35,"YaRN is a compute-efficient method to extend the context window of transformer-based language models, allowing them to effectively utilize and extrapolate to longer context lengths. It surpasses previous methods and can extrapolate beyond the limited context of a fine-tuning dataset.

00:00 Section: 1 Introduction
03:25 Section: 1.1 Acknowledgements
06:14 Section: 2.2 Positional Interpolation
08:58 Section: 2.4 Related work
12:52 Section: 3.2 Loss of Relative Local Distances - ""NTK-by-parts"" Interpolation
17:24 Section: 3.3 Dynamic Scaling - ""Dynamic NTK"" Interpolation
21:49 Section: 3.5 Extrapolation and Transfer Learning
25:01 Section: 4.2.1 Long Sequence Language Modeling

https://arxiv.org/abs//2309.00071

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-09-04T15:42:59Z,2023-09-06T11:45:19Z
22,AI Hallucinations: The Unseen Side of Large Language Models | AI News,_mAHoWFYRXI,3,4:,"ü§ñ AI Hallucinations: The Unsettling Reality of AI Mistakes ü§ñ

Dive deep into the world of Large Language Models (LLMs) and their tendency to ""hallucinate"" or produce false information. From innocent mistakes to potentially harmful misinformation, how do we navigate the challenges posed by these AI systems?

üîç In this video:

- Real-life incidents where AI's hallucinations have caused distress.
- Insights from experts like Oliver Devane and Sebastian Berns on why LLMs like OpenAI‚Äôs ChatGPT produce inaccuracies.
- Techniques like Reinforcement Learning from Human Feedback (RLHF) that aim to reduce hallucinations.
- The debate on whether hallucinations can be fully eliminated or if they might have creative applications.
- A comparison of AI's imperfections with human errors and the standards we set for them.

As AI continues to evolve, understanding its limitations and potential risks is crucial. Join us as we explore the phenomenon of AI hallucinations and the ongoing efforts to address them.

üëç If you're interested in the intricacies of AI and its impact on our world, make sure to like, share, and subscribe for more in-depth discussions!

#AIHallucinations #OpenAI #LLMs",MatrixMention,2023-09-04T15:15:55Z,2023-09-06T11:45:19Z
23,Can Large Language Models be used in Science?,TGM94QSfiXM,67,1:1:38,"Presented by Prof. Giovanni De Gasperis, University of L'Aquila, Italy; chaired by Chiara Puri, University of L'Aquila, Italy

Large language models, such as GPT-3, originally developed for natural language processing, can be effectively employed in diverse scientific fields beyond human language. This seminar explores the applications of large language models in non-linguistic scientific domains. By analyzing vast amounts of scientific literature, these models can aid in scientific research, assisting with literature reviews, trend identification, and hypothesis generation. Moreover, they can be trained to analyze complex datasets, enabling data-driven decision-making and pattern recognition in various scientific disciplines. In the field of drug discovery, language models can assist in virtual screening and drug-target interaction optimization. They can also contribute to computational biology tasks, including protein folding prediction and genomics research. Additionally, these models can be applied to climate modeling, aiding weather prediction and climate change projections. However, it is crucial to emphasize that large language models should be used in conjunction with domain expertise, as they are not domain-specific experts. Adapting and fine-tuning these models for specific scientific tasks remains an ongoing area of research.

Instagram: https://www.instagram.com/thursdaymorningscienceunivaq/
Facebook: https://www.facebook.com/tms.thursdaymorningscience.1/
Linkedin: https://it.linkedin.com/in/thursday-morning-science-1a929a201
Twitter: https://twitter.com/ThursdayMornin8",Thursday morning Science,2023-09-04T13:23:05Z,2023-09-06T11:45:19Z
24,What are Large Language Models LLMs and how can I use them ?,2GUUmXHn1iU,2,4:57,"Let's explain the concepts behind Large Language Models (LLMs) and how to use them.
Illustrate using the example of ChatGPT.",Explain how to Access AI and get started using it,2023-09-04T07:21:31Z,2023-09-06T11:45:19Z
25,What Is Prompt Engineering in Software Testing?,GF1VhQxQzOc,1304,18:16,"What is Prompt Engineering? What is Prompt Engineering in Software Testing? Maybe you have asked yourself this questions already or you have heard about the term prompt engineering in combination with large language models such as GPT, bard or DALL-E.

In this video I am going to explain what prompt engineering is. Furthermore, I am going to share information with you, why prompt engineering in software testing is a complex and challenging task.

At the end of the video I am going to show you in a real life example of testRigor, how prompt engineering can be used to train a testing LLM product to get better results.

Thanks to testRigor, for being a sponsor of this video üôèüèª.

üîó Links:
üëâ https://testrigor.com
üëâ https://testrigor.com/features/
üëâ https://testrigor.com/docs/language/
üëâ https://testrigor.com/sign-up/
üëâ https://www.promptingguide.ai/ 


üìö My Book

üëâ https://leanpub.com/Mobileapptesting
üëâ https://www.amazon.com/dp/B0B2GMLVHY/

üë®üèΩ‚Äçüíª Online course

üßëüèº‚Äçüè´ A Beginners Guide To Mobile Testing: https://www.ministryoftesting.com/dojo/courses/beginner-s-guide-to-mobile-testing-daniel-knott by Daniel Knott 

My equipment:

üì∏ Hardware:

üîó * iPhone 12: https://amzn.to/3CVbRIZ
üîó * MacBook Pro: https://amzn.to/3CSSZdy
üîó * Green box background: https://amzn.to/3XDEEtl
üîó * Microphone: https://amzn.to/3XDEp1p
üîó * LED Ring Light: https://amzn.to/3WdjgtX

üíø Software:

üîó Camtasia https://www.techsmith.com/store/camtasia

The links marked with * are affiliate links that belong to the Amazon affiliate program. If you buy something through these links, I get a commission, of course without you having to pay more.

#softwaretesting #AIinTesting #GenerativeAI #testrigor #openAI #AI #gpt #chatGPT, #bard #dalle",Software Testing by Daniel Knott,2023-09-04T06:56:13Z,2023-09-06T11:45:19Z
26,LLMs Are Not Chatbots: 8 Ways LLM is Different From Chatbot,eqTKoadBeK0,35,16:53,"LLMs and the Chatbots solves different problems. Chatbots automate a process, while LLMS generate the next word from a given prompt. Whats important to note is LLMs cannot be effectively used for automating a process. 
The video dives into the workings of chatbot and llm. Explains the challenges and benefits of each technology. This video is the first in the series of videos which explains the design and development of the chatbots. 
 
I believe you will like this video, and subscribe to the channel. Further uploads related to Big Data, Large Language models and Artificial Intelligence will be shared to your Youtube Dashboard Directly.

The supporting playlists are 
The bard Project
https://www.youtube.com/playlist?list=PLbzjzOKeYPCoHRX30whyu0Re-YfOsJZlt
Practical Projects Playlist
https://www.youtube.com/playlist?list=PLbzjzOKeYPCpr8v5GpUwb_dq6BHgPRoui
Huggingface Playlist
https://youtube.com/playlist?list=PLbzjzOKeYPCpVfe6Up7ga3kDVwRDlEw6k
Python Data Engineering Playlist
https://www.youtube.com/playlist?list=PLbzjzOKeYPCo_hMXIl2URu7GL33-4_Yy0
Python Ecosystem of Libraries
https://www.youtube.com/playlist?list=PLbzjzOKeYPCoNAsZs679iXwsdP44G5SDS
ChatGPT and AI Playlist
https://www.youtube.com/playlist?list=PLbzjzOKeYPCpp3NCeQioevM0YpZa5VqcS
AWS and Python AWS Wrangler
https://www.youtube.com/playlist?list=PLbzjzOKeYPCogrhYDBgRNJDPV2CCwGrFT
Exploring the Realm of Generative AI: Hardware and Software Discussions
https://www.youtube.com/playlist?list=PLbzjzOKeYPColJzdASbvDq3_XUB_QM3MQ

PS: Got a question or have a feedback on my content. Get in touch 
By leaving a Comment in the video
topmate.io/insightbuilder?utm_source=topmate&utm_medium=popup&utm_campaign=SocialProfile
@mail insighthacker21@gmail.com
@twitter Handle is @KQrios
@medium https://medium.com/@kamaljp/about
@github https://github.com/Kamalabot",Kamalraj M M,2023-09-04T05:39:41Z,2023-09-06T11:45:19Z
27,ART Automatic multi step reasoning and tool use for large language models Meta 2023,W6p0kgNnI9c,17,45:39,ART Automatic multi-step reasoning and tool-use for large language models (Meta 2023),mardin mardin,2023-09-04T03:13:27Z,2023-09-06T11:45:19Z
28,Unlocking the Future: A deep dive in Large Language Models,5fi9kP4LxHs,6,4:32,"Bart, GPT-4, LlaMA, Claude LLMs. What are they and what are they used for? Which one should you use and for what tasks? Are there any differences?",EVO AI,2023-09-04T03:07:34Z,2023-09-06T11:45:19Z
29,What is large languaging models in prompt engineering ? #chatgpt #prompt #ai #ml,6jD6ULc8Ito,330,23,,Do you know ??,2023-09-04T02:30:02Z,2023-09-06T11:45:19Z
30,Fine Tuning Large Language models,YO5qzwvyV6Q,277,1:25:6,"LLM Bootcamp: Zero to Hero in LLMs

Module - 8: Fine Tuning Large Language Models by Abhishek Mishra, Tech Lead and AI Consultant at Intel",AI Planet,2023-09-04T01:33:16Z,2023-09-06T11:45:19Z
31,How to Build Large Language Models #aimodels #largelanguagemodels,NeYtwbhW3ME,33,16,"Stages of building #aimodels #llms:
1. Determine use case
2. Fine-tune for product
3. Address input- and output-level risks
4. Build transparency and reporting mechanisms in user interactions

üé• Subscribe to my YouTube channel https://www.youtube.com/@aistudiospodcast  
üíå Sign up for my free newsletter! https://aistudios.substack.com/
üê¶ Follow me on Twitter https://twitter.com/Nale
üë• Connect with me on LinkedIn https://www.linkedin.com/in/nataliaburina/",Natalia Burina,2023-09-04T01:04:45Z,2023-09-06T11:45:19Z
32,Potential Downsides To Outsourcing Language Models and Open Source - KNN #165,zDOYQlnp4wo,11,2:35,"Full Episode: https://youtu.be/r1DyYttS8QE?si=suv7AjgXpaxwW0HC

Listen to Ken's Nearest Neighbors on all the main podcast platforms! 
On YouTube: https://www.youtube.com/channel/UCpEJMMRoTIHJ8vG8q_EwqCg 
On Apple Podcasts: https://podcasts.apple.com/us/podcast/kens-nearest-neighbors/id1538368692 (Please rate if you enjoy it!)
On Spotify: https://open.spotify.com/show/7fJsuxiZl4TS1hqPUmDFbl
On Google: https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5idXp6c3Byb3V0LmNvbS8xNDMwMDQxLnJzcw?sa=X&ved=0CAMQ4aUDahcKEwjQ2bGBhfbsAhUAAAAAHQAAAAAQAQ

If you would like to support the Podcast -  Sponsors, Affiliates, and Partners:
- 365 Data Science (57% discount) - https://365datascience.pxf.io/P0jbBY | Learn data science today
- Interview Query (10% discount) - https://www.interviewquery.com/?ref=kenjee |  Interview prep questions
- Pathrise - http://pathrise.com/KenJee | Career mentorship for job applicants (Free till you land a job)
- Taro - http://jointaro.com/r/kenj308 (20% discount) | Career mentorship if you already have a job 


*I use affiliate links on the products that I recommend. These give me a small portion of the sales price at no cost to you. I appreciate the proceeds and they help me to improve my channel!",KNN Clips,2023-09-03T22:36:34Z,2023-09-06T11:45:19Z
33,E33: Transforming words into wonders - Large Language Models,aBeP4LkFiw4,0,14:14,"In this episode, we dive deep into the extraordinary world of large language models (LLMs). From understanding natural language processing to exploring the groundbreaking capabilities of LLMs, we uncover the secrets behind these powerful tech marvels. Join us as we unravel the intricate neural network architectures and mechanisms that enable LLMs to process vast volumes of text and generate remarkably accurate predictions. Discover how LLMs like GPT-4 and BERT revolutionize text generation, completion, sentiment analysis, and more. We explore real-world applications, from customer service to text editing and translation, and delve into the fascinating techniques of in-context learning and prompt programming. As we wrap up, we ignite your motivation, reminding you that every person, regardless of coding expertise, can leverage the power of language to create incredible things. Tune in and get ready to unlock a world of possibilities with LLMs.",WGMI,2023-09-03T17:24:38Z,2023-09-06T11:45:19Z
34,Reinforced Self-Training (ReST) for Language Modeling (Paper Explained),V4dO2pyYGgs,15876,53:7,"#ai #rlhf #llm 

ReST uses a bootsrap-like method to produce its own extended dataset and trains on ever higher-quality subsets of it to improve its own reward. The method allows for re-using the same generated data multiple times and thus has an efficiency advantage with respect to Online RL techniques like PPO.

Paper: https://arxiv.org/abs/2308.08998

Abstract:
Reinforcement learning from human feedback (RLHF) can improve the quality of large language model's (LLM) outputs by aligning them with human preferences. We propose a simple algorithm for aligning LLMs with human preferences inspired by growing batch reinforcement learning (RL), which we call Reinforced Self-Training (ReST). Given an initial LLM policy, ReST produces a dataset by generating samples from the policy, which are then used to improve the LLM policy using offline RL algorithms. ReST is more efficient than typical online RLHF methods because the training dataset is produced offline, which allows data reuse. While ReST is a general approach applicable to all generative learning settings, we focus on its application to machine translation. Our results show that ReST can substantially improve translation quality, as measured by automated metrics and human evaluation on machine translation benchmarks in a compute and sample-efficient manner.

Authors: Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas

Links:
Homepage: https://ykilcher.com
Merch: https://ykilcher.com/merch
YouTube: https://www.youtube.com/c/yannickilcher
Twitter: https://twitter.com/ykilcher
Discord: https://ykilcher.com/discord
LinkedIn: https://www.linkedin.com/in/ykilcher

If you want to support me, the best thing to do is to share out the content :)

If you want to support me financially (completely optional and voluntary, but a lot of people have asked for this):
SubscribeStar: https://www.subscribestar.com/yannickilcher
Patreon: https://www.patreon.com/yannickilcher
Bitcoin (BTC): bc1q49lsw3q325tr58ygf8sudx2dqfguclvngvy2cq
Ethereum (ETH): 0x7ad3513E3B8f66799f507Aa7874b1B0eBC7F85e2
Litecoin (LTC): LQW2TRyKYetVC8WjFkhpPhtpbDM4Vw7r9m
Monero (XMR): 4ACL8AGrEo5hAir8A9CeVrW8pEauWvnp1WnSDZxW7tziCDLhZAGsgzhRQABDnFy8yuM9fWJDviJPHKRjV4FWt19CJZN9D4n",Yannic Kilcher,2023-09-03T12:06:46Z,2023-09-06T11:45:19Z
35,"Ultimate LLM models Showdown! Bard, Llama 2, ChatGPT &amp; Claude AI writes Python Pandas code.",mdEMgRfl3Sk,81,3:58,"In this video, we ask the same question to 4 large language models, Bard, Llama 2, ChatGPT & Claude AI and compare there responses.",The Data Corner,2023-09-03T09:52:28Z,2023-09-06T11:45:19Z
36,Experience the Power of GPT-3 Playground: An AI Playground for Language Models,J2V-kzA4Qe8,15,43,"Step into the future of AI with GPT-3 Playground, the ultimate AI playground where you can unleash your creativity and experiment with cutting-edge language models. Powered by OpenAI's GPT-3, one of the most advanced language models in the world, GPT-3 Playground allows you to generate text, translate languages, write creatively, and get informative answers to your questions. Dive into the world of large language models and explore the endless possibilities. Discover GPT-3 Playground today and embark on an AI-powered journey

Check out the Tool Nowüëá
üîó  https://platform.openai.com/playground
üìà To grow your business with AI Technology, catch us on
üåê https://buildyourai.consulting/

#AIPlayground #GPT3Playground #LanguageModels #OpenAI #TextGeneration #LanguageTranslation #CreativeWriting #InformativeAnswers #FutureOfAI #YouTubeShorts #SJInnovationLLC #SJI #BuildyourAi #CraftedEmail #SoftwareDevelopmentAgency #Youtube #Shorts #Viral #ViralVideos #TrendingShorts #Trending #UnitedStates #US",BuildYourAI,2023-09-02T23:30:06Z,2023-09-06T11:45:19Z
37,"DB-GPT: The All-In-One Model! Chat Privately With FIles Locally, Plugins, Auto Ai Agents, &amp; More!",KYs4nTDzEhk,5422,12:36,"In this video, we delve into the revolutionary DB-GPT project, your ultimate solution for robust data security and privacy in the age of intelligent large models. As we witness the incredible evolution of these models, it's crucial to address the heightened risks to data privacy and security. Join us as we explore how DB-GPT empowers you to maintain absolute control over sensitive data and environments, while eliminating any potential leaks or security vulnerabilities.

üî• Become a Patron (Private Discord): https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 
Business Inquires: intheworldzofai@gmail.com

[MUST WATCH]:
RAGstack: How to Chat With PDF, TXT, and CSV Files Privately on a Virtual Cloud! - https://youtu.be/QsQbXtiqWiI?si=7CylH1vjLy6TT23a
Abacus.Ai: Build Autonomous Ai Agents and Host LLM Apps At Scale!- https://youtu.be/nM6uQm3KApE?si=UnwddP063fuBQNK2 
DocsGPT: Chat With Multiple PDFs, TxT, Rst, Md, & Zip Files Locally For FREE With ONE CLICK! - https://youtu.be/7az-Xk96QZY?si=kGi-nii23NHr3CWg

[Links Used]:
DB-GPT Githug Repo: https://github.com/eosphoros-ai/DB-GPT#installation 
DB-GPT Doc: https://db-gpt.readthedocs.io/en/latest/getting_started/install/deploy/deploy.html
Mini Conda Download: https://docs.conda.io/projects/miniconda/en/latest/
Python Download: https://www.python.org/downloads/
Git Download: https://git-scm.com/downloads

Discover how DB-GPT, an experimental open-source initiative, leverages localized GPT models to ensure your data remains 100% private and secure. We highlight the following key aspects:

1. Private Domain with Question Answering and Data Processing: Tailored for specific domains and tasks, enhancing utility.
2. Faster Processing: Experience improved processing speed for more efficient model interactions.
3. Chat with Multiple Ranges of Files: Interact seamlessly with various file types and formats, ideal for data-centric applications.
4. Better User Interface (UI): Enjoy a user-friendly interface for accessibility and ease of use.
5. Compatibility with Other Language Models (LLMs): Expand versatility by integrating with different language models.

If you're passionate about data security and privacy, don't forget to like this video, subscribe to our channel for more insightful content, and share this video with your network. Together, we can champion data privacy in an increasingly digital world.

Additional Tags and Keywords:
DB-GPT, Data Security, Data Privacy, Large Language Models, Innovative Solutions, Privacy Protection, Secure Data Handling, Data Leakage Prevention, Future of Data Security, Open-Source Initiative, Data Privacy Solutions.
Hashtags:
#DBGPT #DataSecurity #PrivacyProtection #Innovation #DataPrivacySolutions #OpenSource #SecureDataHandling",WorldofAI,2023-09-02T21:46:04Z,2023-09-06T11:45:19Z
38,"Exploring the Pros and Cons of Large Language Models (LLMs) - Generative AI, ChatGPT Podcast",2RAoZyoYycM,97,5:38,"Exploring the Pros and Cons of Large Language Models (LLMs) - Generative AI, ChatGPT Podcast",futureXskills,2023-09-02T17:48:27Z,2023-09-06T11:45:19Z
39,Large Language Models and the Future of Programming by Peter Norvig,ia6aJIplmtc,1604,53:15,"We're thrilled to begin our event with a keynote by the esteemed Peter Norvig, a driving force at the intersection of AI-driven search, software development, and online education.

About Peter Norvig:
Peter is a Distinguished Education Fellow at Stanford's Human-Centered Artificial Intelligence Institute and a Google researcher. His vast experience ranges from heading Google's core search algorithms group to teaching AI to over 160,000 online students. [Read more](http://www.norvig.com/).

#machinelearning #ai #llm #generativeai #agi #Google #GoogleAi #GoogleBrain #Deepmind",Google Developer Communities North America,2023-09-01T22:51:04Z,2023-09-06T11:45:19Z
40,Abacus.Ai: Build Autonomous Ai Agents and Host LLM Apps At Scale!,nM6uQm3KApE,2942,10:31,"Welcome to our channel! In this video, we dive deep into the world of Abacus.AI's AI Agents, a game-changer in the realm of specialized enterprise applications powered by Large Language Models (LLMs). If you're ready to revolutionize your approach to AI-driven solutions, you're in the right place. Let's explore how Abacus.AI's AI Agents can transform your business.

üî• Become a Patron (Private Discord): https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 
Business Inquires: intheworldzofai@gmail.com

[Must Watch]:
SuperAgent: Better Version Than SuperAGI? Build, deploy, and Manage LLM-Powered Agents - https://youtu.be/D9JXvqKCMf0?si=NlZv3cs576a3w-3Z
SuperAGI: Deploy GODLY Autonomous Ai Agents Better Than AutoGPT (Installation Tutorial) - https://youtu.be/PDz6aHdvXlQ?si=lplVhHGLJB_8uRX-
ChatGPT Code Interpreter For FREE! - Open Interpreter (Installation Guide) - https://youtu.be/4OhuFjPyZNQ?si=kRKa1rx3JTB2SFV7

[Links Used]:
Abacus.Ai Seminar: https://www.eventbrite.com/e/ai-agents-build-powerful-ai-agents-in-2-hours-using-our-llmops-platform-tickets-704906162307?aff=erelexpmlt
Blog Post: https://blog.abacus.ai/blog/2023/08/31/supercharge-productivity-accomplish-10x-more-with-ai-agents/
Abacus Ai Agents Website: https://abacus.ai/ai_agents

üîç Unleashing AI Excellence: Abacus.AI's AI Agents are purpose-built to excel in specific tasks, from crafting custom chatbots to generating content, translating code, and extracting invaluable data insights. We'll show you how this platform can streamline your projects, saving you time and resources.

üöÄ Remarkable Speed: Discover the standout feature that sets Abacus.AI apart - lightning-fast AI agent development. Learn how developers can create applications in mere minutes, reducing development cycles and increasing agility.

üõ†Ô∏è Customization at Its Best: Abacus.AI provides extensive customization options, empowering you with support for custom data transformers, vector stores, and user-code modules. Fine-tune your AI agent's behavior like never before.

ü§ñ Advanced LLMs: Explore how you can harness advanced LLMs, including GPT-4, to supercharge your AI agents. Whether out-of-the-box or fine-tuned by Abacus, these models bring unparalleled natural language understanding and generation capabilities to your projects.

üîó Seamless Module Chaining: Dive into the world of seamless module chaining. Discover how you can combine various data processing components, user-specific code, and LLM-based modules to create intricate AI workflows. Efficiency and complexity, all in one.

üåê Scalability & Monitoring: Learn how to swiftly deploy your AI agents into production, ensuring they're ready to scale with your business. Monitoring tools allow for performance tracking, enabling continual refinement and optimization.

Empower Your Data Science Team
Abacus.AI's AI Agents empower data science teams to unlock insights from internal knowledge bases and data. Facilitate rapid data-driven decision-making, transforming your organization's efficiency and productivity across diverse domains.

If you found this video insightful, don't forget to give it a thumbs up, subscribe to our channel for more cutting-edge insights, and share it with your network. Your support keeps us going!

Additional Tags and Keywords
Abacus.AI AI Agents
Enterprise AI Solutions
AI Agent Development
GPT-4 Integration
Custom AI Workflows
Data Insights Automation
Data-Driven Decision Making
Abacus.AI Platform
Enterprise Productivity
Hashtags
#AI #AbacusAI #EnterpriseSolutions #DataScience #AIDevelopment #TechInnovation",WorldofAI,2023-09-01T19:40:30Z,2023-09-06T11:45:19Z
41,How Does AI &quot;Think&quot;? The Science Behind Large Language Models,Xs5RzRXE5lo,189,1:1:7,"Embark on a captivating exploration of the intricate world of neurology and artificial intelligence in this enlightening episode of the Ramos Law Difference Makers Podcast, featuring Dr. Don Cooper, Director of Medical Sciences at Ramos Law. Dr. Cooper takes center stage to unravel the complexities of the ""brain"" driving artificial intelligence and the fascinating connection between cutting-edge AI models and the intricacies of human thought.

Dr. Jim Hoven and Dr. Cooper delve into the dynamic landscape of AI's potential and challenges, exploring the remarkable parallels between these models and the human brain and uncovering the inner workings of AI's goal-driven mechanisms, revealing how these models are shaped by rewards and objectives.

Throughout the episode, Dr. Cooper provides invaluable insights into the future of AI and neuroscience, offering glimpses into the boundless possibilities that lie ahead. This conversation offers a unique blend of medical expertise and technological exploration, highlighting the synergies between these fields and their potential to shape the future.

Learn more about Dr. Cooper and Ramos Law's Medical Sciences Division ‚¨áÔ∏è
https://www.ramoslaw.com/medical-sciences/



Ramos Law - Personal Injury Law Firm located in Colorado and Arizona.

If you've been injured in an auto accident, slip and fall, injury at work, or other, contact us today for a free consultation. No fees unless we win.

üìû Colorado: (720) 764-6865
üìû Arizona: (602) 878-7545

üîó For more info: www.RamosLaw.com

üîî Turn on notifications to never miss a new upload!

üì± Follow Ramos Law:
Instagram: https://www.instagram.com/ramoslawfirm/
TikTok: https://www.tiktok.com/ramoslaw 
Facebook: https://www.facebook.com/RamosInjuryFirm
Twitter: https://twitter.com/TheRamosLawFirm",Ramos Law,2023-09-01T16:00:25Z,2023-09-06T11:45:19Z
42,Belajar ChatGPT - Large Language Model | Prompt Engineering #2,29Y9hP9ZpE0,25,3:57,"Selamat datang di saluran saya! Pada video ini, kami akan merinci secara lengkap tentang ChatGPT LLM, membahas segala hal mulai dari cara kerja dasar hingga pembuatan modelnya. Kami juga akan mengatasi beberapa kesalahan umum yang bisa terjadi dalam penggunaan ChatGPT dan memberikan solusi yang berguna.

00:00 Pembukaan
00:15 Apa Itu LLM ?
00:42 Contoh
01:18 Penyebab Salah
02:31 Solusi
03:20 Kesimpulan

Jika Anda tertarik dengan kecerdasan buatan dan teknologi terkini, pastikan untuk menonton video ini hingga akhir. Jangan lupa berlangganan saluran kami untuk pembaruan lebih lanjut tentang topik ini dan topik AI lainnya!

#ChatGPT #AI #KecerdasanBuatan #PembuatanModel #Teknologi #Solusi",KECERDASAN BUATAN,2023-09-01T15:45:36Z,2023-09-06T11:45:19Z
43,"What Do Large Language Models Know About Language? | Prof Ga≈°per Begu≈°, UC Berkeley",8eAcWPBiA1w,380,13:57,"How Much Do Large Language Models Know About Language Formalism?

--
This work is an excerpt, edited for exposition and brevity in line with the title and description above. It was created  for educational purposes Only under the FAIR USE Doctrine. 

Follow the link Below for the original source, which covers a broader perspective.

----
Source and Credits:
https://www.youtube.com/watch?v=c_UqS54ZA5o",Tech Stories 101,2023-09-01T12:02:49Z,2023-09-06T11:45:19Z
44,Explained: The OWASP Top 10 for Large Language Model Applications,cYuesqIKf9A,6963,14:22,"OWASP Top 10 for Large Language Model Applications ‚Üí https://ibm.biz/BdMzY4

AI for cybersecurity ‚Üí https://ibm.biz/BdMzYR

Large Language Models (LLMs), like any new technology, are subject to the risk that ""malicious actors"" will abuse it for financial or other gain by attempting to circumvent built-in security measures. The well-known Open Worldwide Application Security Project or OWASP project has recently published their list of top 10 security risks for LLMs. In this video, IBM Distinguished Engineer Jeff Crume explains a subset of them and what you can do to protect you and your users.

Get started for free on IBM Cloud ‚Üí https://ibm.biz/buildonibmcloud

Subscribe to see more videos like this in the future ‚Üí http://ibm.biz/subscribe-now

0:00 What is the OWASP Top 10 for LLMs?
1:25 Prompt Injection (Direct)
3:37 Prompt Injection (Indirect)
6:43 Insecure Output Handling
8:55 Training Data
11:46 Over Reliance",IBM Technology,2023-09-01T11:00:26Z,2023-09-06T11:45:19Z
45,Language Models for Materials Science Ontology Assessment (EUROMAT2023),SVSTrcipwm0,145,4:20,"Utilising Large Language Models for Ontology Evaluation in the Field of Materials Science Engineering
Authors: Mirza Mohtashim Alam, Ebrahim Norouzi, J√∂rg Waitelonis, Heike Fliegl and Harald Sack
EUROMAT 2023 

Abstract: 
For Material Science and Engineering (MSE) Machine Learning can be applied for i.e, Material Discovery Design, Property Prediction, Microstructure Analysis etc. Ontologies are considered vital tools for MSE. In ontology design the competency questions (CQs) are one important step to extract knowledge from domain experts to be formalised within the developed ontology. CQs are essential for the ontology evaluation process, because they are addressed using the knowledge embedded within the ontology. Here the power of large language models (LLMs) can be leveraged. LLMs can help material scientists to extract answers to their CQs directly from Knowledge Graphs (KG) without necessarily mastering sophisticated query languages.  Here, we use a very recently developed MSE specific KG, the NFDI-MatWerk-KG as well as the MatWerk Demonstrator and MatWerk Ontology (MWO) and NFDI-Core Ontology, which serve as the context for the LLM. The objective is to respond to competency questions, which have been developed for the MatWerk-KG.  Typically,  these questions are converted into SPARQL queries to check if they're created ontology and the accompanying KG filled with relevant data meets the initial requirements.  Our goal is to obtain answers for the CQs from the KG  using LLMs in an automated manner. This is a challenging task due to the underlying complexities of translating natural language queries into structured data requests as we show in our work. One of the main challenges is to come up with a proper evaluation process regarding the performance of LLMs against manually crafted SPARQL queries for the CQs due to the fact of having various types of CQs and the nature of LLMs.",ISE FIZ Karlsruhe,2023-09-01T09:44:00Z,2023-09-06T11:45:19Z
46,Applications of Large Language Models using Azure OpenAI,Ubadr9NM3sA,8,10:30,Applications of Large Language Models using Azure OpenAI,Saumya Soni,2023-09-01T07:42:10Z,2023-09-06T11:45:19Z
47,Meta&#39;s Open-Source Llama2 AI Challenges ChatGPT,Z30NVwN9H4g,225,10:38,"Get the scoop on Meta's new Llama2 AI in this video and how it compares to Chat GPT, Google Bard, and more! We dive into what this open source large language model can and can't do, including its strengths in conversational AI. Find out why Meta released it, the catch with the ""free"" commercial license, and their responsible AI approach. üß† Does Llama2 live up to the hype or is it an AI imposter? ü§î
Let us know your thoughts in the comments. Smash that like button if you want more videos exploring the latest in artificial intelligence! üëç

‚åöTimeline
0:00 ‚Äì Introduction
0:22 ‚Äì What is Large Language Model?
1:01 ‚Äì Llama2
4:48 ‚Äì Release Paper
7:58 ‚Äì Comparison?
9:45 ‚Äì Final Thoughts

üîóLinks
Perplexity Labs - https://labs.perplexity.ai/
About Llama 2 - https://ai.meta.com/llama/
Research Paper - https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/
Mark Zuckerberg Interview - https://youtu.be/6PDk-_uhUt8?si=OgGg-BtyomBU5jnZ
Download Models - https://huggingface.co/models?other=llama-2
Music By, Tim Taj ‚Äì https://pixabay.com/music/corporate-technology-8850/

#Llama2 #ChatGPT #GoogleBardAI #Claude2 #BingAI #Metaverse #MetaAI #Meta #AI #artificialintelligence #virtualassistant #conversationalai #Kenya #USA #UK #Nigeria #Africa #India",JW Tech Bytes,2023-09-01T07:30:11Z,2023-09-06T11:45:19Z
48,Large Language Models for Beginners | Exploring LLMs üöÄ,GI6yjUdlN30,12,16:53,"Hello, My name is Vikash and I create Data Science/Analytics based tutorial/videos that can help you in your learning or preparation for a career in analytics. Incase you're new to the channel then please consider pressing the subscribe button to support my work and drop a like for the videos that I create ( these will be free for you but will be really encouraging for me :-) )




1. Mentorship For Data Science

I got 3jobs in 1yearü§©
Click here: https://www.youtube.com/watch?v=pdBammFAwKs&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=1&pp=iAQB


Best practices for Data Science prepüíµüëç
Click here: https://www.youtube.com/watch?v=8myTWgsBzOc&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=4&t=130s&pp=iAQB


Skills you need to get 50,000/- salaryüí∞üòØ
Click here: https://www.youtube.com/watch?v=yjn2rUF7MFA&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=7&t=355s&pp=iAQB


Importance of DSA for Data Science jobsü§î
Click here: https://www.youtube.com/watch?v=tvDNVuqNj6o&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=9&t=206s&pp=iAQB


Data Scientist interview experience at Cognizantüëç
Click here: https://www.youtube.com/watch?v=HzNRJuzELSU&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=8&pp=iAQB


Salary negotiation tipsüíµüëç
Click here: https://www.youtube.com/watch?v=H9qfWEmg5es&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=6&pp=iAQB


5 Mistakes to avoid during Data Science prepüòØüëç
Click here: https://www.youtube.com/watch?v=D9N_7BVdqus&list=PLupK5DK91flXM5eS8FKQBfVFgTY0Ogcoy&index=3&t=306s&pp=iAQB



#largelanguagemodels #llm #generativeai #llm #datascience #deeplearning #analytics #career",Vikash Das,2023-09-01T07:30:03Z,2023-09-06T11:45:19Z
49,Using AI in PhD Thesis Writing/Research - Language Models and Economic Research,70G8PurkPR4,47,1:4:59,"Hosted by Arshad Ayub Graduate Business School - UiTM

Tuesday, August 29, 2023 5:00 PM
Speaker: Tomas Oles (PhD candidate, University of Economics in Bratislava, Slovakia, ERASMUS ODDEA Seconded Researcher)
Platform: Cisco Webex",AAGBS UiTM,2023-09-01T03:46:28Z,2023-09-06T11:45:19Z
50,üåå Embracing Technological Evolution: From Slide Rulers to Large Language Models üì±üß†,4AjL076kEN8,39,59,#TechnologicalEvolution #LanguageModels #Creativity #Innovation #ToolsOfTheFuture #EmbracingChange #DigitalAge #AdaptingToTech #UnleashIdeas,Beyond Bitcoin,2023-08-31T22:00:02Z,2023-09-06T11:45:19Z
51,What are Large Language Models? #ai #datascience #llm #chatgpt #machinelearning  #deeplearning,oE3T4loyyqk,35,55,,Swayanshu,2023-08-31T20:38:00Z,2023-09-06T11:45:19Z
52,Large Language Models  #ai #datascience #nlp #chatgpt #machinelearning #neuralnetworks #analysis,V8A7BHUXIwg,90,7:2,"In this video, I delve into the fascinating world of large language models. I explored what they are, how they work, and their impact on various fields, such as natural language processing, translation, and even creative writing. Join me as I uncover the power and potential of these sophisticated AI models and discover how they are revolutionizing the way we interact with language. Thanks to @canva for the video editing. 

Recommended Courses:
https://www.coursera.org/learn/introduction-to-large-language-models/
https://www.coursera.org/learn/introduction-to-generative-ai/",Swayanshu,2023-08-31T19:53:33Z,2023-09-06T11:45:19Z
53,LLaSM: Large Language and Speech Model,ztr87-sYE_k,110,10:27,"This paper introduces LLaSM, a large multi-modal speech-language model capable of following speech-and-language instructions. The model demonstrates a more natural way for humans to interact with AI. A dataset and code are also provided.

00:00 Section: 1 Introduction
03:11 Section: 2 Related Work
07:08 Section: 3.2 Data Collection
10:15 Section: 4 Experiments

https://arxiv.org/abs//2308.15930

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-31T15:35:27Z,2023-09-06T11:45:19Z
54,How Large Language Model AI is Revolutionizing Construction,rgFKMpeGSQM,25,4:14,"üèóÔ∏è Learn more at http://thecontechcrew.com

--

A large language model is bigger than a blockchain.

And there are three ways it can impact construction.

Tune in to learn more about the power of AI and how it can get things done in seconds!

üëâ Watch the Full Episode Here: https://youtu.be/wWIRHqvCVoE

‚ùó Subscribe to  @TheConTechCrew to keep updated with the latest in the construction industry.


üìö Additional Resources:

Listen to the show at http://thecontechcrew.com

Follow us on Twitter: https://twitter.com/thecontechcrew

‚Äì

Follow Wyatt on LinkedIn: https://www.linkedin.com/in/wyattjenkins/

Check Procore out for more information: https://www.procore.com/en-sg

‚Äì

The ConTech Crew is a construction news podcast dedicated to keeping you up to date with all the latest in construction technology.

Give us a follow so you never miss an episode!

#procore #constructiontechnology #Tech #Construction #News",The ConTech Crew,2023-08-31T15:00:47Z,2023-09-06T11:45:19Z
55,Should We Be Concerned About AGI Emerging from Large Language Models?,V5L1Gr_q1GU,107,11:,"Will artificial general intelligence emerge from super-massive, large language models?
We explore the so-called emergent capabilities of large language models and how they relate to artificial general intelligence. We distinguish between scientific fact and myths of AGI in this short video.
Sign up for my course and learn to build your first LLM-powered application: https://www.data-centric-solutions.com/course
Follow me on Medium for my written content: https://johnadeojo.medium.com/
Book a consultation with me: https://www.data-centric-solutions.com/booking-calendar
Paper on Emergent Abilities: https://arxiv.org/pdf/2206.07682.pdf
Paper debunking Emergent Abilities: https://arxiv.org/pdf/2304.15004.pdf",Data-Centric Solutions,2023-08-31T14:10:16Z,2023-09-06T11:45:19Z
56,From Idea to Implementation - How to Use Language Models in Your Business,Py8nhj5bpqU,17,1:5:55,"From Idea to Implementation - How to Use Language Models in Your Business is a video that teaches entrepreneurs and business owners how to leverage their data and business processes using AI. The video covers three main areas: 

* Prompt Engineering
* Application Development 
* Fine-Tuning

***
Want to learn how you can leverage AI and Large Language Models in your business? 

Contact Vincent at Founders Workshop: 
https://foundersworkshop.com/ai/

or Ana at Decision Tree AI:
https://www.decision-tree-ai.com/",Vincent Serpico,2023-08-31T13:48:51Z,2023-09-06T11:45:19Z
57,Live Anderson Amaral (Stealth Mode AI Startup) - Large Language Models,vNr2T5T88TM,0,P0D,"T√≠tulo Original: O uso de Large Language Models aplicado em Business Analytics 

üíº Biografia do palestrante 
Tem mais de 26 anos de experi√™ncia em tecnologia, tendo passado como Head de dados em empresas como Stone, Picpay e empresas norte-americanas. √â profissional Top Rated Plus no Upwork e dono de um ag√™ncia on line de desenvolvimento de assistents de IA e Chatbots principalmente para o mercado estrangeiro. Atualmente tem um startup em Stealth Mode desenvolvimento produtos j√° lan√ßados, e outros a lan√ßar. 

LinkedIn do Palestrante: https://www.linkedin.com/in/andersonlamaral/ 

‚û°Ô∏è Saiba mais: https://bit.ly/2023-vamos-la  

J√° conhece a comunidade e desejar assinar agora:  
Plano Anual: https://bit.ly/43u7mQz  
Plano Semestral: https://bit.ly/3qdbEgO  

ü•áFa√ßa parte do EstaTiDados: ü•á  
üìåSaiba mais ¬ª https://linktr.ee/estatidados  
üí¨ Grupo Telegram ¬ª https://t.me/estatciencia/1  
üéÅ Loja EstaTiDados Editora GEN (Desconto 20%) ¬ª https://bit.ly/e-estatidados20  
üìÅApp portfolio R ¬ª https://estatidados.shinyapps.io/portfoliothiagomarques/ 
üéìCertificados: http://comunidadedeestatistica.com.br/blog/ 
üìö Forma√ß√µes ao vivo: https://bit.ly/43th2uE 
üì∞Nossos artigos: https://comunidadedeestatistica.com.br/blog/",EstaTiDados,2023-08-31T13:18:53Z,2023-09-06T11:45:19Z
58,Investigating Two Techniques for Discrete Parameter-Free Prompt Optimization - Vector Intern Talks,sEzFkG45igA,53,14:54,"In this presentation, Saeed discusses two techniques to optimize discrete prompts without updating or introducing any parameters over the T5 large language model. The first approach involves conducting a gradient search over mini-batches of training examples and necessitates computing the gradient in the language model. On the other hand, the second method is entirely gradient-free, and it enhances the prompt by optimizing the initial instruction based on the final task metric over validation data. The presentation will showcase optimized prompts created using both these methods for sentiment analysis.

Vector applied interns are curious students and researchers affiliated with the Vector Institute who collaborate with the best and brightest AI developers, scaling research breakthroughs in Machine Learning and Deep Learning. 

This is one of many Internship Talks from Demo Day, where interns presented their projects after completing their work term. Projects span across sectors, some of which include: Project Management, Automation, Applied Machine Learning, and Data Visualization.",Vector Institute,2023-08-31T13:09:13Z,2023-09-06T11:45:19Z
59,Unlocking AI Language Models for Data Management: Insights for Data and Business Leaders,KS-hVqvf0vY,29,49:53,"While nobody can predict the overall future of generative AI, the business case for AI-driven data management is becoming clear. 

Most early adopters estimate that large language models such as ChatGPT and Bard make them up to 30% more productive, and new domain-specific tools from data pipeline vendors aim to beat these gains. 

Data teams use language models to document their environments, build pipeline code, run data quality checks, learn new techniques, and more. 

But Chief Data Officers and business leaders must tread with caution. 

They must understand new risks for data quality, privacy, intellectual property, fairness, and explainability. 

They must adapt their data governance programs to control these risks, train their teams on prompt engineering, and give careful thought to evolving team responsibilities. By adopting these guiding principles, CDOs and business leaders can democratize business  consumption of data for analytics--unleashing unprecedented productivity gains.

Watch this strategic discussion with Kevin Petrie, VP of Research at Eckerson Group, and Heine Iversen, CEO of TimeXtender, to explore the impact of language models on data management. 

You will learn:

-The definition of generative AI and language models
-The business benefits and costs of applying language models to data management
-Guiding principles for successful adoption and bottom-line results",TimeXtender,2023-08-31T11:18:12Z,2023-09-06T11:45:19Z
60,What You Can Use Large Language Models &amp; Vector Database for and Why You Need It?,C8BKnv7Vn64,22,46,"AnalyticDB for PostgreSQL is idea for vector data storage and similarity search. By seamless integration with LLM, you can build your own chatbot or knowledge base to improve efficiency.

„ÄêFree Trial„Äë
https://www.alibabacloud.com/product/hybriddb-postgresql

„ÄêLearn More„Äë
https://www.alibabacloud.com/blog/600220",Alibaba Cloud ApsaraDB,2023-08-31T07:40:10Z,2023-09-06T11:45:19Z
61,Exploring Llama 2: Open-Source AI Advances &amp; the Future of Large Language Models,-v7CH8EY3oM,42,3:14,"The newsletter discusses the release of Llama 2 and CodeLlama, new additions to the open-source AI large language model (LLM) landscape. It also mentions the leaked details of the GPT-4 model and alternative transformer-based LLMs. OpenAI has introduced a new finetuning API for the GPT-3.5-turbo, sparking discussions about closed proprietary AI systems versus open-source models. The newsletter highlights the contributions of the open-source community in developing finetuning technologies and mentions the NeurIPS LLM Efficiency Challenge. Llama 2 is a foundational model that offers pretrained base models and finetuned chat models, with improved performance compared to other open-source models. The models were refined using reinforcement learning with human feedback (RLHF) and the Llama 2 paper provides detailed information on their training. The newsletter also discusses the challenges of extending LLMs to larger input contexts and introduces Retentive Network as a new transformer alternative. Additionally, it mentions the ongoing GPU shortage in the industry. The copyright status of LLMs trained on copyrighted material is still not fully understood, as highlighted in a recent article about authors accusing Meta of utilizing their copyrighted works in training LLMs. The term ""foundation models"" has gained acceptance, and a new term ""frontier AI models"" has been coined to describe highly capable LLMs with dangerous capabilities. There is an ongoing GPU shortage, and NVIDIA has announced the GH200 GPUs with increased RAM. The newsletter also mentions upcoming events and opportunities in the LLM field, including a keynote talk and a tutorial session. The NeurIPS 2023 LLM Efficiency Challenge is highlighted as an exciting opportunity to develop more efficient training methods for LLMs.

üîó https://magazine.sebastianraschka.com/p/ahead-of-ai-11-new-foundation-models

#AI #AI #GPT #OpenAI #Prompt #LLM",AI Insight News,2023-08-31T07:11:36Z,2023-09-06T11:45:19Z
62,[T@W 2023 intro] Suzan Verberne ‚Äî Conversational Agents and Search,PiSTMoa40dQ,56,1:46,"This talk will be about the relation between information retrieval and generative large language models, and will argue why we in this time still need information retrieval and search engines. Generative large language models are very fluent in generating language for human like bots, they're also very prone to generating misinformation just because of how they were designed. We need to do something to make them more reliable and grounded in sources.",Zeta Alpha Vector,2023-08-31T07:00:23Z,2023-09-06T11:45:19Z
63,VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models,Yvn4eR05A3M,2763,5:48,"VoxPoser: Composable 3D Value Maps for Robotic Manipulation with Language Models (CoRL 2023 Oral)
Authors: Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, Li Fei-Fei
Website: voxposer.github.io

Abstract: Large language models (LLMs) are shown to possess a wealth of actionable knowledge that can be extracted for robot manipulation in the form of reasoning and planning. Despite the progress, most still rely on pre-defined motion primitives to carry out the physical interactions with the environment, which remains a major bottleneck. In this work, we aim to synthesize robot trajectories, i.e., a dense sequence of 6-DoF end-effector waypoints, for a large variety of manipulation tasks given an open-set of instructions and an open-set of objects. We achieve this by first observing that LLMs excel at inferring affordances and constraints given a free-form language instruction More importantly, by leveraging their code-writing capabilities, they can interact with a visual-language model (VLM) to compose 3D value maps to ground the knowledge into the observation space of the agent. The composed value maps are then used in a model-based planning framework to zero-shot synthesize closed-loop robot trajectories with robustness to dynamic perturbations. We further demonstrate how the proposed framework can benefit from online experiences by efficiently learning a dynamics model for scenes that involve contact-rich interactions. We present a large-scale study of the proposed method in both simulated and real-robot environments, showcasing the ability to perform a large variety of everyday manipulation tasks specified in free-form natural language.",Wenlong Huang,2023-08-31T05:12:40Z,2023-09-06T11:45:19Z
64,Setting up a local Large Language Model (LLM),wbVdwFNeZCA,291,1:50:37,"Learn how to setup a local Large Language Model on windows that is GPU accelerated. During the stream, I will show you how to set up your Windows environment for LLM development, including:

- Installing Python, Notepad++, Visual Studio, CUDA, NumPy, and PyTorch
- Configuring your environment for GPU acceleration
- Downloading and loading a large language model
- Creating a prompt template
- Interacting with the large language model

We will also have some fun with prompt templates, trying out different ways to generate text and I will answer your questions regarding LLMs. In this stream I'll build a 'Snoop Dogg'-inator, the code can be found at Github: https://github.com/DannyArends/LLMstream/tree/master

Thanks for taking an interest in my channel üòÑIf you've made it this far down, support me by giving a like or subscribing.

00:00:00 Sound check
00:01:27 Overview for today
00:06:56 What is a Large Language Model (used for)
00:11:24 Installing Python and the package installer for Python (pip)
00:13:20 Testing our Python installation using CMD
00:15:01 Visual Studio Community Edition & Python development Workload
00:18:34 Install the CUDA development library
00:23:04 Python packages for LLMs (NumPy, PyTorch, LlamaCPP)
00:33:09 Picking an Large Language Model
00:48:14 Coding an LLM in Python (Step by Step)
01:00:21 Create a sentence embedding in Python
01:10:22 Create a LLM callback handler
01:18:47 Setup the LlamaCPP Large Language Model
01:30:12 Prompt Template and LLMchain
01:35:58 User Input and executing the LLMchain
01:37:30 Running the LLM
01:40:06 Next steps in LLM development
01:44:33 Thoughts about the next stream

#LLMsetup #GPUacceleratedLLM #LLMdevelopment #prompttemplates #largelanguagemodels #artificialintelligence #machinelearning #generativeai",Danny Arends,2023-08-31T02:01:05Z,2023-09-06T11:45:19Z
65,Applied Large Language Models with Brian MacKay,0j8gDJXpDsM,19,1:5:15,"Source:
https://www.spreaker.com/user/16677006/dotnetrocks-1861-applied-large-language-

How can a large language model help your application? Carl and Richard talk to Brian MacKay about his work with large language models, including ChatGPT - and others! Brian talks about how LLMs continue to evolve and the limitations they have. But identifying language inside your applications can be powerful, and Brian talks through a few scenarios his company uses in production today. Work could you be taking advantage of today!",Carl Franklin,2023-08-31T00:53:16Z,2023-09-06T11:45:19Z
66,Making Large Language Models Work For You,aC7UQcZN6y8,1286,1:9:30,,WordPress,2023-08-30T22:07:30Z,2023-09-06T11:45:19Z
67,LLM Mini-Series E2 - Parallel Multi-Document Question Answering With Llama Index and RAG,xOOIVwH3g68,143,12:31,"Theoretical introduction to multi-index RAG: 00:00 - 03:53
Walk through of the application code: 03:54 - 08:25
Demo of the Streamlit application: 08:26 - 10:17
Graph-based analysis of skills and competencies: 10:18 - 12:31

Explore the fascinating world of Large Language Models with our LLM Mini-Series!

In Episode 2, we explore the revolutionary approach of Parallel Multi-Document Question Answering using Llama Index and Retrieval Augmented Generation (RAG). This episode is a deep dive into how HR recruitment can be transformed through the power of Large Language Models (LLM) and semantic search technologies.

Learn how to efficiently gather and compare information from multiple documents by splitting them into smaller text chunks and computing vector representations. We'll walk you through the entire process, from initializing a node parser to setting up query engines for each document. Discover how to execute queries with a query executor and visualize network graphs based on the skills of different applicants.

This episode also delves into the importance of having a robust knowledge base to support the querying stage. We'll show you how to use a semantic search retrieval pipeline to filter relevant information and generate accurate answers. You'll also get insights into cluster analysis, and how to compare the soft skills of different data scientists using the Center Transformer model.

Whether you're an HR professional, a data scientist, or someone interested in natural language processing, this episode offers invaluable insights into the future of recruitment and data analysis. Don't miss out on this enlightening journey‚Äîwatch now and stay tuned for more episodes in the series!

#HRRecruitment #DataScience #naturallanguageprocessing  #LlamaIndex #llm #RetrievalAugmentedGeneration

Access to the Git-Hub Repository: https://github.com/PositiveThinkingComp/LLM_Mini_Series_Part_II

Read the blog post:",Positive Thinking Company,2023-08-30T15:53:05Z,2023-09-06T11:45:19Z
68,Open-Source Spotlight - Titan Takeoff - Fergus Finn,aIRP5yW5E1E,147,24:57,"Titan Takeoff: This is a server designed for optimized inference of large language models.

00:00 Intro and a few words about Fergus 
00:12 Titanml 
00:26  The Takeoff Server
00:55 Demo: using The Takeoff Server to quickly and easily deploy large language models locally
04:00 Examples of interacting with a large language model using The Takeoff Server
06:16 Optimisations: getting around needing a big GPU - optimising through quantisation, how it works and what it means for memory usage 
07:04 Running a model on a 4GB laptop with 4GB of GPU and 16 GB RAM
07:55 User interfaces of The Takeoff Server: chat and playground
11:00 Running The Takeoff server locally with a CPU
12:13 - Helm charts, Kubernetes deployment, resources
14:34 Models that are supported by The Takeoff Server 
17:11 List of things contributors can help with - open source community project & how to get involved 
18:24 How to find the Discord channel
19:00 How to give a star on GitHub
19:46 Future plans - generating structured content from large language, more optimisations for more models, ongoing improvements to the ergonomics 
23:10 Advice for people interested in this area

Links: 

- GitHub repository: github.com/titanml/takeoff
- GitHub community: https://discord.com/invite/SDnUJSPg7t
- Document: https://docs.titanml.co/blog

Free MLOps course: https://github.com/DataTalksClub/mlops-zoomcamp
Join DataTalks.Club: https://datatalks.club/slack.html
Our events: https://datatalks.club/events.html",DataTalksClub ‚¨õ,2023-08-30T15:00:01Z,2023-09-06T11:45:19Z
69,"Using ChatGPT, GPT-4, &amp; Large Language Models In the Enterprise",Dnn-7F_9vxs,89,51:59,"Watch our insightful in-person event designed for professionals and industry experts, where we unravel how the latest advancements in NLP can reshape data utilization in enterprise settings.

Explore a comprehensive range of topics and strategies that will empower data scientists, business analysts, and executives alike. Discover how to tap into the true potential of language models to elevate your enterprise data game. From decoding complex datasets to making informed decisions, this event equips you with practical knowledge and real-world applications.

Don't miss this opportunity to stay ahead of the curve and transform your data-driven endeavors. https://www.royalcyber.com/generative-ai-impact-on-businesses/?refer=Youtube 

Website: https://www.royalcyber.com/
LinkedIn: https://www.linkedin.com/company/royal-cyber-inc- 
Twitter: https://twitter.com/RoyalCyberUSA
Instagram: https://www.instagram.com/royalcyberinc/
Facebook: https://www.facebook.com/RoyalCyber

#NLP #GPT4 #DataRevolution #EnterpriseInsights #chatgpt #gpt-4",Royal Cyber Inc,2023-08-30T14:41:41Z,2023-09-06T11:45:19Z
70,Introduction to Language Models,Rx5MRau-zXA,356,20:5,"Join Us for an Exploration into Language Models: Your Essential First Step!

üëã Welcome to the Language Models Fundamentals Course with H2O.ai!

üìò Course Overview:
Embark on an insightful journey into the world of Language Models (LMs) with us! This course serves as your gateway to understanding the fundamental concepts within the Language Models domain. It's the inaugural stage of the comprehensive LLM Learning Path crafted by our H2O University Department.

üîç What You'll Learn:
Throughout this course, we'll delve into key topics:
1. üß† Understanding Language Models: Uncover their significance and common techniques.
2. üåê Importance and Applications: Witness LMs in action across diverse fields.
3. üåà Large Language Models (LLMs): Explore their capabilities and potential applications.

üéì Why Join Us:
No matter your background, this course offers an accessible learning experience tailored to your pace. Acquire insights and practical knowledge that can make a difference.",H2O.ai,2023-08-30T13:00:21Z,2023-09-06T11:45:19Z
71,The First Thing to Tell a Large Language Model | Prompt Engineering and LLMs,2dpIP-RHFqk,188,31:3,"In an interview with The New Stack, renowned technologist Adrian Cockcroft discussed the process of fine-tuning Large Language Models (LLMs) through prompt engineering. Cockcroft, known for his roles at Netflix and Amazon Web Services, explained how to obtain tailored programming advice from an LLM. By crafting specific prompts like asking the model to provide code in the style of a certain expert programmer, such as Java's James Gosling, users can guide the AI's output.

Prompt engineering involves setting up conversations to bias the AI's responses. These prompts are becoming more advanced with plugins and loaded information that shape the model's behavior before use. Cockcroft highlighted the concept of fine-tuning, where models are adapted beyond what a prompt can contain. Companies are incorporating vast amounts of their internal data, like wiki pages and corporate documents, to train the model to understand their specific domain and processes.

Cockcroft pointed out the efficacy of ChatGPT within certain tasks, illustrated by his experience using it for data analysis and programming assistance. He also discussed the growing need for improved results from LLMs, which has led to the demand for vector databases. These databases store word meanings as vectors with associated weights, enabling fuzzy matching for enhanced information retrieval from LLMs. In essence, Cockcroft emphasized the multifaceted process of shaping and optimizing LLMs through prompt engineering and fine-tuning, reflecting the evolving landscape of AI-human interactions.

Learn more from The New Stack about LLMs and Prompt Engineering:

Top 5 Large Language Models and How to Use Them Effectively
https://thenewstack.io/top-5-large-language-models-and-how-to-use-them-effectively/

The Pros (And Con) of Customizing Large Language Models
https://thenewstack.io/the-pros-and-con-of-customizing-large-language-models/

Prompt Engineering: Get LLMs to Generate the Content You Want
https://thenewstack.io/prompt-engineering-get-llms-to-generate-the-content-you-want/

Developer Tips in AI Prompt Engineering
https://thenewstack.io/developer-tips-in-ai-prompt-engineering/",The New Stack,2023-08-30T11:00:01Z,2023-09-06T11:45:19Z
72,"Large language models - What, How, implications and potential",CxtsaEHaak4,27,1:23:10,"In this informative and interactive webinar our speakers will take us through a 101 of Large Language Models as well as both local and international examples of how they are being applied across sectors for impact. We will unpack their implications, including referring to our recently released discussion paper on the policy implications of such models, and potential, enabling a deep dive into key areas, and there will be time for the audience to ask questions.",AI Researchers Association,2023-08-30T08:10:15Z,2023-09-06T11:45:19Z
73,A Benchmarking Approach for Large Language Models as Agents (BLAST AI &#39;23 Summer Symposium),VbJOEJ6ISaU,12,15:24,,Blast AI,2023-08-30T00:35:53Z,2023-09-06T11:45:19Z
74,NLP in Fintech  How Large Language Models are transforming the future of Fintech,6z1-5CltK6g,257,27:12,"Don‚Äôt miss Data Science Salon Miami on September 19! Book your pass here https://www.datascience.salon/miami/ to learn more about generative AI and machine learning in the enterprise.

Presented by Jayeeta Putatunda, Senior Data Scientist at Fitch Ratings

This presentation by Jayeeta Putatunda, Senior Data Scientist at Fitch Ratings provides an overview of AI in finance - where it is and the path forward. It includes best practices to consider as organizations begin implementing end-to-end ML models and how you can prepare for the NLP revolution and extract value as a data driven organization. It closes with a case-study on how to use open-source NLP large language models (LLMs) to gain insights from terabytes of unstructured financial text data.",Data Science Salon,2023-08-29T20:39:20Z,2023-09-06T11:45:19Z
75,Research Talk: Knowledge-graphs enhanced Large Language Models (LLMs) by Dr. Saatviga Sudhahar,EWxPWuskMpg,109,1:13,"Synopsis: Large language models (LLMs) are renowned for their ability to learn knowledge from large-scale corpus and achieve state-of-the-art performance in various Natural language processing tasks. However, LLMs are often criticized for their hallucination issues, and lacking interpretability. To address these, LLMs are enhanced with knowledge graphs (KGs) which store enormous knowledge in an explicit and structured way, which can be used to enhance the knowledge awareness of LLMs. To improve the interpretability of LLMs, researchers also utilize KGs to interpret the facts and the reasoning process of LLMs . In this talk we summarize some representative applications of using LLMs and KGs and how these two work in synergy and pinpoint some of the future research directions.

Guest Speaker: Dr. Saatviga Sudhahar is a Senior Machine Learning Scientist at Healx, an AI-powered Bio-tech company in Cambridge. Her key specialities are in Natural Language Processing, Machine Learning, Knowledge graphs and Reasoning using Deep learning. Saatviga has a PhD in Engineering Mathematics and AI from the University of Bristol. She is an author of over 20 peer-reviewed publications with over 500 citations, serving as mentor or Hatch Works, Sri Lanka providing mentorship for start-ups on using ML and NLP technologies.",DataSEARCH,2023-08-29T19:54:10Z,2023-09-06T11:45:19Z
76,‡∂∏‡∑ú‡∂±‡∑Ä‡∂Ø ‡∂∏‡∑ö Large Language Models? | Discussion with Malinda Alahakoon,NNsUMzkGN-U,1432,24:11,"A Large Language Model (LLM) refers to a type of artificial intelligence system that is specifically designed to process and generate human-like text. These models are built using deep learning techniques and are trained on vast amounts of text data from the internet, books, articles, and other sources. The aim of training these models is to enable them to understand and generate human language with a high degree of fluency and context.

One of the most well-known examples of a Large Language Model is OpenAI's GPT (Generative Pre-trained Transformer) series, including GPT-3. These models consist of numerous layers of processing units that can learn complex language patterns, grammatical structures, and contextual relationships from the data they are trained on.

Large Language Models are capable of various language-related tasks, including:

Text Generation: They can produce coherent and contextually relevant text passages, articles, stories, and more.

Text Completion: They can suggest word predictions or complete sentences given a partial input.

Text Summarization: They can generate concise summaries of longer texts.

Language Translation: They can translate text from one language to another.

Question Answering: They can provide answers to questions posed in natural language.

Chatbots and Conversational Agents: They can engage in text-based conversations, simulating human-like interactions.

Content Creation: They can assist with content generation for marketing, social media, and other platforms.

Code Generation: They can generate programming code based on descriptions or requirements.

Data Analysis: They can assist in processing and analyzing textual data.

Language Understanding: They can extract information, sentiment, and context from text.

Large Language Models have shown significant advancements in their ability to understand and generate text, leading to applications in various industries such as customer service, content creation, education, research, and more. They are also part of ongoing research and development in the field of artificial intelligence, contributing to the progress of natural language processing capabilities.

‡∑Ä‡∑í‡∂Ø‡∑î‡∑É‡∂ª - ‡∑Å‡∑ä‚Äç‡∂ª‡∑ì ‡∂Ω‡∂Ç‡∂ö‡∑è‡∑Ä‡∑ö ‡∂¥‡∑Ö‡∑Ä‡∂± ‡∂ë‡∂ö‡∂∏ ‡∂¥‡∑ú‡∂Ø‡∑î‡∂¢‡∂± ‡∑Ä‡∑í‡∂Ø‡∑ä‚Äç‡∂∫‡∑è ‡∂¥‡∑ä‚Äç‡∂ª‡∂ö‡∑è‡∑Å‡∂±‡∂∫.

‡∑Ä‡∑í‡∂Ø‡∑ä‚Äç‡∂∫‡∑è ‡∂Ω‡∑ù‡∂ö‡∂∫‡∑ö ‡∂±‡∑Ä‡∂≠‡∂∏ ‡∂≠‡∑ú‡∂ª‡∂≠‡∑î‡∂ª‡∑î ‡∑É‡∂≥‡∑Ñ‡∑è ‡∂¥‡∑í‡∑Ä‡∑í‡∑É‡∑ô‡∂±‡∑ä‡∂±: 
üëâ Facebook https://www.facebook.com/Vidusara 

üëâ Instagram http://instagram.com/Vidusara.lk 

üëâ Twitter https://twitter.com/vidusaranews 

üëâ LinkedIn https://www.linkedin.com/company/vidusara-science-magazine/ 

üëâ Telegram Channel https://t.me/vidusarasciencemagazine

#largelanguagemodel #science #vidusara",Vidusara,2023-08-29T11:30:07Z,2023-09-06T11:45:19Z
77,dScience Lunch Seminar: Large language models under the hood,NNQ_pWvNjAw,0,P0D,"Welcome to our dScience lunch seminar in the Science Library, where Andrey Kutuzov will talk about ChatGPT.

In the last few years, radical increase in the scale of deep neural language models (both in terms of the size of the training data and the size of the models themselves) has led to impressive achievements in various natural language processing tasks. ""Celebrity"" models, like ChatGPT, LLaMa, BLOOM or PaLM are already sometimes described to as ""approaching artificial intelligence"", although the reality can differ from over-hyped media coverage.

In this talk, Kutuzov will describe the foundations of the technology behind large-scale language models. Two most important components behind their success are 1) state-of-the-art deep learning architectures (in particular, Transformer) and 2) the availability of tremendous amount of textual data used to train such models. The interaction of these two poses intricate theoretical and practical questions, also linked to issues with unequal distribution of computing resources. Do we have enough good-quality training data for languages other than English? Is ""data poisoning"" with automatically generated texts is a real danger? Why is it important to open source both training data and model weights?

Speaker
Andrey Kutuzov (PhD, UiO, 2020) is an Associate Professor in the Language Technology Group at the University of Oslo. He currently serves as the Norwegian on-site manager of the High-Performance Language Technology (HPLT) project. His academic interests include Computational linguistics and natural language processing, semantic change detection and diachronically aware language models, distributional semantics, machine learning and large-scale language models. In 2022, Kutuzov received the Norwegian Artificial Intelligence Research Consortium (NORA) award as a Distinguished Early Career Researcher.

https://www.uio.no/dscience/english/news-and-events/events/23-ls-sep7.html",UiO Realfagsbiblioteket,2023-08-29T10:55:24Z,2023-09-06T11:45:19Z
78,Multimodal Chain of Thought Reasoning in Language Models,bv7nzVVQwTo,100,9:47,"Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer. However, existing CoT studies have focused on the language modality. Multimodal-CoT incorporates language and vision modalities into a two-stage framework that separates rationale generation and answer inference. Mutimodal-CoT-Large outperforms GPT-3.5 by 16.51% on ScienceQA. 

In this video, I will talk about What is multimodal CoT and How does multimodal CoT perform on ScienceQA.

For more details, please look at https://arxiv.org/pdf/2302.00923.pdf

Zhang, Zhuosheng, Aston Zhang, Mu Li, Hai Zhao, George Karypis, and Alex Smola. ""Multimodal chain-of-thought reasoning in language models."" arXiv preprint arXiv:2302.00923 (2023).",Data Science Gems,2023-08-29T04:20:18Z,2023-09-06T11:45:19Z
79,Jian Ma | Large Language Models for Computational Biology  A Primer,tRTVxlakJCw,426,49:26,,Computational Genomics Summer Institute CGSI,2023-08-29T01:10:06Z,2023-09-06T11:45:19Z
80,Create a Large Language Model using Python,4MHzI10iVbQ,61,23:16,"Welcome to this Python tutorial on creating your own Language Model using PyTorch! Have you ever wondered how your smartphone predicts the next word as you type? This video will walk you through each step of the process to develop a simplified version of this technology.

Links: 
- Pytorch: https://pytorch.org/docs/stable/index...
- Github: https://github.com/rishabh4497/aiModel/blob/main/llm.py
- Attention is All You Need paper: https://arxiv.org/abs/1706.03762
- My Twitter: https://twitter.com/_rishavchhabra

Chapters:
00:00 Introduction
00:20 Setting Up the Environment and Understanding Language Models
06:34 Preparing and Preprocessing data
11:54 Creating Hyperparameters
13:50 Training the Model: Making it Smarter
19:48 Testing: Let's Predict Some Text!

In this video, we cover:

Setting up a Python environment for machine learning
What a Language Model is and how it works
How to prepare your data for the model
How to define and train the model in PyTorch
How to test your model to predict the next word in a sentence
Perfect for anyone interested in machine learning, natural language processing, or just curious about how text prediction works.

#PyTorch #NaturalLanguageProcessing #LanguageModel #MachineLearning #TextPrediction #PythonProgramming #DeepLearning #ArtificialIntelligence #DataScience #CodingTutorial

Thanks for watching.",Rishav Chhabra,2023-08-28T21:24:48Z,2023-09-06T11:45:19Z
81,New AI - Code Llama - Broke the Internet: Why Everyone&#39;s Switching from GPT-4,_OaIJLMbIwU,21246,8:29,"Meta's new AI, Code Llama, is a revolutionary tool designed for coding tasks, surpassing competitors like ChatGPT and GitHub Copilot Chat. With unique features like fill-in-the-middle, it aids coders in generating and understanding code, and is available for free on Perplexity AI Labs and HuggingFace. Explore the capabilities of Code Llama and anticipate its upcoming version, Unnatural Code Llama, for a versatile coding experience.

Become a Member of the channel and Supporter of AI Revolution ‚Üí https://www.youtube.com/channel/UC5l7RouTQ60oUjLjt1Nh-UQ/join

#codellama #ai",AI Revolution,2023-08-28T21:22:25Z,2023-09-06T11:45:19Z
82,Bradley Love | Advancing Neuroscience Using Large Language Models,7G4gR8LfI04,523,50:23,"*Apply to join Foresight Neurotech program:* https://foresight.org/neurotech-improving-cognition-program/ 
A group of neuroscience researchers, entrepreneurs, and allies advancing beneficial short-term and long-term neurotechnology applications.

*Bradley Love, UCL*
*Advancing Neuroscience Using Large Language Models*
Bradley is a Professor of Cognitive and Decision Sciences in Experimental Psychology at UCL and a fellow at The Alan Turing Institute for data science and AI, as well as the European Lab for Learning & Intelligent Systems (ELLIS). His lab's research centers around human learning and decision making, integrating behavioural, computational, and neuroscience perspectives. Currently, they are focused on large-scale modelling of brain and behaviour using deep learning approaches, as well as using large language models to create BrainGPT, a tool to assist neuroscience researchers.
https://bradlove.org/

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

*About The Foresight Institute*

The Foresight Institute is a research organization and non-profit that supports the beneficial development of high-impact technologies. Since our founding in 1986 on a vision of guiding powerful technologies, we have continued to evolve into a many-armed organization that focuses on several fields of science and technology that are too ambitious for legacy institutions to support. From molecular nanotechnology, to brain-computer interfaces, space exploration, cryptocommerce, and AI, Foresight gathers leading minds to advance research and accelerate progress toward flourishing futures.

*We are entirely funded by your donations. If you enjoy what we do please consider donating through our donation page:* https://foresight.org/donate/

*Visit* https://foresight.org, *subscribe to our channel for more videos or join us here:*
*‚Ä¢ Twitter:* https://twitter.com/foresightinst 
*‚Ä¢ Facebook:* https://www.facebook.com/foresightinst 
*‚Ä¢ LinkedIn:* https://www.linkedin.com/company/foresight-institute",Foresight Institute,2023-08-28T20:51:15Z,2023-09-06T11:45:19Z
83,Unleashing the Power of Large Language Models for Exciting Tech Innovations,VH8Od4UjrFk,22,53,,Apoorva Pande at FocusedFounder,2023-08-28T20:00:08Z,2023-09-06T11:45:19Z
84,"Exploring Neural Networks, LLMs, and GPTs | Web Development with Generative AI Ep4",Ox2QrrCOgyg,1147,9:41,"In this episode, @heyAustinGil takes a break from coding to get a better understanding of how AI tools work. Austin briefly covers machine learning, neural networks, large language models (LLMs), parameters, embeddings, and generative pre-trained models (GPTs).

New to Cloud Computing? Get started here with a $100 credit ‚Üí https://www.linode.com/lp/youtube-viewers/?ifso=linodetube&utm_source=youtube&utm_medium=SuperUser

Chapters:
0:00 Inroduction
0:30 Brief Recap
1:00 What is AI? 
1:35 About Artificial Neural Networks
2:00 About Large Language Models
3:35 About Embeddings
5:00 About GPT
8:27 Conclusion

Follow along with Austin's GitHub ‚Üí https://github.com/AustinGil/versus
Check out Qwik.js docs‚Üí https://qwik.builder.io/docs/
See OpenAI Docs ‚Üí https://platform.openai.com/overview
Learn more about Fetch API ‚Üí https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API
Subscribe to get notified of new episodes as they come out ‚Üí https://www.youtube.com/linode?sub_confirmation=1

#AkamaiDeveloper #openai #qwikjs #nodejs 
Product: Akamai Developer, Open AI, Qwik.js, ChatGPT; @heyAustinGil‚Äã",Akamai Developer,2023-08-28T19:00:16Z,2023-09-06T11:45:19Z
85,AI - Mastering Large Language Models (LLMs) under 15 mins: A Comprehensive Guide,Z6htN7lbQfk,159,15:6,"In this video, I'm going to show you how to master LLM (Language Learning Module) machine learning models in just 15 minutes.

If you're new to machine learning or want to quickly improve your skills, this comprehensive guide is for you. I'll explain everything from the basics of machine learning to more advanced techniques, so you can learn how to build powerful models in no time!",Acemapper,2023-08-28T17:57:35Z,2023-09-06T11:45:19Z
86,An Introduction to Large Language Models and Chat GPT4,-eBtOAgPQUI,19,1:1:19,"Hosted by: 
Shawn Patt, CPWA¬Æ
Michael Salam
Daniel Leibman

Sponsored By:
Atala Financial: Leaders in Personal Wealth Management
Wonderworks: Innovators in Tech Education

About This Video:
Get ready to dive deep into the world of Large Language Models and Chat GPT-4. Perfect for tech enthusiasts, business professionals, and AI aficionados. We'll cover everything from how these algorithms work, their practical use cases, to the limitations you should be aware of.

What You'll Learn:
How Algorithms Power Language Models: Get an insider look at the technology behind Large Language Models like Chat GPT-4.

Use Cases in Business & Personal Projects: Learn how these language models are transforming industries from customer service to content creation.

Limitations & Weaknesses: We discuss the challenges and pitfalls you should be mindful of when using these powerful tools.

Effective Usage Tips for Chat GPT-4: End with actionable strategies to make the most out of your interaction with Chat GPT-4.

If this video provides value to you, please give it a LIKE, drop a  COMMENT, and SHARE. Remember to SUBSCRIBE and ring the bell for updates on new content!",Mind Your Own Money,2023-08-28T14:45:10Z,2023-09-06T11:45:19Z
87,Unlocking AI Language Models for Data Management - Eckerson Group Webinar,8jMQBPxUzkw,61,49:53,"While nobody can predict the overall future of generative AI, the business case for AI-driven data management is becoming clear. Most early adopters estimate that large language models such as ChatGPT and Bard make them up to 30% more productive, and new domain-specific tools from data pipeline vendors aim to beat these gains. Data teams use language models to document their environments, build pipeline code, run data quality checks, learn new techniques, and more. 

But chief data officers and business leaders must tread with caution. They must understand new risks for data quality, privacy, intellectual property, fairness, and explainability. They must adapt their data governance programs to control these risks, train their teams on prompt engineering, and give careful thought to evolving team responsibilities. By adopting these guiding principles, CDOs and business leaders can democratize business  consumption of data for analytics--unleashing unprecedented productivity gains.

You will learn:
-The definition of generative AI and language models
-The business benefits and costs of applying language models to data management
-Guiding principles for successful adoption and bottom-line results

Sponsor: TimeXtender",Eckerson Group,2023-08-28T14:22:51Z,2023-09-06T11:45:19Z
88,"1. What is LLM? LLM Types, LLM Benefits, LLM Challenges",LNmqrkvam5g,136,17:,"Here you go, we have started the Large Language Models series here. In this session we have discussed the LLM basics, definition, types, benefits, challenges and more!",Shriram Vasudevan,2023-08-28T14:15:12Z,2023-09-06T11:45:19Z
89,LLMs as compilers,vxprc7n_RL8,623,7:12,"https://vivekhaldar.com/articles/llms-are-compilers/

Large Language Models: Compilers for the 4th Generation of Programming Languages?
https://drops.dagstuhl.de/opus/volltexte/2023/18524/pdf/OASIcs-SLATE-2023-10.pdf


What is it like to program with artificial intelligence?
https://arxiv.org/pdf/2208.06213.pdf",Vivek Haldar,2023-08-28T14:00:29Z,2023-09-06T11:45:19Z
90,Classifying text with Large Language Models #openai #chatgpt #gpt4 #ai #datascience #data,oYIgGDIZcJo,210,52,"Text classification has become way easier nowadays with the help of Generative AI tools such as ChatGPT. While the trivial approach of letting the LLM provide the class directly is extremely easy, there are better ways to guarantee more reliable results to transform your business. In this video, we show three approaches:

1) The straightforward one... just asking ChatGPT to classify the text.
2) Extracting embeddings and training a traditional ML model on top of it.
3) Asking ChatGPT to explain why it thinks that's the actual class. Then, using technique number 2 to classify the explanation.

#openai #chatgpt #gpt4 #ai #datascience #data #artificialintelligence #ai #datascience #machinelearning #ml #decisionmaking #business #entrepreneurship #analytics #businessanalytics",NILG AI,2023-08-28T09:18:26Z,2023-09-06T11:45:19Z
91,KFUPM DAD: Reporting Week Activities 2023: Generative AI and Large Language Models in Academia,o9uGO6d26i4,34,2:10:26,KFUPM DAD: Reporting Week Activities 2023: Generative AI and Large Language Models in Academia,Deanship of Academic Development¬†,2023-08-28T08:54:23Z,2023-09-06T11:45:19Z
92,Summarize Text documents with LangChain | OpenAI | Using Large Language Model (LLM),E5bZSQ4Qjiw,116,21:28,"#artificialintelligence #gpt #langchain #openai 

In this video i am explaining how we can create Pdf documents summarization app using langchain openai wrappers and Render genereated summary on Web using Streamlit application.

LangChain is highly recommended when a longer PDF is in your hand. LangChain has played an important role in our life and is widely used in many fields besides PDF files. With it, you do not need to spend amounts of time reading, and saves you lots of time. Rather than getting a summarization of a PDF, you can also freely chat with it and have a positive interaction.

‚ù§Ô∏è Buy me a coffee : https://www.buymeacoffee.com/rajparmar23

Blog Link :- https://thecodespace.in/multiple-pdf-summarizer-webapp-using-openai-langchain-and-streamlit/

Map Reduce CombineDocument Chain : https://python.langchain.com/docs/modules/chains/document/map_reduce
Stuffing CombineDocument Chain : https://python.langchain.com/docs/modules/chains/document/stuff
RefineCombineDocument Chain : https://python.langchain.com/docs/modules/chains/document/refine

ChatopenAI Wrapper : https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html
OpenAI Wrapper : https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html?highlight=openai#langchain.llms.openai.OpenAI

Related Tags:
artificialintelligence
gpt
langchain
openai
PDFsummarization
text summarization
LangChainApp
Streamlit
documentprocessing
MapReduce
CombineDocumentChain
PDFinteraction
Streamlit
appframework
MachineLearning
DataScience
webapps
ChatOpenAI
LanchainFramework
largeLanguageModels
TiktokenTokenizer
BPEtokenizer
OpenAIlibrary
OpenAPI
PythonAPI
programming
PromptInstructions
TempfileModule
temporaryfiles
datastorage
pythondotenv
environmentvariables
TheCodeSpace
Raj Parmar",TheCodeSpace,2023-08-28T08:30:08Z,2023-09-06T11:45:19Z
93,Beyond LLMs: A Brain Inspired Architechture for AI | Prof Tom Dietterich,J4Hp2QGiHq4,530,18:36,"What if More Scaling does NOT get us to AGI?

Prof Thomas G. Dietterich discusses the skeleton of a possible path forward.

Thomas G. Dietterich is emeritus professor of computer science at Oregon State University. He is one of the pioneers of the field of machine learning. 
He served as executive editor of the journal called Machine Learning (1992‚Äì98) and helped co-found the Journal of Machine Learning Research. 

---
This work is an excerpt, edited for exposition and brevity in line with the title and description above. It was created  for educational purposes Only under the FAIR USE Doctrine. 

Follow the link Below for the original source, which covers a broader perspective.

----
Source and Credits:
Thomas G. Dietterich 
https://www.youtube.com/watch?v=cEyHsMzbZBs",Tech Stories 101,2023-08-28T07:28:11Z,2023-09-06T11:45:19Z
94,Automatically Correcting Large Language Models Surveying the Landscope of diverse self correction st,NiufabYjLPU,23,52:8,Automatically Correcting Large Language Models Surveying the Landscope of diverse self-correction strategies (UCSB 2023),mardin mardin,2023-08-28T04:23:11Z,2023-09-06T11:45:19Z
95,NanoGPT using Simpsons Data: Get Started with Large Language Models,Ty2_bR1mrBQ,188,7:56,"NanoGPT is a simple, fast repository for training/finetuning medium-sized GPTs. I recommend it to get a better handle on large language models. This video walks through using it on a Simpsons dataset. It covers why I chose nanoGPT, how I munged the Simpson dataset, how I trained my first model, and ways to keep learning.

Chapters:
00:00:00 intro
00:00:17 Why NanoGPT
00:00:52 Simpons dataset
00:01:47 Using the Google Colab notebooks
00:02:24 pull into nanogpt_simpsons repo
00:04:18 using the config files
00:05:36 training the model
00:06:12 getting predictions
00:07:16 using weights and biases for experiment management


Repo: https://github.com/rajshah4/nanoGPT_simpsons
Notebook: http://bit.ly/nanogpt_raj
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚òÖ Rajistics Social Media ¬ª 
‚óè Web page: https://rajivshah.com
‚óè LinkedIn: https://www.linkedin.com/in/rajistics/
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ","Rajistics - data science, AI, and machine learning",2023-08-27T21:51:39Z,2023-09-06T11:45:19Z
96,"You Ask, I Answer: Influencing Large Language AI Models for Brand Marketing?",0kZjcDdnr8U,33,7:29,"In today's episode, Jay asks, ""How can we influence large language models to show our brands more favorably?"" To accomplish this, you need a robust PR strategy to get your brand mentioned widely across the internet. I explain how language models work and why broad exposure is key to optimizing for them. Tune in to learn more about this important emerging strategy for marketing!

Subscribe to my weekly #email newsletter:
http://www.christopherspenn.com/newsletter

Please subscribe to my YouTube channel for more #marketing and #analytics videos!
https://www.youtube.com/user/christopherspenn

Need help with your company's #data and #analytics? Let me know:
https://www.trustinsights.ai

Join my free private Slack group, Analytics for #Marketers:
https://www.trustinsights.ai/analyticsformarketers

Grab my newest book, AI for Marketers:
http://aiformarketersbook.com",Christopher Penn,2023-08-27T19:53:04Z,2023-09-06T11:45:19Z
97,WizardLM: Empowering Large Language Models to Follow Complex Instructions Explained,P0CDVRqS8iA,570,33:54,"Paper found here: https://arxiv.org/abs/2304.12244

Code release: https://github.com/nlpxucan/WizardLM",Gabriel Mongaras,2023-08-27T18:00:16Z,2023-09-06T11:45:19Z
98,AI This week - LOTS of ü§ë $$$ and New MODELS!!!,yB9iGpArGzU,4249,24:1,"00:00 Hugging Face raises $235M from investors, including Salesforce and Nvidia
02:07 Watch out, Midjourney! Ideogram launches AI image generator with impressive typography 
04:00 Seamless m4t 
05:56 CodeLlama 
08:22 Unnatural Codellama 
08:56 Phind CodeLlama 
10:27 WizardCoder 34B Python 
11:35 OpenAI Fine-Tuning 
14:13 OpenAI Scale AI Partnership for Enterprise Fine-Tuning 
15:50  A Survey on Large Language Model based Autonomous Agents 
17:47 Meta AI‚Äôs Sorry Alignment People - 
20:19 AutoGPTQ Transformers Integration - 
22:41 XAI hiring 


AI News:

1. Hugging Face raises $235M from investors, including Salesforce and Nvidia
https://techcrunch.com/2023/08/24/hugging-face-raises-235m-from-investors-including-salesforce-and-nvidia/ 
2. Watch out, Midjourney! Ideogram launches AI image generator with impressive typography https://venturebeat.com/ai/watch-out-midjourney-ideogram-launches-ai-image-generator-with-impressive-typography/ 
3. Seamless m4t https://ai.meta.com/blog/seamless-m4t/ 
4. CodeLlama https://ai.meta.com/blog/code-llama-large-language-model-coding/ 
5. Unnatural Codellama - https://huggingface.co/pharaouk/unnatural_codellama_34B
6. Phind CodeLlama - https://www.phind.com/blog/code-llama-beats-gpt4 
7. WizardCoder 34B Python - https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0
8. OpenAI Fine-Tuning - https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates  https://twitter.com/hwchase17/status/1695466818918650182 
9. OpenAI Scale AI Partnership for Enterprise Fine-Tuning - https://openai.com/blog/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models 
10. A Survey on Large Language Model based Autonomous Agents https://arxiv.org/pdf/2308.11432v1.pdf https://github.com/Paitesanshi/LLM-Agent-Survey 
11. Meta AI‚Äôs Sorry Alignment People - https://twitter.com/agikoala/status/1695125016764157988 
12. AutoGPTQ Transformers Integration - https://huggingface.co/blog/gptq-integration 
13. XAI hiring - https://twitter.com/xai/status/1695477026730479826 



‚ù§Ô∏è If you want to support the channel ‚ù§Ô∏è
Support here:
Patreon - https://www.patreon.com/1littlecoder/
Ko-Fi - https://ko-fi.com/1littlecoder",1littlecoder,2023-08-27T16:04:29Z,2023-09-06T11:45:19Z
99,Tech Talk: IBM CTO says ChatGPT-like large language models financially unsustainable,0kuCv0kd5jk,734,3:8,"For  more:
https://www.cgtn.com/video

IBM stunned the world in 1997 when its Deep Blue computer defeated world chess champion Garry Kasparov, and its supercomputer Watson wowed the tech industry again by winning against two champions on a TV quiz show in 2011.

With ChatGPT now sparking a new round of AI revolution, how will IBM deploy its AI, or generative AI? Xie Dong, CTO at IBM Greater China Group, told CGTN that the cost is extraordinarily high for companies using ChatGPT-like large language models, so introducing targeted AI services and building models that help enterprises complete specific tasks is necessary. 

Subscribe to us on YouTube: https://goo.gl/lP12gA
Download our APP on Apple Store (iOS): https://itunes.apple.com/us/app/cctvnews-app/id922456579?l=zh&ls=1&mt=8
Download our APP on Google Play (Android): https://play.google.com/store/apps/details?id=com.imib.cctv",CGTN,2023-08-27T14:32:35Z,2023-09-06T11:45:19Z
100,Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries,BekDOLm6qBI,132,12:14,"Due to challenges such as hallucination, detecting errors in the output of a given prompt becomes an important challenge.  In this work, we introduce ""diversity measures"" that are domain independent and can be used to measure the uncertainty in the result of a language model.

Preprint: https://arxiv.org/abs/2308.11189 
Source code: https://github.com/lab-v2/diversity_measures
Lab website: https://labs.engineering.asu.edu/labv2  

About the channel:
The Neuro Symbolic Channel provides the tutorials, courses, and research results on one of the most exciting areas in artificial intelligence and machine learning.  With content originally from the AI course taught at Arizona State University, this channel brings you the latest at the intersection of symbolic methods (e.g., logic programming) and deep learning.  Learn about the latest algorithms, Python packages, and progress toward larger goals such as artificial general intelligence (AGI).",Neuro Symbolic,2023-08-27T13:02:29Z,2023-09-06T11:45:19Z
101,Reinforced Self-Training (ReST) for Language Modeling (Paper Review),Knuyalci7GY,112,5:54,"Hi there, I am Jack See, a PhD student who is working on AI models for molecular graph prediction. In this video, I will be going through a very recent paper related to RLHF of ChatGPT-like models. Enjoy yourself and leave any comments!

Paper: https:/_/arxiv.org/abs/2308.08998 (remove the underscore)

Find me on:
-Twitter: https:/_/twitter.com/JackSee47284524 (remove the underscore)
-Linkedin: https:/_/www.linkedin.com/in/jack-see-096212244/ (remove the underscore)


#ai #research #airesearch #machinelearning #deeplearning #education #chatgpt #languagemodeling #naturallanguageprocessing #reinforcementlearning #gpt4  #transformers",Jack See,2023-08-27T12:49:48Z,2023-09-06T11:45:19Z
102,"Generative AI Weekly Research Highlights | 21-27 Aug |Prompt2Model, Codellama, Graph of thoughts....",6Ue9zRJcdbY,356,2:44,"PROMPT2MODEL: Generating Deployable Models from Natural Language Instructions [https://arxiv.org/pdf/2308.12261.pdf]

Code Llama: Open Foundation Models for Code [https://arxiv.org/pdf/2308.12950.pdf]

Bridging the Gap: Deciphering Tabular Data Using Large Language Model [https://arxiv.org/pdf/2308.11891.pdf]

A Survey on Fairness in Large Language Models [https://arxiv.org/pdf/2308.10149.pdf]

Large Language Models for Software Engineering: A Systematic Literature Review [https://arxiv.org/pdf/2308.10620.pdf]

Graph of Thoughts: Solving Elaborate Problems with Large Language Models [https://arxiv.org/pdf/2308.09687.pdf]

A Survey on Large Language Model based Autonomous Agents [https://arxiv.org/pdf/2308.11432.pdf]

Use of LLMs for Illicit Purposes: Threats, Prevention Measures, and Vulnerabilities [https://arxiv.org/pdf/2308.12833.pdf]

#generativeai,#promptengineering,#largelanguagemodels,#openai,#chatgpt,#gpt4,#ai,#abcp,#prompt,#responsibleai,#promptengineer,#chatgptprompt,#anybodycanprompt,#artificialintelligence,", ABCP | Anybody Can Prompt,2023-08-27T03:29:58Z,2023-09-06T11:45:19Z
103,"How Is ChatGPT‚Äôs Behavior Changing over Time? (James Zou, PhD)",Nb2JEO2FJQo,8525,31:56,"Synthetic Intelligence Forum is excited to convene a session about ""How Is ChatGPT‚Äôs Behavior Changing over Time?"" with James Zou, PhD (Assistant Professor of Biomedical Data Science, Stanford University).

Dive deep into the evolving landscape of Generative AI and Large Language Models with Professor Zou as he explains the latest research findings about the evolving behaviours of GPT-3.5 & GPT-4.

Explore the performance variations between March 2023 and June 2023 services on an array of tasks including:

‚Ä¢ Math problems
‚Ä¢ Sensitive questions
‚Ä¢ Opinion surveys
‚Ä¢ Knowledge-intensive multi-hop queries
‚Ä¢ Code generation
‚Ä¢ Medical exams
‚Ä¢ Visual reasoning

It's intriguing to note the dramatic shift in GPT-4's ability to recognize prime numbers within a mere span of three months. And that's just one of the many revelations!

Discover why GPT-3.5 outshined in math by June 2023, the reasons GPT-4 became more reserved about sensitive topics, and the occasional challenges both models faced in generating code.

Prof. Zou explains the concept of pleitropy in the context of Large Language Models and its implications for fine tuning and adapting models for specific domains and tasks.

This comprehensive overview emphasizes the importance of consistent monitoring and evaluation of Generative AI and Large Language Models.

Biography: Professor James Zou is an Assistant Professor of Biomedical Data Science and, by courtesy, of Computer Science and Electrical Engineering at Stanford University. His work focuses on making machine learning more reliable, human-compatible and statistically rigorous, with an emphasis on applications in human disease and health.

He received a Ph.D from Harvard in 2014, and was a member of Microsoft Research, a Gates Scholar at Cambridge and a Simons fellow at UC Berkeley. Professor Zou joined Stanford in 2016 and is a two-time Chan-Zuckerberg Investigator and the faculty director of the university-wide Stanford Data4Health hub. He is also a member of the Stanford AI Lab. His research is supported by the Sloan Fellowship, the NSF CAREER Award, and Google, Amazon and Adobe AI awards. 

Profiles of the host and presenter:
‚Ä¢ Vik Pant, PhD - https://www.linkedin.com/in/vikpant
‚Ä¢ James Zou, PhD - https://www.linkedin.com/in/james-zou-2123a4133

Web profiles of James Zou, PhD:
‚Ä¢ Stanford University - https://profiles.stanford.edu/james-zou
‚Ä¢ Research - https://www.james-zou.com

Join Synthetic Intelligence Forum online:
‚Ä¢ Website - http://www.synthint.org
‚Ä¢ LinkedIn (Page) - https://www.linkedin.com/company/synthint/
‚Ä¢ LinkedIn (Group) - https://www.linkedin.com/groups/12092618/
‚Ä¢ YouTube - https://www.youtube.com/c/SyntheticIntelligenceForum

Special Thanks to our Partner:
‚Ä¢ ET Business Services",Synthetic Intelligence Forum,2023-08-27T02:59:11Z,2023-09-06T11:45:19Z
104,"Protecto LLM Proxy - Data Loss Prevention for AI and Large Language Models Such as ChatGPT, Bard",UPr-58q802M,14,1:11,,Protecto,2023-08-27T02:28:40Z,2023-09-06T11:45:19Z
105,[AUTOML23] Structural Pruning of Large Language Models via Neural Architecture Search,G_fe3limPO8,12,4:57,"Authors: Aaron Klein, Jacek Golebiowski, Xingchen Ma, Valerio Perrone, Cedric Archambeau
https://2023.automl.cc/program/accepted_papers/",AutoMLConf,2023-08-26T10:22:26Z,2023-09-06T11:45:19Z
106,[AUTOML23] Structural Pruning of Large Language Models via Neural Architecture Search Teaser,7r4WwB_6w9s,0,1:4,"Authors: Aaron Klein, Jacek Golebiowski, Xingchen Ma, Valerio Perrone, Cedric Archambeau
https://2023.automl.cc/program/accepted_papers/",AutoMLConf,2023-08-26T10:22:25Z,2023-09-06T11:45:19Z
107,[AUTOML23] Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference,xx-bXUFBa98,26,9:18,"Authors: Chi Wang, Xueqing Liu, Ahmed Hassan Awadallah
https://2023.automl.cc/program/accepted_papers/",AutoMLConf,2023-08-26T10:22:02Z,2023-09-06T11:45:19Z
108,02: Adaptation ‚Äì Large Language Models (NUS CS6101 NUS.WING),SD1zRmmK_QY,80,2:9:31,"00:00 Start
01:20 Week 01 Kahoot!
16:20 LECTURE START - Why Adapt Language Models?
39:10 Probing
1:10:00 Fine-Tuning (Zero-Shot)
1:37:50 Fine-Tuning (Alignment)
1:59:30 Lightweight Fine-Tuning (Video initially not shared properly, see link. https://drive.google.com/file/d/1wfbEPUKWkH5i2jf8wWeStVH-qpc2dCAg/view)

Slides at http://bit.ly/cs6101-t2310-w02
Scribe Notes at http://bit.ly/cs6101-t2310-w02-scribe
Video at http://bit.ly/cs6101-t2310-w02-yt",Web IR / NLP Group at NUS,2023-08-25T22:16:05Z,2023-09-06T11:45:19Z
109,Unlocking the Potential of Large Language Models with ComfyUI | Advanced Tutorial,asMgkwTDAQQ,595,7:20,"In today's video, we'll learn how to harness the power of Large Language Models using ComfyUI. We'll explore loading models, generating stories, extracting tags, and creating related images. We'll utilize the ComfyUI-N-Nodes and ComfyUI-Custom-Scripts libraries to enhance ComfyUI's capabilities. The process involves installing dependencies, configuring GPT nodes, utilizing custom prompts, and much more


*** Links from the Video Tutorial ***
ComfyUI-N-Nodes for GPT support: https://github.com/Nuked88/ComfyUI-N-Nodes
ComfyUI-Custom-Scripts by pythongosssss : https://github.com/pythongosssss/ComfyUI-Custom-Scripts
CUDA Download: https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64
W64devkit : https://github.com/skeeto/w64devkit/releases
Bin Models: https://huggingface.co/TheBloke

Command for install llama-cpp-python cpu only ..\..\python_embeded\python.exe -s -m pip install llama-cpp-python",DreamingAI,2023-08-25T22:00:01Z,2023-09-06T11:45:19Z
110,Code Llama powered Gradio App for Coding: Runs on CPU,AJOhV6Ryy5o,3602,42:8,"In this video, I'll walk you through how I harnessed the power of Code Llama, a cutting-edge large language model designed specifically for coding tasks. Code Llama is at the forefront of publicly available language models, offering incredible potential to streamline workflows for experienced developers and democratize coding education for newcomers.

I'll demonstrate how I took a quantized version of Code Llama and seamlessly integrated it into a Gradio app, unlocking its remarkable coding capabilities for everyone to use. With Langchain, I'll show you how to craft prompts and chains, harnessing the full potential of Code Llama for coding solutions, all running efficiently on a CPU.

Don't miss out on this opportunity to supercharge your coding journey. Watch the video now and let's dive into the world of Code Llama! 

LLM Playlist: https://www.youtube.com/playlist?list=PLrLEqwuz-mRIdlmvhddd7nGiNh8exqsBG
AI Anytime's GitHub: https://github.com/AIAnytime
The Bloke HF: https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGML/tree/main
Llama 2 Meta AI: https://ai.meta.com/llama/
Code Llama: https://ai.meta.com/blog/code-llama-large-language-model-coding/
CTransformers: https://github.com/marella/ctransformers

#generativeai #python #ai",AI Anytime,2023-08-25T15:31:34Z,2023-09-06T11:45:19Z
111,Create a Large Language Model from Scratch with Python ‚Äì Tutorial,UU1WVnMk4E8,114272,5:43:41,"Learn how to build your own large language model, from scratch. This course goes into the data handling, math, and transformers behind large language models. You will use Python.

‚úèÔ∏è Course developed by @elliotarledge 

üíª Code and course resources: https://github.com/Infatoshi/fcc-intro-to-llms

Join Elliot's Discord server: https://discord.gg/pV7ByF9VNm

‚≠êÔ∏è Contents ‚≠êÔ∏è
(0:00:00) Intro
(0:03:25) Install Libraries
(0:06:24) Pylzma build tools
(0:08:58) Jupyter Notebook
(0:12:11) Download wizard of oz
(0:14:51) Experimenting with text file
(0:17:58) Character-level tokenizer
(0:19:44) Types of tokenizers
(0:20:58) Tensors instead of Arrays
(0:22:37) Linear Algebra heads up
(0:23:29) Train and validation splits
(0:25:30) Premise of Bigram Model
(0:26:41) Inputs and Targets
(0:29:29) Inputs and Targets Implementation
(0:30:10) Batch size hyperparameter
(0:32:13) Switching from CPU to CUDA
(0:33:28) PyTorch Overview
(0:42:49) CPU vs GPU performance in PyTorch
(0:47:49) More PyTorch Functions
(1:06:03) Embedding Vectors
(1:11:33) Embedding Implementation
(1:13:06) Dot Product and Matrix Multiplication
(1:25:42) Matmul Implementation
(1:26:56) Int vs Float
(1:29:52) Recap and get_batch
(1:35:07) nnModule subclass
(1:37:05) Gradient Descent
(1:50:53) Logits and Reshaping
(1:59:28) Generate function and giving the model some context
(2:03:58) Logits Dimensionality
(2:05:17) Training loop + Optimizer + Zerograd explanation
(2:13:56) Optimizers Overview
(2:17:04) Applications of Optimizers
(2:18:11) Loss reporting + Train VS Eval mode
(2:32:54) Normalization Overview
(2:35:45) ReLU, Sigmoid, Tanh Activations
(2:45:15) Transformer and Self-Attention
(2:46:55) Transformer Architecture
(3:17:54) Building a GPT, not Transformer model
(3:19:46) Self-Attention Deep Dive
(3:25:05) GPT architecture
(3:27:07) Switching to Macbook
(3:31:42) Implementing Positional Encoding
(3:36:57) GPTLanguageModel initalization
(3:40:52) GPTLanguageModel forward pass
(3:46:56) Standard Deviation for model parameters
(4:00:50) Transformer Blocks
(4:04:54) FeedForward network
(4:07:53) Multi-head Attention
(4:12:49) Dot product attention
(4:19:43) Why we scale by 1/sqrt(dk)
(4:26:45) Sequential VS ModuleList Processing
(4:30:47) Overview Hyperparameters
(4:32:14) Fixing errors, refining
(4:34:01) Begin training
(4:35:46) OpenWebText download and Survey of LLMs paper
(4:37:56) How the dataloader/batch getter will have to change
(4:41:20) Extract corpus with winrar
(4:43:44) Python data extractor
(4:49:23) Adjusting for train and val splits
(4:57:55) Adding dataloader
(4:59:04) Training on OpenWebText
(5:02:22) Training works well, model loading/saving
(5:04:18) Pickling
(5:05:32) Fixing errors + GPU Memory in task manager
(5:14:05) Command line argument parsing
(5:18:11) Porting code to script
(5:22:04) Prompt: Completion feature + more errors
(5:24:23) nnModule inheritance + generation cropping
(5:27:54) Pretraining vs Finetuning
(5:33:07) R&D pointers
(5:44:38) Outro

üéâ Thanks to our Champion and Sponsor supporters:
üëæ davthecoder
üëæ jedi-or-sith
üëæ ÂçóÂÆÆÂçÉÂΩ±
üëæ Agust√≠n Kussrow
üëæ Nattira Maneerat
üëæ Heather Wcislo
üëæ Serhiy Kalinets
üëæ Justin Hual
üëæ Otis Morgan

--

Learn to code for free and get a developer job: https://www.freecodecamp.org

Read hundreds of articles on programming: https://freecodecamp.org/news",freeCodeCamp.org,2023-08-25T15:09:55Z,2023-09-06T11:45:19Z
112,How Large Language Models are Transforming Machine-Paraphrased Plagiarism (EMNLP Conference 2022),vA0sawFKSR0,75,12:55,"Jan Philip Wahle presents the paper ''How Large Language Models are Transforming Machine-Paraphrased Plagiarism'' by J. P. Wahle, T. Ruas, F. Kirstein, and B. Gipp. The paper was published in the proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP).

Find the paper preprint on ArXiv: https://arxiv.org/abs/2210.03568
Or download the PDF of the paper directly: https://gipplab.org/wp-content/papercite-data/pdf/wahle2022d.pdf

ABSTRACT
The recent success of large language models for text generation poses a severe threat to academic integrity, as plagiarists can generate realistic paraphrases indistinguishable from original work. However, the role of large autoregressive transformers in generating machine paraphrased plagiarism and their detection is still developing in the literature. This work explores T5 and GPT-3 for machine-paraphrase generation on scientific articles from arXiv, student theses, and Wikipedia. We evaluate the detection performance of six automated solutions and one commercial plagiarism detection software and perform a human study with 105 participants regarding their detection performance and the quality of generated examples. Our results suggest that large models can rewrite text humans have difficulty identifying as machine-paraphrased (53% mean acc.). Human experts rate the quality of paraphrases generated by GPT-3 as high as original texts (clarity 4.0/5, fluency 4.2/5, coherence 3.8/5). The best-performing detection model (GPT3) achieves a 66% F1-score in detecting paraphrases. We make our code, data, and findings publicly available for research purposes.",Gipp Lab at Uni G√∂ttingen,2023-08-25T12:45:04Z,2023-09-06T11:45:19Z
113,Professional Certification Benchmark Dataset The First 500 Jobs for Large Language Models,4TKExbbcqZg,4,22:31,"Professional Certification Benchmark Dataset: The First 500 Jobs for Large Language Models

David Noever and Matt Ciolino, PeopleTec, USA

Abstract

The research creates a professional certification survey to test large language models and evaluate their employable skills. It compares the performance of two AI models, GPT-3 and Turbo-GPT3.5, on a benchmark dataset of 1149 professional certifications, emphasizing vocational readiness rather than academic performance. 

Keywords

Transformers, Text Generation, Generative Pre-trained Transformers, GPT

Full Text : https://aircconline.com/csit/papers/vol13/csit131211.pdf
Abstract URL : https://aircconline.com/csit/abstract/v13n12/csit131211.html
Volume URL : https://airccse.org/csit/V13N12.html

#transformers #textgeneration #gpt #naturallanguageprocessing",Computer Science & IT Conference Proceedings,2023-08-25T12:46:24Z,2023-09-06T11:45:19Z
114,Bubo Gpt | Advanced Large Language Model | Chat GPT,dVszwFSsM-w,182,3:3,"Website link : https://bubo-gpt.github.io/

BuboGPT, a cutting-edge multimodal large language model developed by Bite Dance Inc. This exciting project is making waves in the AI community, and you can explore its capabilities right now by checking out the code available on our GitHub page.

BuboGPT goes beyond traditional language models by seamlessly integrating text, images, and audio inputs. It possesses a remarkable skill ‚Äì the ability to bridge its responses with visual and auditory elements. This means it can not only understand but also interact intelligently with image and audio data, setting it apart from conventional AI models.

Imagine providing audio to our chatbot. BuboGPT can discern the distinctive sounds within it. For instance, listen to an audio clip where the distinct sounds of dishes clinking and kitchen activities are evident. It's like you're right there in a bustling kitchen, with the ambiance painting a vivid domestic scene.

Present an image to BuboGPT, and it will astound you with its vivid descriptions. For instance, consider an image of a cat lounging on an orange float in a swimming pool, sporting stylish sunglasses. BuboGPT brings the image to life with its imaginative portrayal.",Global Techtricks,2023-08-25T10:52:56Z,2023-09-06T11:45:19Z
115,CODE LLAMA - THE BEST CODING MODEL IS HERE!,qFiz1cYGgB0,18696,8:5,"In this video, we are going to explore the newly released coding model from Meta, Code-Llama. Code Llama is an AI model built on top of Llama 2, fine-tuned for generating and discussing code. It‚Äôs free for research and commercial use.

#codellama #llama2 #metaai 
‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨ CONNECT ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
‚òï Buy me a Coffee: https://ko-fi.com/promptengineering
|üî¥ Support my work on Patreon: Patreon.com/PromptEngineering
ü¶æ Discord: https://discord.com/invite/t4eYQRUcXB
‚ñ∂Ô∏èÔ∏è Subscribe: https://www.youtube.com/@engineerprompt?sub_confirmation=1
üìß Business Contact: engineerprompt@gmail.com
üíºConsulting: https://calendly.com/engineerprompt/consulting-call
‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
LINKS:
Blogpost: https://about.fb.com/news/2023/08/code-llama-ai-for-coding/
‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨
All Interesting Videos:
Everything LangChain: https://www.youtube.com/playlist?list=PLVEEucA9MYhOu89CX8H3MBZqayTbcCTMr

Everything LLM: https://youtube.com/playlist?list=PLVEEucA9MYhNF5-zeb4Iw2Nl1OKTH-Txw

Everything Midjourney: https://youtube.com/playlist?list=PLVEEucA9MYhMdrdHZtFeEebl20LPkaSmw

AI Image Generation: https://youtube.com/playlist?list=PLVEEucA9MYhPVgYazU5hx6emMXtargd4z",Prompt Engineering,2023-08-25T06:14:25Z,2023-09-06T11:45:19Z
116,Code Llama: Meta&#39;s State-of-the-Art LLM for Coding,U24mPUHXuv8,1411,5:3,"Links: 
https://ai.meta.com/blog/code-llama-large-language-model-coding/
https://labs.perplexity.ai/",Developers Digest,2023-08-25T00:56:13Z,2023-09-06T11:45:19Z
117,Webinar: Maximizing the Power of Gaudi2: Accelerating Generative AI and Large Language Models,3Ri6Fnd_6so,71,40:45,"As the world of artificial intelligence continues to push boundaries, Gaudi2, Habana‚Äôs advanced deep learning accelerator, has emerged as a game-changing solution. In this webinar, our team of experts will guide you through the steps to easily enable Gaudi2 to supercharge your LLM-based applications with performance, productivity and efficiency.

Key Topics Covered:

Introduction to Gaudi2 AI Processor: Gain a comprehensive understanding of the Gaudi architecture, and how to take advantage of Habana‚Äôs large catalog of optimized models.
Model Migration: We‚Äôll show you how to quickly migrate models from other platforms with the addition of only a few lines of code.
Accelerating LLM Training: Discover how Gaudi2 uses DeepSpeed and Hugging Face-based models to accelerate LLM training, including fine-tuning a model from the Hugging Face Optimum Habana repository.
High-Performance Inference: Learn how Gaudi2 can deliver lightning-fast, real-time generative AI and LLM inference results.
Whether you‚Äôre a data scientist, AI researcher, developer, or technology enthusiast, this webinar will equip you with the knowledge and insights necessary to tap into the benefits of the Gaudi2 AI processor and empower your LLM-based projects with unparalleled speed and efficiency.",Habana Labs,2023-08-24T21:57:46Z,2023-09-06T11:45:19Z
118,Transform Customer Experience with Large language Models and Generative AI - Demo,cT9HjNhKgvA,67,15:32,"Check out this Demo on Transforming your Customer Experience with Large Language Models & Generative AI, presented by Onliners Chris Theriault & David Barentsen! 
-
Visit: https://www.obsglobal.com/
Follow us on LinkedIn: https://www.linkedin.com/company/online-business-systems/
Like us on Facebook: https://www.facebook.com/OBSGlobal
Follow us on Instagram: https://www.instagram.com/obs_global/
Subscribe to Online Business Systems: https://www.youtube.com/@UCpB4PnAD2VGv9mb0jwaSl-Q 
-
#llm #AI #genai  #cx #customerexperience",Online Business Systems,2023-08-24T21:04:21Z,2023-09-06T11:45:19Z
119,"How To Install Code Llama Locally - 7B, 13B, &amp; 34B Models! (LLAMA 2&#39;s NEW Coding LLM)",OQKmYxsvp9g,14817,12:41,"Welcome to the ultimate guide on how to install Code Llama locally! In this comprehensive video, we introduce you to Code Llama, a cutting-edge large language model that's the product of meticulous fine-tuning from the robust foundation of Llama-2 base models. With Code Llama's emergence in three distinct flavors‚Äîvanilla, Instruct, and Python‚Äîyou'll discover tailored solutions catering to various coding scenarios and user preferences.

üî• Become a Patron (Private Discord): https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 

[MUST WATCH VIDEOS]:
How To Install Llama 2 Locally and On Cloud - 7B, 13B, & 70B Models! - https://youtu.be/SbuhznykQBg?si=jj6FUAkAug-PIrrz
How To Install UNCENSORED Llama 2 Locally - 7B, 13B, & 70B Models! - https://youtu.be/RpGXhpeH668?si=-JFY_g_4v1PjFv2Q
LlamaGPT: Access Uncensored LLAMA 2 - Self-Hosted, Offline, Private, and FREE! (Install Tutorial) - https://youtu.be/NZFpEEpg1u4?si=_VEl8X16bJcpqQy0

[Links Used]:
How to Install TextGen WebUI - Install ANY LLMs IN Minutes Locally! (Oobabooga) - https://youtu.be/efoJ9GUOymY?si=c--CY-2W06xIKUV7
Code LLama Blog Post: https://ai.meta.com/blog/code-llama-large-language-model-coding/?utm_source=twitter&utm_medium=organic_social&utm_campaign=codellama&utm_content=gif
Download Model From Meta: https://ai.meta.com/resources/models-and-libraries/llama-downloads/
Hugging Face Model Cards: https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GPTQ
Research Paper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/

üî• Key Highlights:
- Unveiling Code Llama's impressive dimensions: 7 billion, 13 billion, and a remarkable 34 billion parameters for vanilla, Instruct, and Python models respectively.
- A closer look at the locally adept smaller model configuration that smoothly functions with just a capable GPU.

Dive into the video as we delve deeper:
1. Mastering Performance Metrics:
Discover how CodeLlama-python has outshone GPT-3.5 and even achieved a remarkable score of 53.7 on the HumanEval benchmark, surpassing GPT-3.5's performance at 48.1. We'll also explore its impressive performance on the MBPP task, achieving a score of 56.2 compared to GPT-3.5's score of 52.2.
2. Toppling Competitors:
Explore how Code Llama surpasses prominent models like PaLM-Coder and Codex (GitHub copilot model) as well as various open-source models including StarCoder. We'll delve into what makes Code Llama the standout choice for AI-powered coding assistance.
3. Unique Training Mechanism:
Unravel the secrets behind Code Llama's training process, driven by the innovative ""infilling objective."" Learn how it empowers the model to generate code within specific contexts, revolutionizing code generation and autoregressive capabilities.
4. Augmenting Training Data:
Discover the synthetic data derived from the Self-Instruct approach, comprising 60,000 coding interview questions, unit tests for code solutions, and the meticulous filtering process that retains only high-quality examples.
5. Long Context Fine-Tuning Strategies:
Explore how Code Llama benefits from long context fine-tuning strategies, utilizing 4,000-token and 16,000-token contexts to maintain consistency across different lengths.
6. Embracing AI-Powered Coding:
Witness the future of coding assistance as Code Llama showcases its potential through finesse in code generation and context comprehension. Backed by impressive benchmark performances and innovative training methodologies, it's truly a remarkable leap forward in AI-powered coding assistance.

Don't miss out on this invaluable insight into the world of Code Llama and AI-assisted coding! Like, subscribe, and share this video to support our channel and stay updated with the latest advancements in technology.

üöÄ Additional Tags & Keywords: Code Llama, Local Installation, AI-Powered Coding, Llama-2 Base Models, Vanilla, Instruct, Python, Performance Metrics, HumanEval Benchmark, MBPP Task, Coding Assistance, Training Process, Infilling Objective, Self-Instruct Approach, Long Context Fine-Tuning, AI-Powered Coding Assistant.
üì¢ Hashtags: #CodeLlama #AIcoding #LocalInstallation #CuttingEdgeAI #CodingAssistance #AIAdvancements

Join us on other platforms for more exciting content and updates:

Thank you for watching and being a part of our coding journey! Your support drives us to explore new horizons in the world of AI-powered coding.",WorldofAI,2023-08-24T19:31:19Z,2023-09-06T11:45:19Z
120,"AutoGPT, LangChain e il Futuro dei Large Language Models",f00hL828zgw,0,P0D,"Una diretta esclusiva dedicata alla rivoluzione portata dai Large Language Models (LLM) e le evoluzioni AutoGPT e LangChain. Questi strumenti, avvalendosi della potenza degli agenti autonomi, hanno la capacit√† di trasformare compiti altamente complessi in processi fluidi e totalmente automatizzati.

Inizieremo con una panoramica sugli AI Agents, per poi approfondire le specifiche di LangChain e AutoGPT. Faremo delle Live Demo per mostrare le loro capacit√† e le differenze chiave tra loro. Rifletteremo insieme sulle possibili applicazioni future, sul modo in cui questi modelli possono e potranno influenzare le nostre quotidiane interazioni e sulle implicazioni a lungo termine di tali tecnologie.

In un mondo in cui l‚Äôintelligenza artificiale sta ridefinendo i confini del possibile, √® sempre pi√π importante essere informati e consapevoli delle nuove frontiere dell‚ÄôAI ed √® fondamentale per chiunque desideri diventare un professionista nel settore.

Scopri tutti i corsi Data Masters: https://datamasters.it/corsi/

üì≤ Iscriviti al canale YOUTUBE selezionando l'icona a forma di campana per rimanere sempre aggiornato sui nuovi video pubblicati!

üì≤ Iscriviti al server DISCORD di DataMasters (https://launchpass.com/datamasters) per accedere alla pi√π grande Community italiana della Data Science!

Seguici sui nostri canali:
DISCORD: https://launchpass.com/datamasters
LINKEDIN: https://www.linkedin.com/company/data...
FACEBOOK: https://www.facebook.com/datamasters
INSTAGRAM: https://www.instagram.com/datamasters...
TWITTER: https://twitter.com/datamasters_it
e visita https://www.datamasters.it

#datamasters #ai #chatgpt #autogpt #langchain #llm #largelanguagemodels #openai #machinelearning  #artificialintelligence #datascience #intelligenzaartificiale",DataMasters,2023-08-24T19:00:40Z,2023-09-06T11:45:19Z
121,Will Meta&#39;s New AI Coding Model Eliminate Human Developers?,C4YQcFYHxsc,803,2:28,"Meta just unveiled Code Llama, the state-of-the-art language model designed to revolutionize coding assistance. Learn about its capabilities, performance, and the impact it's set to make in the developer community.

üìú Whitepaper: https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/
üîó GitHub Repo: https://github.com/facebookresearch/codellama
üì∞ Meta Blog Post: https://ai.meta.com/blog/code-llama-large-language-model-coding/",CAPS LOCK DAVE,2023-08-24T18:02:56Z,2023-09-06T11:45:19Z
122,Key Challenges in Building Enterprise LLM Applications | Large Language Models in the Enterprise,NjtwlK4QGEU,243,1:11:30,"üíº Learn to build LLM-powered apps in just 40 hours with our Large Language Models bootcamp: https://hubs.la/Q01ZZGL-0

_

As enterprises move beyond ChatGPT, Bard, and 'demo applications' of large language models, product leaders, and engineers are running into challenges. The magical experience we observe on content generation and summarization tasks using ChatGPT is not replicated on custom LLM applications built on enterprise data. This frustration can lead to one (or a mix) of the following reactions:

- LLMs are yet another hype or a fad at best.
- LLMs are good only for summarization and content generation tasks; They are not suitable for enterprise applications.
- Building LLM applications is significantly harder than just using an off-the-shelf foundation model.

The third point is the closest to reality. Enterprise LLM applications are easy to imagine and build a demo out of, but somewhat challenging to turn into a business application. The complexity of datasets, training costs, cost of token usage, response latency, context limit, fragility of prompts, and repeatability are some of the problems faced during product development.

As the Chief Data Scientist at Data Science Dojo, Raja has led a team of extremely talented data scientists and software engineers to deliver multiple enterprise applications of large language models. In this live talk, Raja will go over the challenges faced by his team while building these mission-critical applications and how the team overcame those challenges.

_

Table of Contents:
0:00 ‚Äì Introduction
1:14 ‚Äì Agenda
1:27 ‚Äì Misaligned Behavior 
10:15 ‚Äì Context Length
13:57 ‚Äì Cost
21:12 ‚Äì Latency
31:46 ‚Äì Reproducibility 
34:37 ‚Äì Evaluation
41:33 QnA

#largelanguagemodels #llms #generativeai",Data Science Dojo,2023-08-24T15:45:43Z,2023-09-06T11:45:19Z
123,David Spivak on Applied Category Theory and Large Language Models,a_L1ZktKMcI,69,1:14:27,"An interview ranging over what applied category theory is, including many thoughts about its relevance for LLMs.",Turing Transparency Initiative,2023-08-24T15:38:13Z,2023-09-06T11:45:19Z
124,LLM Explained Simply |  What is LLM?,uTSGHBsvplg,1741,6:58,"Simple and easy explanation of LLM or Large Language Model in less than 5 minutes. In this short video,  you will build an intuition of how a large language model works using animation and simple storytelling. This is the explanation that even a high school student can understand easily.

Neural network simple explanation: https://www.youtube.com/watch?v=ER2It2mIagI

Do you want to learn technology from me? Check https://codebasics.io/?utm_source=description&utm_medium=yt&utm_campaign=description&utm_id=description for my affordable video courses.

Need help building software or data analytics/AI solutions? My company https://www.atliq.com/ can help. Click on the Contact button on that website.

üé• Codebasics English Channel: https://www.youtube.com/c/codebasics
#Ô∏è‚É£ Social Media #Ô∏è‚É£
üîó Discord:  https://discord.gg/r42Kbuk
üì∏ Dhaval's Personal Instagram: https://www.instagram.com/dhavalsays/
üì∏ Instagram: https://www.instagram.com/codebasicshub/
üîä Facebook: https://www.facebook.com/codebasicshub
üì± Twitter: https://twitter.com/codebasicshub
üìù Linkedin (Personal): https://www.linkedin.com/in/dhavalsays/
üìù Linkedin (Codebasics): https://www.linkedin.com/company/codebasics/",codebasics Hindi,2023-08-24T13:30:07Z,2023-09-06T11:45:19Z
125,Discovering Willy 1 and Willy 2: Advanced AI Language Models for Creative Content &amp; Problem Solving,iV2Zu7kz8gA,12,6:51,"In this video, we delve into the groundbreaking AI language models, Willy 1 and Willy 2, developed by Stability AI. These cutting-edge models are based on LLaMA 65B and LLaMA 2 70B, respectively, and have been fine-tuned using a novel synthetically-generated dataset. Learn about the diverse data they were trained on, including text from books, articles, websites, and code from GitHub and Stack Overflow. We explore their remarkable capabilities, from comprehensive question answering to generating creative content like poems, code, scripts, and more.

Discover why Willy 1 and Willy 2 are at the forefront of AI research, outperforming other models on reasoning tasks and how they have the potential to revolutionize customer service, marketing, education, and problem-solving in science and engineering. Uncover their limitations, which include being under development and the importance of mitigating potential inaccuracies in critical tasks.

Join us as we explore the accuracy of these models for different tasks, their competition landscape in the AI field, and the future potential of AI language models. If you're curious about the latest advancements in AI and how Willy 1 and Willy 2 are shaping the future of creative content and problem-solving, this video is a must-watch!

#AI #ArtificialIntelligence #LanguageModels #Willy1 #Willy2 #StabilityAI #CreativeContent #ProblemSolving #AdvancedAI #MachineLearning #LLMs",TG Online Solutions and Services,2023-08-24T12:30:32Z,2023-09-06T11:45:19Z
126,How to Get the Best of Commercial &amp; Open Source Large Language Models While Protecting Corporate IP,Pk-0JLj3dCY,122,1:1:56,"In the rapidly evolving world of ChatGPT and Large Language Models (LLMs), businesses are understandably apprehensive. Numerous potential hazards and hurdles exist such as: 

Unrealistic expectations of LLMs as a magic solution to managing corporate content without requisite human involvement 
Difficulty distinguishing between creative outputs and fabricated responses (hallucinations)
Decisions around training models: balancing usefulness with the threat of exposing trade secrets or other proprietary knowledge 
Absence of clear audit trails and citation sources 
The risk of generating responses misaligned with company policies or brand image 
Potential financial burden of proprietary LLMs and related enterprise software platforms

In this webinar, we will examine a structured approach to harvest, utilize, and protect corporate knowledge resources. We will explore how both commercial and open-source large language models can be leveraged to deliver precise conversational responses without jeopardizing intellectual property.",Earley Information Science,2023-08-24T12:19:30Z,2023-09-06T11:45:19Z
127,How To CONVERT LLMs into GPTQ Models in 10 Mins - Tutorial with ü§ó Transformers,RlCQTtIYajM,5935,9:8,"In this tutorial, You'll learn everything from:

1. Converting a Pytorch LLM into GPTQ Models
2. Push the newly created GPTQ Models to HF Transformers
3. Load the GPTQ models into Hugging Face Transformers for Inference

Blogpost https://huggingface.co/blog/gptq-integration
Colab https://colab.research.google.com/drive/1_TIrmuKOFhuRRiTWN94iLKUFu6ZX4ceb?usp=sharing

‚ù§Ô∏è If you want to support the channel ‚ù§Ô∏è
Support here:
Patreon - https://www.patreon.com/1littlecoder/
Ko-Fi - https://ko-fi.com/1littlecoder",1littlecoder,2023-08-24T06:30:13Z,2023-09-06T11:45:19Z
128,Large Language Models(LLMs) - The Ultimate Comparison 2023,px5L7nwn90U,225,4:29,"llm rankings
Facebook large language model
Google large language model
OpenAI''s large language model

In this video, I will be showing you the top 3 large language models(LLMs) that could disrupt the tech industry anytime soon from now. 

Subscribe to our channel üëâ https://shorturl.at/uCET4

If you enjoyed this video be sure to give it a like and subscribe for more! 

ChatGPT: Here's how to get a job at Google, Meta, Tesla ...
https://youtu.be/yjr2je3YihU

ChatGPT generates NFTs ! New Passive Income With ChatGPT !
https://youtu.be/ULqdnlee4CM

I Lost $XXX after OpenAI's Secret Key LEAKED !!
https://youtu.be/nE5kaOKz2bw

Web Scraping using ChatGPT | Coded by ChatGPT
https://youtu.be/MZrW-jbcmcI

Flutter ChatGPT using OpenAI's GPT-3 | Flutter Chatbot
https://youtu.be/7AsHNDb0Vdo

How to Manage State Using Flutter GetX | Flutter State Managementhttps://youtu.be/g4NOAWyiMkM

How to Manage State Using Flutter Provider | Flutter State Managementhttps://youtu.be/ep6PC6QHpEc

How to Solve Vertical viewport was given unbounded height | Flutter Common Error
https://youtu.be/HNhFtmucc2w

Installation & Configuration | Flutter Firebase Tutorial #1
 https://youtu.be/IAVIPbZI5GE

Firebase RealTime Database (CRUD) | Flutter Firebase Tutorial #3 
https://youtu.be/4iQeSN1zGs4

How To Create A Flutter Table Calendar In Just 5 Minutes!
https://youtu.be/6Gxa-v7Zh7I

Dropdown in Flutter for creating flexible, reusable user interfaces
https://youtu.be/on4C74-dzZo

Object-oriented Programming in Dart 
https://www.youtube.com/playlist?list=PLuJCX405YaLnQesHWqvrxqoSHzgcR5Asv

Flutter Project Ideas 
https://www.youtube.com/playlist?list=PLuJCX405YaLkk2Ejg-pmafjH4p4xYHjHC

Flutter Package Tutorials 
https://www.youtube.com/playlist?list=PLuJCX405YaLkscz22os2PrXRtJQbUDiId

#llm #largelanguagemodels #openai #chatgpt",AI with Flutter,2023-08-24T05:15:04Z,2023-09-06T11:45:19Z
129,üéôÔ∏èThe Future of AI and Large Language Models in Financial Services üí∞,_HP-rj4ydD8,10,10:13,"In this video, we uncover the issues financial brand leaders need to consider when utilizing AI, and how to avoid the 'shiny object syndrome.'üöÄ

We also talk about the challenges organizations face when implementing AI and how they can overcome these to realize their potential. It's important to avoid getting caught up in the hype, buying tools without a clear idea of how they will solve real problems. 

So, how do we tackle this? We always need to start with a strategy and establish our priorities.

We discuss the importance of data, how it forms the cornerstone of any AI initiative and how even large institutions struggle to have their data environments in order.üîê

We discuss a simple first step you can take on your AI journey, even if it's just in your personal daily workflow. Want a small win? Try running a complicated email or report through a language model like GPT. 

üîó Link to the full video: https://youtu.be/17eEQ9_PQB8",Digital Growth Institute,2023-08-24T05:00:25Z,2023-09-06T11:45:19Z
130,Â§ßËØ≠Ë®ÄÊ®°ÂûãÂæÆË∞É‰πãÈÅì1‚Äî‚Äî‰ªãÁªç,3apAPNXogAQ,634,3:,"Â§ßËØ≠Ë®ÄÊ®°ÂûãÂæÆË∞É‰πãÈÅì1‚Äî‚Äî‰ªãÁªç

#Â§ßËØ≠Ë®ÄÊ®°ÂûãÂæÆË∞É‰πãÈÅì

Ê¨¢ËøéÊù•Âà∞Áî±Sharon Zhou‰∏ªËÆ≤ÁöÑ„ÄäÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂæÆË∞É‰πãÈÅì„ÄãËØæÁ®ã„ÄÇËøôÈó®ËØæÁ®ãÂ∞ÜÊïô‰Ω†Â¶Ç‰ΩïÂú®Ëá™Â∑±ÁöÑÊï∞ÊçÆ‰∏äËøõ‰∏ÄÊ≠•ËÆ≠ÁªÉÂºÄÊ∫êLLM„ÄÇ

ËôΩÁÑ∂‰Ω†ÂèØËÉΩÂ∑≤ÁªèÁü•ÈÅìÂ¶Ç‰ΩïÊèêÁ§∫‰∏Ä‰∏™Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºå‰ΩÜËøôÈó®ËØæÁ®ã‰ºöÊ∑±ÂÖ•ËÆ≤Ëß£Âè¶‰∏Ä‰∏™ÈáçË¶ÅÂ∑•ÂÖ∑ÔºöÂæÆË∞É„ÄÇ

ÈÄöËøáÂæÆË∞ÉÔºå‰Ω†ÂèØ‰ª•‰ΩøLLMÊõ¥Âä†Á¨¶Âêà‰Ω†ÁöÑÈúÄÊ±Ç„ÄÇ‰Ω†Ëøò‰ºö‰∫ÜËß£Âà∞ÊåáÁ§∫ÂæÆË∞ÉËøôÁßçÁâπÂÆöÊñπÊ≥ïÔºåÂÆÉÊòØÂ¶Ç‰ΩïÊääGPT3ÂèòÊàêChatGPTÁöÑÔºåËøôÁßçÊñπÊ≥ïÊïôLLMÂ¶Ç‰ΩïÈÅµÂæ™ÊåáÁ§∫„ÄÇ

Ê≠§Â§ñÔºå‰Ω†Ëøò‰ºöÂ≠¶‰π†Â¶Ç‰Ωï‰∏∫‰Ω†ÁöÑLLMÂáÜÂ§áÊï∞ÊçÆ„ÄÅËÆ≠ÁªÉÊ®°ÂûãÂπ∂Âú®‰ª£Á†Å‰∏≠ËØÑ‰º∞ÂÆÉ„ÄÇ

Ëøô‰∏™ËØæÁ®ãÈÄÇÂêàÁÜüÊÇâPythonÁöÑ‰∫∫Â≠¶‰π†Ôºå‰ΩÜË¶ÅÂÆåÂÖ®ÁêÜËß£ÊâÄÊúâÁöÑ‰ª£Á†ÅÔºåÊúÄÂ•ΩËøòÊúâÊ∑±Â∫¶Â≠¶‰π†ÁöÑÂü∫Á°ÄÁü•ËØÜ„ÄÇÂú®Ëøô‰∏™Áü≠ÊúüËØæÁ®ã‰∏≠Ôºå‰Ω†Â∞ÜÊ∑±ÂÖ•‰∫ÜËß£Â¶Ç‰ΩïÈÄöËøáÂú®Ëá™Â∑±ÁöÑÊï∞ÊçÆ‰∏äÂæÆË∞ÉÁé∞ÊúâÁöÑLLMÊù•ÊûÑÂª∫Ëá™Â∑±ÁöÑLLM„ÄÇÂºÄÂßãÂ≠¶‰π†ÂêßÔºÅ



ËØæÁ®ãÂú∞ÂùÄÔºöhttps://www.deeplearning.ai/short-courses/finetuning-large-language-models/",ÂÆùÁéâÁöÑÊäÄÊúØÂàÜ‰∫´,2023-08-24T02:22:28Z,2023-09-06T11:45:19Z
131,Exploring the Boundaries of Chinese Creative Writing Capabilities in Large Language Models,uK3tr4uosnc,36,24:55,"Alex TSANG Cheuk Yin, Technological and Higher Education Institute of Hong Kong, and NG Kwong-Tai, National Tsing Hua University, Taiwan","School of General Education and Languages, THEi",2023-08-24T02:00:10Z,2023-09-06T11:45:19Z
132,ProAgent: Building Proactive Cooperative AI with Large Language Models,OdEtr1CE3Bc,4,16,"#blacksstopkillingblackschallenge_360 #leadership #futureofautomation 

Building AIs with adaptive behaviors in human-AI cooperation stands as a pivotal focus in AGI research. Current methods for developing cooperative agents predominantly rely on learning-based methods, where policy generalization heavily hinges on past interactions with specific teammates. These approaches constrain the agent's capacity to recalibrate its strategy when confronted with novel teammates. We propose \textbf{ProAgent}, a novel framework that harnesses large language models (LLMs) to fashion a \textit{pro}active \textit{agent} empowered with the ability to anticipate teammates' forthcoming decisions and formulate enhanced plans for itself. ProAgent excels at cooperative reasoning with the capacity to dynamically adapt its behavior to enhance collaborative efforts with teammates. Moreover, the ProAgent framework exhibits a high degree of modularity and interpretability, facilitating seamless integration to address a wide array of coordination scenarios. Experimental evaluations conducted within the framework of \textit{Overcook-AI} unveil the remarkable performance superiority of ProAgent, outperforming five methods based on self-play and population-based training in cooperation with AI agents. Further, when cooperating with human proxy models, its performance exhibits an average improvement exceeding 10\% compared to the current state-of-the-art, COLE. The advancement was consistently observed across diverse scenarios involving interactions with both AI agents of varying characteristics and human counterparts. These findings inspire future research for human-robot collaborations. For a hands-on demonstration, please visit \url{this https URL}.",Bumlife2Bomblife Management,2023-08-23T23:35:07Z,2023-09-06T11:45:19Z
133,What is the future of Education in the midst of Large Language Models?,2_gB_xEIQro,29,9:34,"Discover the remarkable impact of large language models on education in this comprehensive video! Join us as we delve into the intricate ways these AI systems are reshaping learning materials, personalizing education, and fostering critical thinking. Explore how language barriers are being shattered through real-time translation services, and learn about the potential for AI-assisted research. We also address the pressing concern of cheating in education and how educators are navigating this ethical challenge. Join us on this educational journey to understand how AI is revolutionizing education while promoting responsible and ethical use. Don't miss out ‚Äì watch now to uncover the future of learning!
#EducationRevolution #AIinEducation #LanguageModels #PersonalizedLearning #GlobalCollaboration #EthicalAI #FutureofLearning #CriticalThinking #DigitalEthics #AcademicIntegrity #ResponsibleTechnology #InnovativeEducation #AIAssistedLearning #EducationTransformation",KamiriTech ,2023-08-23T21:00:01Z,2023-09-06T11:45:19Z
134,Understanding Large Language Models&#39; Effects on Programming with Saman Amarasinghe #AI #science #MIT,a4II32qZzGQ,20,59,"In this episode of the CSAIL Alliances Podcast, Professor Saman Amarasinghe discusses how Large Language Models like Chat GPT will shape the future of programming. Listen to the full podcast here: https://bit.ly/3Qsbu04",MIT CSAIL Alliances,2023-08-23T18:01:44Z,2023-09-06T11:45:19Z
135,T985a -   Ten Essential Factors to consider when comparing Large Language Models (LLMs),AuPmHevwIYM,68,21:10,"The race for AI supremacy has reached a fever pitch. Tech titans like Google, Microsoft, and Meta are locked in an epic battle to build the most powerful large language model (LLM). But with new models emerging at breakneck speed, how do you distinguish the latest GPTs and PaLMs? Join us as we reveal the top 10 secret ingredients for evaluating LLMs. We'll explore everything from training data volume and model architecture to inference efficiency and multimodality. You'll learn all about parameters, context windows, and attention mechanisms. We'll also unpack the role of pre-training, fine-tuning, and prompt engineering. This action-packed deep dive distills the key factors you need to assess any LLM's strengths and weaknesses. Gain the insider knowledge to tell your GPT-3s from your GPT-4s. Get the contextual intelligence to make sense of this rapidly evolving space. Strap in and level up your AI expertise. This is one LLM masterclass you don't want to miss!

Keywords:
#gpt3, #gpt3.5, #chatgpt4, #t5, #gpt4, #webgpt, #gan, #chatgpt, #diffusion, #agi, #asi, #vae, #transformer, #lamda, #llm, #palm, #palm2, #llama, #bloom, #feedforward, #rnn, #cnn, #convolution, #ai #artificialintelligence #deeplearning #neuralnetworks #attention #attentionisallyouneed, #transformerbasedarchitecture, #rlhf

http://www.aitoolsresearch.com",Ai Tools Research,2023-08-23T17:58:15Z,2023-09-06T11:45:19Z
136,AI Tools - Microsofts SHOCKING New &#39;KOSMOS 2&#39; Multimodal AI,9quqDuM28To,470,8:57,"AI Tools - Microsofts SHOCKING New 'KOSMOS 2' Multimodal AI 

Imagine a groundbreaking technology that seamlessly integrates language, vision, and vision-language tasks ‚Äì that's the power of Multimodal Large Language Models (MLLMs). These models have achieved remarkable success, empowering AI to comprehend and respond to various modalities like texts, pictures, and audio, all while using free-form texts. It's like an AI with supersenses, perceiving and understanding the world just like us.

In today's video we look at AI Tools - Microsofts SHOCKING New 'KOSMOS 2' Multimodal AI 

Subscribe for AI, AI News, and AI Tools. Inspired by AI Revolution, AI Uncovered, and TheAIGRID. 

Inspired by Microsofts New 'KOSMOS 2' Multimodal Takes Everyone By SURPRISE! (Now RELEASED!)

Inspired by KOSMOS-2: Microsoft's New AI Breakthrough Generating Text, Images, Video & Sound in Real-Time!

Inspired by GPT-5 AI spy shows how it can destroy the US in a day.

Click here to subscribe: https://bit.ly/43zMmIw",AI Sector,2023-08-23T16:15:02Z,2023-09-06T11:45:19Z
137,New Course: Finetuning Large Language Models,9PxhCekQYNI,4553,2:37,"Enroll today: https://bit.ly/3OOFL6O

Introducing ‚ÄúFinetuning Large Language Models,‚Äù a short and practical course designed to elevate your proficiency using LLMs for your own applications.

Learn how finetuning seamlessly integrates into the training process, the distinctions between finetuning and other methods like prompt engineering and Retrieval Augmented Generation (RAG), and why finetuning is an important leap in capability over many other methods.

By the end of the course, you will:

- Recognize the best use cases for finetuning LLMs
- Choose suitable open source models unique to your application
- Get your data ready for finetuning
- Train and evaluate an LLM on your data

This is an intermediate program for developers eager to learn the techniques and applications of finetuning and have basic Python and PyTorch knowledge. 

Learn more: https://bit.ly/3OOFL6O",DeepLearningAI,2023-08-23T15:00:48Z,2023-09-06T11:45:19Z
138,FLOW Seminar #107: Boxin Wang (UIUC) Can Public Large Language Models Help Private Cross-device FL?,dM0Nf38wetM,62,44:46,"Federated Learning One World Seminar, 2nd August 2023

Seminar: https://sites.google.com/view/one-world-seminar-series-flow/home
Talk: https://sites.google.com/view/one-world-seminar-series-flow/archive/2023#h.fp2s9tdls0v7
Boxin Wang: https://wbx.life/
Twitter: https://twitter.com/flow_seminar",Federated Learning One World Seminar,2023-08-23T12:32:01Z,2023-09-06T11:45:19Z
139,What is Retrieval-Augmented Generation (RAG)?,T-D1OfcDW1M,10127,6:36,"Try RAG with watsonx ‚Üí https://ibm.biz/BdMsRT
Learn more about RAG‚Üí https://ibm.biz/BdMsRt

Large language models usually give great answers, but because they're limited to the training data used to create the model, over time they can become incomplete--or worse, generate answers that are just plain wrong. One way of improving the LLM results is called ""retrieval-augmented generation"" or RAG. In this video, IBM Senior Research Scientist Marina Danilevsky explains the LLM/RAG framework and how this combination delivers two big advantages, namely: the model gets the most up-to-date and trustworthy facts, and you can see where the model got its info, lending more credibility to what it generates.

Get started for free on IBM Cloud ‚Üí https://ibm.biz/sign-up-now
Subscribe to see more videos like this in the future ‚Üí¬†http://ibm.biz/subscribe-now",IBM Technology,2023-08-23T11:00:32Z,2023-09-06T11:45:19Z
140,How LLMs work and how to build your first LLM-based project - Damian Mazurek,49vf07jh5J8,228,25:3,"The latest episode of Tech Talk IT: Powered by Software Mind! 

Dive into the world of AI and large language models with Damian Mazurek, Chief Innovation Officer at Software Mind. In this captivating podcast series, Damian navigates the intricate landscape of AI-driven language processing, from tokens and embeddings to training and memory management. Discover strategies like conversational buffer memory, knowledge graph-based memory and much more. Learn how frameworks like LangChain streamline prompt preparation and execution, while using long-term memory to tap into external data sources.  

Subscribe now and stay connected with all the tech news and best practices! 

Hungry for more? Check out our blog: https://softwaremind.com/blog/",Software Mind,2023-08-23T07:53:22Z,2023-09-06T11:45:19Z
141,GPT Synonyms - The intelligence of Large Language Models just a click away,hPcFD3xi-5w,62,4:36,"Say goodbye to manual synonym entries. GPT Synonyms intelligently suggests relevant synonyms, streamlining your search optimization process:

‚è∞ Save Time & Effort: Our internal tests reveal a whopping 70% time-saving in synonym creation. Focus on what truly matters while GPT Synonyms handles the intricacies.
üí∞ Drive Revenue Growth: Improved search results mean happier customers and increased sales. Elevate your e-commerce platform with unparalleled search capabilities.
üåç Multilingual Support: Cater to a global audience with synonym suggestions across multiple languages.",FactFinder,2023-08-23T07:16:57Z,2023-09-06T11:45:19Z
142,[Lab Seminar] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (NeurIPS 2022),JX5SVlpEmZ8,15,22:7,"2023 Spring Lab Seminar 

Paper : Chain-of-Thought Prompting Elicits Reasoning in Large Language Models (NeurIPS 2022)
Presenter : ÍπÄÏùÄ

[DSAIL Ïó∞Íµ¨Ïã§ ÌôàÌéòÏù¥ÏßÄ]
https://sites.google.com/view/datasciencelab",DSAIL SKKU,2023-08-23T04:32:38Z,2023-09-06T11:45:19Z
143,In-Ear Insights: Analytics Use Cases for Large Language Models,pgGNObybh3A,30,30:58,"In this episode of In-Ear Insights, the Trust Insights podcast, Katie and Chris discuss how to leverage large language models like ChatGPT with your business analytics data. We talk through real examples of using AI to analyze CRM data for buyer personas, extract tables from PDFs, summarize PowerPoints into executive briefs, transform your data into actionable insights, classify social media comments, and answer questions about your data. We explain that while generative AI is exciting, your analytics data should still be the backbone of business decisions. Tune in to learn creative ways analytics and AI can work together to enhance your marketing strategy.

Sign up to our weekly #email newsletter:
https://www.trustinsights.ai/resources/data-in-the-headlights-newsletter/

Subscribe to our YouTube channel for more #marketing and #analytics videos!
https://www.trustinsights.ai/youtube

Need help with your company's #data and #analytics? Let us know:
https://www.trustinsights.ai

Subscribe to the Trust Insights podcast:
https://www.trustinsights.ai/resources/in-ear-insights-the-trust-insights-podcast/

Join our free private Slack community, Analytics for #Marketers:
https://www.trustinsights.ai/analyticsformarketers",Trust Insights,2023-08-23T04:00:20Z,2023-09-06T11:45:19Z
144,"Chirag Shah: The future of search: Information seeking, large language models and search",orucSxnAO20,99,1:25,"This keynote presentation was part of the 2023 ADM+S Web Search Revolution Symposium on 17 August at RMIT University, and online.

The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text or images and even videos. This transformation in progress will have profound impacts on users, developers, and policy makers. It is already changing many sectors including education, health, and commerce. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. I will bring up frequently asked questions about impacts of these technologies on pedagogy, jobs, economy, policies, and democracy. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.

Speaker:
Chirag Shah, Professor of Information and Computer Science, University of Washington",ADM+S Centre,2023-08-23T04:00:33Z,2023-09-06T11:45:19Z
145,Reinforced Self-Training (ReST) for Language Modeling,geMgd7fov2Q,367,16:6,"Reinforced Self-Training (ReST) is a simple algorithm that aligns large language models (LLMs) with human preferences using reinforcement learning from human feedback (RLHF). It improves translation quality efficiently and effectively.

00:00 Section: 1 Introduction
03:30 Section: 3 Reinforced Self-Training (ReST)
07:29 Section: Nomenclature
10:23 Section: 5 Related works
15:24 Section: Acknowledgements

https://arxiv.org/abs//2308.08998

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-23T03:24:31Z,2023-09-06T11:45:19Z
146,Bard 101 - Google&#39;s Large Language Model for Dummies [Tutorial],3KJEGvw6YT0,23,8:29,"Introduction to Bard, Google's Large Language Model Chatbot.

Step by step tutorial to access Bard, login, write prompts, examine features and export outputs.

If you found this video helpful and want to stay updated on our journey of AI-assisted course creation, please subscribe to our channel: 
https://www.youtube.com/@howtocbc?sub_confirmation=1

OUR COURSES:
The Online Course Creation Kickstarter
https://maven.com/howtocbc/online-course-kickstarter

Design Your First Cohort Based Course
https://maven.com/howtocbc/designacbc/

OUR VIDEOS AND PLAYLISTS:
Using OpenAI's ChatGPT to build an online course step-by-step
https://www.youtube.com/playlist?list=PLAM4M8mwNXjCcKOfYdonoe_LFzxWK5Lzq

Mindset Changes in Running Our Own Company 
https://www.youtube.com/watch?v=PfCEOQCuMjc&ab_channel=HowToCBC

üçø WATCH ALSO:
The Edupreneur Show 
https://www.youtube.com/playlist?list=PLAM4M8mwNXjCoI4mDUYZG__ZKbWxIRtua

‚åöÔ∏èTimestamps:
00:00 Introduction
01:00 What is Google's Bard?
01:32 Why are LLMs hot?
02:12 Access Bard
02:58 Prompts and Features
04:34 I/O Formats
05:50 Export Output from Bard
06:53 BONUS: Tips",HowToCBC,2023-08-22T23:47:32Z,2023-09-06T11:45:19Z
147,Generative AI : An Introduction | Large Language Models,IekTYWaCtRc,144,18:33,"This video covers very basics of Generative AI. This is first video in this video series on Generative AI covering lot of key terms and concepts in this space. 

Chapters:
00:00 An introduction
03:00 What is Generative AI?
04:00 How can a naive user use it?
06:26 How can an expert user use it?
08:41 Key concepts/ Terms : Generative AI 
11:45 ChatGPT Demo 
14:53 Gamma.app Demo
16:55 Future Coverage on Generative AI Topics

Other playlists:
AWS DynamoDB Tutorial for beginners | what is amazon DynamoDB | AWS Tutorials 2022
 https://bit.ly/38OaXlR
AWS tutorials playlist https://bit.ly/3NJVxxQ
MongoDB Data Modelling and Advanced Design Patterns https://bit.ly/3GyEooe 
MongoDB Tutorials 2022 | MongoDB Compass | MongoDB Atlas  https://bit.ly/3M7cUXY 
MongoDB | MongoDB Tutorial 2022 | Learn MongoDB for beginners   https://bit.ly/3GHubpF

You may like to visit my website for other wonderful tutorials.
https://www.learnwithneeraj.com
https://www.linkedin.com/in/neerajgarg5/
https://twitter.com/neeraj_garg5

#neerajgarg #generativeai #genai #genaiconcepts #chatgptdemo #chatgpt #hallucination #largelanguagemodels #llms #transformers #huggingface",Data Expert,2023-08-22T23:30:06Z,2023-09-06T11:45:19Z
148,How to Plan for Large Language Model (LLM) Adoption Within Your Engineering Organization,YSwnBQ_AUSA,20,58,"Discover how to navigate the challenges of adopting Large Language Models (LLMs) within your engineering organization HERE https://bit.ly/47HL4O4

With unrestricted access to LLMs, there has been a rise in intellectual property leakage and legal concerns. Companies like Samsung and Apple have even banned internal use of LLMs due to these risks. As legal frameworks and precedents are yet to be established, it is crucial to focus on improving requirements quality to reap the benefits of intelligent assistance. To get started with intelligent assistance, learn how best to improve requirements quality across your engineering organization with the NLP application of EARS & INCOSE best practices. To maximize the benefits of intelligent assistance, we recommend our clients prioritize three key areas. For more information, visit our blog.",Jama Software,2023-08-22T20:26:41Z,2023-09-06T11:45:19Z
149,FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only Quantization for LLMs,k14XD5A10Uw,71,23:,"The paper proposes an efficient weight-only quantization method for large language models (LLMs) to reduce memory consumption and accelerate inference. The method utilizes a heuristic approach that only uses the model weights of a pre-trained model, without requiring additional fine-tuning. The approach addresses the challenges and issues associated with LLM quantization and achieves higher throughput on the same number of GPUs with minimal accuracy loss.

00:00 Section: 1 Introduction
04:00 Section: 2 Background - Challenges of Quantizing LLMs
08:08 Section: 3 Designing Quantization Methods for LLMs - Adaptive Fine-grained Quantization
10:38 Section: 3.2 Granularity of quantization
13:44 Section: 4.1 Experimental setup
18:42 Section: 4.2.1 Accuracy
22:05 Section: 4.3 MoE model performance results

https://arxiv.org/abs//2308.09723

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-22T15:12:19Z,2023-09-06T11:45:19Z
150,Causal Parrots: Large Language Models May Talk Causality But Are Not Causal (published TMLR 2023),vbwrhbuvedE,60,19:15,"Link to Full Paper: https://openreview.net/pdf?id=tv46tCzs83
Authored by Matej Zeƒçeviƒá*, Moritz Willig*, Devendra Dhami, Kristian Kersting
Presented by Matej Zeƒçeviƒá
*co-first

Timeline:
00:00 Introduction
01:00 Why? Motivating Causal AI & ML with LLMs
04:05 Related Work on LLM x (Causal) Reasoning
06:51 Empirical Study of LLM's Causal Capabilities
11:32 Main Conjecture ""Correlation of Causal Facts""
18:45 Conclusion",Matej Zeƒçeviƒá,2023-08-22T14:45:09Z,2023-09-06T11:45:19Z
151,‚ÄúLLAMA2 supercharged with vision &amp; hearing?!‚Äù | Multimodal 101 tutorial,RxBSmbdJ1I8,14789,9:10,"Explore Multimodal language model, like LLaVA, which enables you reach GPT4 level multimodal abilities, unlock use cases like chat with images

üîó Links
- Follow me on twitter: https://twitter.com/jasonzhou1993
- Join my AI email list: https://www.ai-jason.com/
- LLaVA link: https://llava-vl.github.io/

‚è±Ô∏è Timestamps
0:00 Intro
1:03 What is multimodal?
1:23 LLaVA model
2:08 Demo
3:35 Use case: Product development
5:17 Use case: Content curation
6:27 Use case: Medical
7:07 Use case: Captcha
8:09 Use case: Robots


üëãüèª About Me
My name is Jason Zhou, a product designer who shares interesting AI experiments & products. Email me if you need help building AI apps! ask@ai-jason.com

#gpt #autogpt #ai #artificialintelligence #tutorial #stepbystep #openai #llm #largelanguagemodels #largelanguagemodel #chatgpt #multimodality #gpt4 #multimodal #llama2 #llama #llava #machinelearning",AI Jason,2023-08-22T14:04:39Z,2023-09-06T11:45:19Z
152,LLM Explained Simply |  What is LLM?,67_aMPDk2zw,9087,4:17,"Simple and easy explanation of LLM or Large Language Model in less than 5 minutes. In this short video,  you will build an intuition of how a large language model works using animation and simple story telling. This is the explanation that even a high school student can understand easily.

Simple Explanation of Neural Network: https://www.youtube.com/watch?v=ER2It2mIagI

Do you want to learn technology from me? Check https://codebasics.io/?utm_source=description&utm_medium=yt&utm_campaign=description&utm_id=description for my affordable video courses.

Need help building software or data analytics/AI solutions? My company https://www.atliq.com/ can help. Click on the Contact button on that website.

üé• Codebasics Hindi channel: https://www.youtube.com/channel/UCTmFBhuhMibVoSfYom1uXEg

#Ô∏è‚É£ Social Media #Ô∏è‚É£
üîó Discord:  https://discord.gg/r42Kbuk
üì∏ Dhaval's Personal Instagram: https://www.instagram.com/dhavalsays/
üì∏ Codebasics Instagram: https://www.instagram.com/codebasicshub/
üîä Facebook: https://www.facebook.com/codebasicshub
üì± Twitter: https://twitter.com/codebasicshub
üìù Linkedin (Personal): https://www.linkedin.com/in/dhavalsays/
üìù Linkedin (Codebasics):  https://www.linkedin.com/company/codebasics/
üîó Patreon: https://www.patreon.com/codebasics?fan_landing=true",codebasics,2023-08-22T13:30:12Z,2023-09-06T11:45:19Z
153,Cumulative Reasoning With Large Language Models Tsinghua 2023,4eO4Fr6n80w,29,14:37,Cumulative Reasoning With Large Language Models (Tsinghua 2023),mardin mardin,2023-08-22T10:13:48Z,2023-09-06T11:45:19Z
154,META-FORUM 2023: Session 4: European Large Language Models,creK2x_CbLQ,387,55:51,"00:00 Introduction ‚Äì Andy Way (Dublin City University, Ireland)
02:09 Developing Multilingual LLMs ‚Äì Pedro Ortiz (DFKI, Germany)
17:55 High-Performance Language Technologies (HPLT) ‚Äì Barry Haddow (University of Edinburgh, United Kingdom)
29:07 European Web Crawls and LLMs: the OpenWebSearch Project ‚Äì Michael Granitzer (University of Passau, Germany)
43:41 Q&A and Discussion

Chair: Andy Way (Dublin City University, Ireland)",European Language Grid,2023-08-22T08:44:06Z,2023-09-06T11:45:19Z
155,Important Large Language Models (LLMs),6SiYKjwk6Eg,166,5:32,"Our Current Live Course: 
AI Ka Chilla 2023
To register for AI ka chilla 2023, fill this google form: https://forms.gle/ZPXSXEcLQnfha7xw8  

Join this channel to get access to perks:
https://www.youtube.com/channel/UCmNXJXWONLNF6bdftGY0Otw/join

#datascience 
---------------------------------------------------------------------------------------------------------------------------------------
Video Description:

---------------------------------------------------------------------------------------------------------------------------------------

‚úÖSubscribe to our Channel to learn more about the top Data Science, Machine Learning and Deep Learning :  https://www.youtube.com/c/Codanics

---------------------------------------------------------------------------------------------------------------------------------------




---------------------------------------------------------------------------------------------------------------------------------------
Explore other free courses here:
üî•  Python ka chilla v1.0 for Data Science (playlist): https://youtube.com/playlist?list=PL9XvIvvVL50HVsu-Ao8NBr0UJSO8O6lBI

üî•  Machine learning ka chilla (playlist): https://www.youtube.com/watch?v=KYl9zmSt-Ik&list=PL9XvIvvVL50HHzaLPtFBOuikAWa0JdhMW

üî• Streamlit course for dash boards and webapps for data science (playlist): 
https://youtube.com/playlist?list=PL9XvIvvVL50FG8TUsLScsLMmJDacK36x2

üî•  Cloud computing (playlist): https://youtube.com/playlist?list=PL9XvIvvVL50H72Q75WkYA_2zjZok30Rvp

üî•  #RwithAammar Programming with R for Data Analysis and Data Science (Playlist): https://www.youtube.com/playlist?list=PL9XvIvvVL50E8HimtAnVL8N70MqImYOLS

üî• Make publication ready graphs in Rstudio: https://www.youtube.com/playlist?list=PL9XvIvvVL50Hi2RGu-zlNEnk9WJMjPH-g

üî• Computer Vision openCV in Python (Playlist): https://youtube.com/playlist?list=PL9XvIvvVL50GKoKrluZ1A96Bsuw8qC-3r

üî•MS Excel for Data Analysis: https://www.youtube.com/playlist?list=PL9XvIvvVL50Hl4kVygAWYEpBXUteQlAiN

üî• SQL complete course in Hindi/Urdu: https://youtube.com/playlist?list=PL9XvIvvVL50FszjOhcZw9WXIJQY6ZwV5g

---------------------------------------------------------------------------------------------------------------------------------------
üî•-Follow me on following platforms:
1. Twitter: https://twitter.com/aammar_tufail
2. github: https://github.com/AammarTufail
3. Tiktok:  https://www.tiktok.com/@draammar
---------------------------------------------------------------------------------------------------------------------------------------
#dataScience
Join this telegram group for regular updates via zoom meeting 1-to-1 sessions: https://t.me/codanics
---------------------------------------------------------------------------------------------------------------------------------------

for more details:
www.codanics.com",Codanics,2023-08-22T08:00:08Z,2023-09-06T11:45:19Z
156,RARR: Researching and Revising What Language Models Say Using Language Models,kul61M8YORU,55,16:49,"RARR (Retrofit Attribution using Research and Revision) is a framework for revising claims from LMs to make them attributable to the researched evidence. RARR can revise the passages to improve attribution while preserving other desirable properties such as writing style or structure. RARR sits on top of existing generation models without needing to re-design or re-train LMs.

In this video, I will talk about What is RARR? How does RARR work? How does RARR perform?

For more details, please look at https://arxiv.org/pdf/2210.08726.pdf

Gao, Luyu, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan, Vincent Zhao et al. ""Rarr: Researching and revising what language models say, using language models."" In ACL, pp. 16477-16508. 2023.",Data Science Gems,2023-08-22T07:50:08Z,2023-09-06T11:45:19Z
157,Large Language Models: Looking Under the Hood,8fm5onMf1_o,69,46:32,"02:40 Human versus LLM: reasoning and meaning versus statistical language map
06:36 Tokenization
08:10 Embeddings and semantic search
10:21 Unidirectional versus Bidirectional Models
11:43 Transformers
13:38 Parameters
15:56 Issues with LLMs Training Datasets
16:37 Computational Power
17:18 Context Window
18:47 Vocabulary
21:03 Key Risks
22:53 Configurations
23:58 LLM Implementation Options for Businesses
27:50 Benchmarks
29:34 Model Cards and Datasheets for Datasets
31:14 Emerging Solutions Chain of Thought, PAL, Neurosemantic, RAG
33:38 Use Cases and Applications
35:54 Impacts on Workforce: Productivity?
39:13: Regulatory Landscape and the EU's AI Act
40:40 Approach to Governance 





Hey there! It's In√™s here. I work with businesses on generative AI. Here's something I've observed:

- Some leaders are very enthusiastic, seeing huge potential for productivity gains with AI .
- Others are cautious, concerned about issues like ""the bots hallucinate"" and prefer to wait.

It's crucial to strike a balance.

I recently hosted a webinar where I discuss the real workings of these AI models, what they can and can't do, and how best to approach them. Simple, but informed insights.

http://www.nownextlater.ai",Now Next Later AI ‚Äî AI Strategy & Transformation,2023-08-22T04:55:44Z,2023-09-06T11:45:19Z
158,Can Language Models Learn to Listen?,5g3M9EajXyY,6,37,"#blacksstopkillingblackschallenge_360 #leadership #futureofautomation 

We present a framework for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker's words. Given an input transcription of the speaker's words with their timestamps, our approach autoregressively predicts a response of a listener: a sequence of listener facial gestures, quantized using a VQ-VAE. Since gesture is a language component, we propose treating the quantized atomic motion elements as additional language token inputs to a transformer-based large language model. Initializing our transformer with the weights of a language model pre-trained only on text results in significantly higher quality listener responses than training a transformer from scratch. We show that our generated listener motion is fluent and reflective of language semantics through quantitative metrics and a qualitative user study. In our evaluation, we analyze the model's ability to utilize temporal and semantic aspects of spoken text. Project page: this https URL https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/",Bumlife2Bomblife Management,2023-08-22T03:57:53Z,2023-09-06T11:45:19Z
159,Managing the risks of Large Language Models,GXtDbKKObbQ,41,16:45,Learn how to mitigate and manage the risks of Large Language Models with AI expert Dr Lachlan McCalman from Gradient Institute.,CSIRO's Data61,2023-08-22T03:23:29Z,2023-09-06T11:45:19Z
160,What are Large Language Models?,x7EWP_Jc8G0,59,5:41,Learn what Large Language Models are from AI expert and Gradient Institute CEO Bill Simpson-Young.,CSIRO's Data61,2023-08-22T03:19:16Z,2023-09-06T11:45:19Z
161,How Large Language Models work,E_mhX8napII,109,7:48,How do Large Language Models work? Learn from AI expert Dr Lachlan McCalman of Gradient Institute.,CSIRO's Data61,2023-08-22T03:15:36Z,2023-09-06T11:45:19Z
162,Generative AI | Introduction to WatsonX | large language model (LLM),AvK3yWMRjCE,38,2:16,"Watsonx is our enterprise-ready AI and data platform designed to multiply the impact of AI across your business. The platform comprises three powerful products: the watsonx.ai studio for new foundation models, generative AI and machine learning; the watsonx.data¬†fit-for-purpose¬†data store, built on an open lakehouse architecture; and the watsonx.governance toolkit, to accelerate AI workflows that are built with responsibility, transparency and explainability.

Watsonx.ai
Watsonx.data
Watsonx.governance


Generative AI
Artificial Intelligence
Machine Learning
Neural Networks
Deep Learning
Natural Language Generation
Text Generation
Image Generation
Creativity and AI
Creative Algorithms
AI-Generated Content
GANs (Generative Adversarial Networks)
Creative Writing AI
Music Generation
Content Automation
Data-driven Creativity
AI Art
AI Composer
Automated Design
Video Generation
Style Transfer
Autonomous Creativity
Algorithmic Art
AI Storytelling
Virtual Artists",Tech Talk,2023-08-22T03:02:00Z,2023-09-06T11:45:19Z
163,Large Language Models and Jobs,wOAtmI3V-pE,133,44:58,"How will large language models affect how people work, how productive they are, and what kinds of jobs they have? 

These questions have been in the air over the past year, but solid data upon which to base an analysis has been scarce.  In a recent talk at our machine learning and finance reading group, I explored these questions by drawing on two sources: first, MIT economist David Autor's analysis of the labor-market impact of past technological changes;  second, a recent case study of the introduction of a language-mode-based tool in a workplace (Erik Brynjolfsson, Danielle Li, and Lindsey R. Raymond. ""Generative AI at work"". National Bureau of Economics Research Working Paper). While definitive predictions are impossible at this early stage, I hope my discussion provides some useful insights.  I've re-recorded the talk here.

Chapters:
0:00 Introduction
4:11 Autor's analysis of the PC revolution
16:05 LM tool for customer support agents
40:18 Concluding discussion

Reading group home page: https://github.com/paiforsyth/ML-Finance_Group/blob/master/README.md

Main references:
David Autor. ""Polanyi‚Äôs paradox and the shape of employment growth"". National Bureau of Economic Research, (2014).

Brynjolfsson, Erik, Danielle Li, and Lindsey R. Raymond.¬†""Generative AI at work"".  National Bureau of Economic Research,  (2023).


Additional references:
Akari Asai, Sewon Min, Zexuan Zhong, and Danqi Chen. 2023. ""Retrieval-based Language Models and Applications"". In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 6: Tutorial Abstracts), pages 41‚Äì46, Toronto, Canada. Association for Computational Linguistics.

Autor, David H  and David Dorn. ‚ÄúThe growth of low-skill service jobs and the polarization of the US labor market‚Äù. In: American economic review 103.5 (2013), pp. 1553‚Äì1597.

Autor, David H, Frank Levy, and Richard J Murnane. ‚ÄúThe skill content of recent technological change: An empirical exploration‚Äù. In: The Quarterly journal ofeconomics 118.4 (2003), pp. 1279‚Äì1333.

Autor, David H. ""Polanyi‚Äôs paradox and the shape of employment growth"". Tech. rep. National Bureau of Economic Research, 2014

Autor, David H. ‚ÄúWhy are there still so many jobs? The history and future of workplace automation‚Äù. In: Journal of economic perspectives 29.3 (2015),pp. 3‚Äì30.

Autor, David, et al.¬†""New Frontiers: The Origins and Content of New Work, 1940‚Äì2018"". No. w30389. National Bureau of Economic Research, (2022).

Briggs, Joseph et al.  ""The Potentially Large Effects of Artificial Intelligence on Economic Growth."" Goldman Sachs (2023).

Brynjolfsson, Erik, Danielle Li, and Lindsey R. Raymond.¬†""Generative AI at work"". No. w31161. National Bureau of Economic Research, (2023).

Chui, Michael  et al. ‚ÄúThe economic potential of generative AI‚Äù. In: McKinsey Reports (2023)

Eloundou, Tyna, et al. ""Gpts are gpts: An early look at the labor market impact potential of large language models.""¬†arXiv preprint arXiv:2303.10130¬†(2023).

LeCun, Yann. ""A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27.""¬†Open Review¬†62 (2022).

Mialon, Gr√©goire, et al. ""Augmented language models: a survey."" arXiv preprint arXiv:2302.07842 (2023).

Miller, Douglas L. ""An Introductory Guide to Event Study Models.""¬†Journal of Economic Perspectives¬†37.2 (2023): 203-230.

Neelakantan, Arvind, et al. ""Text and code embeddings by contrastive pre-training.""¬†arXiv preprint arXiv:2201.10005¬†(2022).

Nordhaus, William D. ""Two centuries of productivity growth in computing.""¬†The Journal of Economic History¬†67.1 (2007): 128-159.

Noy, Shakked, and Whitney Zhang. ""Experimental evidence on the productivity effects of generative artificial intelligence.""¬†Available at SSRN 4375283¬†(2023).

Ouyang, Long, et al. ""Training language models to follow instructions with human feedback.""¬†Advances in Neural Information Processing Systems¬†35 (2022): 27730-27744.

Peng, Sida, et al. ""The impact of ai on developer productivity: Evidence from github copilot.""¬†arXiv preprint arXiv:2302.06590¬†(2023).

Reimers, Nils, and Iryna Gurevych. ""The curse of dense low-dimensional information retrieval for large index sizes.""¬†arXiv preprint arXiv:2012.14210¬†(2020).

Schick, Timo, et al. ""Toolformer: Language models can teach themselves to use tools.""¬†arXiv preprint arXiv:2302.04761¬†(2023).

Tabarrok, Alex. ""William Baumol and the Cost Disease.""¬†Research in the History of Economic Thought and Methodology: Including a Symposium on the Work of William Baumol. (2022).",Derivative Report,2023-08-21T22:44:30Z,2023-09-06T11:45:19Z
164,Exploring the Potential of Large Language Models as 4th Gen Programming Language Compilers,J5OoMLmUMe4,127,2:32,"The HackerNews post discusses the concept of large language models (LLMs) and their potential as compilers for the 4th generation of programming languages. However, some commenters express frustration with the recycling of version numbers and the lack of historical knowledge in the field of computer science. Others debate the usefulness of LLMs in generating code and the potential future of programming languages. Overall, the discussion revolves around the role of LLMs in programming and the importance of understanding computing history.

üîó https://drops.dagstuhl.de/opus/volltexte/2023/18524/pdf/OASIcs-SLATE-2023-10.pdf

#AI #AI #LLM #Language Model",AI Insight News,2023-08-21T22:12:01Z,2023-09-06T11:45:19Z
165,ChatHaruhi: Reviving Anime Character in Reality via Large Language Model.,ZdTynwUFpYI,42,1:3,"#blacksstopkillingblackschallenge_360 #leadership #futureofautomation 

Role-playing chatbots built on large language models have drawn interest, but better techniques are needed to enable mimicking specific fictional characters. We propose an algorithm that controls language models via an improved prompt and memories of the character extracted from scripts. We construct ChatHaruhi, a dataset covering 32 Chinese / English TV / anime characters with over 54k simulated dialogues. Both automatic and human evaluations show our approach improves role-playing ability over baselines. Code and data are available at this https URL .",Bumlife2Bomblife Management,2023-08-21T21:25:53Z,2023-09-06T11:45:19Z
166,Executive Briefing Course on Generative AI and Large Language Models (LLMs) #generativeai #llm,RZLi3WdgsfM,133,1:39,"Course Link:  https://www.alankargupta.com/courses/Executive-Briefing--Generative-AI-and-LLMs-64cb8cfce4b0a56398994597-64cb8cfce4b0a56398994597

Use Coupon code: GEN50 and avail 50% discount

Unveiling the Future of AI: Gen AI's Impact on Data and Productivity! üåü Brace yourself for a journey into the heart of AI marvels, where knowledge meets innovation. Every tap brings you closer to understanding the true essence of Generative AI and Large Language Models (LLMs)",Alankar Gupta,2023-08-21T21:03:15Z,2023-09-06T11:45:19Z
167,"Using ChatGPT, GPT-4, &amp; Large Language Models In the Enterprise",e_vKiJWD_XA,1509,56,"Join us as we explore, learn, and experience the incredible potential that Generative AI, Large Language Models, and secure data integration bring to the forefront of enterprise excellence. Your journey toward a transformative future begins now. RSVP : https://www.royalcyber.com/generative-ai-impact-on-businesses/?refer=SocialMediaYoutube 

Website: https://www.royalcyber.com/
LinkedIn: https://www.linkedin.com/company/royal-cyber-inc- 
Twitter: https://twitter.com/RoyalCyberUSA
Instagram: https://www.instagram.com/royalcyberinc/
Facebook: https://www.facebook.com/RoyalCyber",Royal Cyber Inc,2023-08-21T19:46:44Z,2023-09-06T11:45:19Z
168,Graph of Thoughts: Solving Elaborate Problems with Large Language Models,f0QE_NXVA2k,586,32:54,"The paper introduces Graph of Thoughts (GoT), a framework that enhances prompting capabilities in large language models by modeling information as a graph. GoT offers advantages over existing paradigms and can be extended for new prompting schemes.

00:00 Section: 1 Introduction
04:40 Section: 2 Background & Notation
07:42 Section: 3 The GoT Framework
11:00 Section: Aggregation Transformations
13:13 Section: 4 System Architecture & Extensibility
16:12 Section: 4.5 GoO & GRS
19:46 Section: 5.2 Set Operations
22:17 Section: 5.4 Document Merging
24:50 Section: 7 Evaluation
28:32 Section: 7.3 Discussion on Task Decomposition
31:00 Section: 8.2 Self-Reflection & Self-Evaluation

https://arxiv.org/abs//2308.09687

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-21T19:38:23Z,2023-09-06T11:45:19Z
169,Chatgpt &amp; Large Language Model LLMs Exploring the Basics! How to generate Rhymes using ChatGpt?,rQ-tAdkxHnc,332,3:46,"#SaachiTalksConceptsandStories @codeorg 
https://youtu.be/X-AWdfSFCHQ - How Chatbots and Large Language Models Work
DIY Science Projects - Demos, concepts and Models - Playto Summer Science Festival 2023 for kids
https://www.youtube.com/watch?v=P_0SsEXvhjU&list=PLKDaN0En95-vnw2sji4bAKyxXQ6hYvdCL&index=1&t=10s
Rewards & Achievements https://www.youtube.com/watch?v=56E0exQFXYU&list=PLKDaN0En95-sUP_rEgkPG1pxNfksMPPMq
Beginner Coding project ideas:https://www.youtube.com/watch?v=_a87ppqOBm8&list=PLKDaN0En95-sWXYSS6RVxO7CpaY1vxRru
Interactive Worksheets solutions
https://www.youtube.com/watch?v=5ip2_kI8A18
My creative projects ideas:https://www.youtube.com/watch?v=ZzBtuGpKBLk&list=PLKDaN0En95-tthpilOMXM21H47qxlM0jt
Storytime Central, Imagination Station, Laugh and Learn: Engaging Podcast for Curious Minds https://www.youtube.com/watch?v=Wg1G1CD2_Z0&list=PLKDaN0En95-uFqPJpnqTy5MY6vbtALAZD
Shorts playlist:  https://www.youtube.com/watch?v=hd6oJscg9NY&list=PLKDaN0En95-snbXG-pGGVgNuss_p0UUPf
Illusions, Wonders of Science & Maths, Magic Mania!
https://www.youtube.com/watch?v=xFdtV_CeoeU&list=PLKDaN0En95-uZAakkJUO3Q1ah4G8JAqnH&index=1
Python Beginner project ideas:https://www.youtube.com/watch?v=FSqUaREqgpo&list=PLKDaN0En95-uU37RrbUkFY_0t8arVRrEq
Handpicked Topics, Customized Innovative fun & learn practicing ideas for kids.
Let's learn about India - Quizzes, Stories, Essay, Food & a lot more!
https://www.youtube.com/watch?v=bpiZA05RsNk
Subscription Link:
https://www.youtube.com/SaachiTalksConceptsandStories
Rewards & Achievements
https://www.youtube.com/watch?v=56E0exQFXYU&list=PLKDaN0En95-sUP_rEgkPG1pxNfksMPPMq
Science Knowledge, Experiments, learnings, NASA Space Science
https://www.youtube.com/watch?v=cDDBEG0FPB8&list=PLKDaN0En95-tNOgmYAMX8svQcLwupLgag
Coding Projects Playlist
https://www.youtube.com/watch?v=DBP_rvmWPCQ&list=PLKDaN0En95-sWXYSS6RVxO7CpaY1vxRru
Science Knowledge, Experiments, learnings, NASA Space Science
https://www.youtube.com/watch?v=cDDBEG0FPB8&list=PLKDaN0En95-tNOgmYAMX8svQcLwupLgag
Vocabulary Enhancing Kids Activities Ideas
https://www.youtube.com/watch?v=fjD7uwEPzp0&list=PLKDaN0En95-t4UmxvOJXbNW6Iss2gH6y3
Celebrating 100 videos with Fun Shorts 
https://www.youtube.com/watch?v=H-kep6oVgOc&list=PLKDaN0En95-u3CwO522_qHsIVq3Wp1TbG
Hands on coding activity worksheets, daily practice worksheets:
https://www.youtube.com/watch?v=oaxSziTYOVU&list=PLKDaN0En95-tVt93p1grjfw5PgOZPBrkD
Interesting Stories:
https://www.youtube.com/watch?v=ltGT_ON_bgs&list=PLKDaN0En95-tB6axoyjdj0Ay35ST2dAs9
Little Presenter shares Science Concepts & Experiments:
https://www.youtube.com/watch?v=5ISdKZs3e9c&list=PLKDaN0En95-vddwWIIY66_kjlcd-T226U
DIY Worksheets:
https://www.youtube.com/watch?v=yepd6lfxezo&list=PLKDaN0En95-uv-hNJ6ZXiLTvucXPYXGcm
Kids Questions:
https://www.youtube.com/watch?v=9cQ2-_TvMwE&list=PLKDaN0En95-sLfFunlT3aK1qB840th1Vb
Curiosity Bites: 
https://www.youtube.com/watch?v=WWZdkBec9gs&list=PLKDaN0En95-tW-g-P_y7gCRbuL8mUO26A
Shorts:
https://www.youtube.com/watch?v=IWW4AGkg7ME&list=PLKDaN0En95-snbXG-pGGVgNuss_p0UUPf
Knowledge Point:
https://www.youtube.com/watch?v=_vmF694cYDU&list=PLKDaN0En95-uptq4CFXaUKBEZowuTcsdX
Let's Read Together:
https://www.youtube.com/watch?v=K3X6vWkXjAg&list=PLKDaN0En95-vP3VuuEQVAM1xlwePd22iV
Wisdom Words:
https://www.youtube.com/watch?v=xgjEoyGHC7E&list=PLKDaN0En95-uZUKQb-7jfL-8av08LhPzW
Know How:
https://www.youtube.com/watch?v=4KTAy9tfe3A&list=PLKDaN0En95-tsjHlXQ9EZHickYwhM7xnF
Five Words Series:
https://www.youtube.com/watch?v=0sj4aVP4h0k&list=PLKDaN0En95-vVP4eZK50VKn_YaFM9htaN
Puzzles, Books, Games:
https://www.youtube.com/watch?v=Td7qlY5Bzfs&list=PLKDaN0En95-vXTScNb4ELKWNLqGXvq9GX
Colors, Shapes, Numbers:
https://www.youtube.com/watch?v=HpLFoOxGs4o&list=PLKDaN0En95-s8xzmhgfzaGZZdLGPSd4BN",Saachi Talks Concepts and Stories ,2023-08-21T16:05:44Z,2023-09-06T11:45:19Z
170,"Ultimate LLM Guide: From Theory to Practice - Part 2 Introduction - Emergent Abilities, Power of LLM",_rmNp96kNyQ,40,12:12,"This is the second video of a video series about LLMs. I explained the LLMs' characteristics, difference from PLMs and important features, emergent abilities such as in-context learning, instruction tunning and steps-by-steps reasoning. 
Next video will be the last theoretical one which will explain the LLMs family and the transformer architecture. Then, there will be videos about hands-on LLMs(openai library etc.).

Chinchilla paper link: https://arxiv.org/abs/2203.15556

Please share your feedback if you like or dislike the presentation and explanation.

#largelanguagemodels #llm",Emre KOCYIGIT,2023-08-21T14:59:10Z,2023-09-06T11:45:19Z
171,Insights and Tips for Using Large Language Models Part 1,EchSGpLEHlU,26,11:17,"In this video, I share my insights and practical tips for using large language models, specifically focusing on chat GPT. I discuss the differences between the free and paid versions, token usage, and the importance of context in generating accurate and relevant responses. I also demonstrate how to create prompts that yield more interesting and targeted results. Whether you're a medical educator or simply interested in exploring the capabilities of language models, this video will provide valuable information and guidance.

This will be part of series of videos to cover my insights and tips for using LLMs like ChatGPT and others I have been using.",Danish Bhatti,2023-08-21T13:11:41Z,2023-09-06T11:45:19Z
172,FinGPT: Open-Source Financial Large Language Models,kX_7ocfTS8g,2523,26:10,"Join the Hudson and Thames Reading Group: https://hudsonthames.org/reading-group/

Michael Struwig, explored the paper and open-source project, ‚ÄúFinGPT: Open-Source Financial Large Language Models‚Äù. It aims to democratize access to high-quality financial data and stimulate innovation in applications like robo-advising and algorithmic trading. Collaboration within the AI4Finance community is encouraged, and the associated code repositories are available for further development. 

The FinGPT code can be found here: https://lnkd.in/dAzjMBB4",Hudson & Thames,2023-08-21T12:35:00Z,2023-09-06T11:45:19Z
173,Large Language Models with Langchain - The Ultimate Guide,IbMtSXTJ0ic,246,53:20,"In this video, we will guide you through the process of building large language models using Langchain. We will cover everything from the basics of Langchain to the advanced techniques that can take your language models to the next level. By the end of this video, you will have all the knowledge you need to create your own powerful language models.

00:00 - Agenda
00:30 - Why Langchain?
02:07 - What is Langchain?
04:52 - How to get started?

Table of Contents:

06:11 - Installation
07:23 - Setup OpenAI API key

Language components
08:05 - LLM and Chat Models in Langchain
12:46   - Prompt Engineering using ChatPromptTemplate in Langchain
22:26    - Output parser
27:21   - Chain [LLMChain and SequentialChain]
37:57   - Memory
45:52 - Build a ChatBot on your own data

Source code: https://bit.ly/langchain-recipes

----------------------------------
Twitter: https://twitter.com/TRJ_0751
LinkedIn: https://www.linkedin.com/in/jaintarun75/
Instagram: https://instagram.com/jaintarun.ai
GitHub: https://github.com/lucifertrj
-----------------------------------

#AI #LLM",AI With Tarun,2023-08-21T11:30:11Z,2023-09-06T11:45:19Z
174,LabTwin l Large Language models l The Lab of the Future is now.,y13NxZT2hPs,30,1:,"With the integration of the new Large Language Models (LLM) capabilities into LabTwin, scientists can effortlessly gain answers to their experimental queries. This advancement enables access to scientific or organizational information and even troubleshooting tips from software.
Welcome to the AI- and Voice-powered Lab of the future. If you‚Äôre interested in understanding how LabTwin can enhance efficiency within your organization, feel free to reach out or schedule a demo (labtwin.com/demo).
#labtechnology #labofthefuture #technology #laboratory #scientist #researchanddevelopment #digitaltransformation #digitaladoption #llm
#largelanguagemodels #largelanguagemodel",LabTwin,2023-08-21T11:09:39Z,2023-09-06T11:45:19Z
175,LLMs vs LMs in Prod // Denys Linkov // LLMs in Production Conference Part 2,y1HqPNwBp0U,807,24:44,"// Abstract
What are some of the key differences in using 100M vs 100B parameter models in production? In this talk, Denys from Voiceflow will cover how their MLOps processes have differed between smaller transformer models and LLMs. He'll walk through how the main 4 production models Voiceflow uses differ, and the processes plus product planning behind each one. The talk will cover prompt testing, automated training, real-time inference, and more!

// Bio
Denys is the ML lead at Voiceflow focused on building the ML platform and data science offerings. His focus is on real-time NLP systems that help Voiceflow‚Äôs 60+ enterprise customers build better conversational assistants. His role alternates between product management, ML research, and ML platform building. Previously he worked at a large global bank as a senior cloud architect.",MLOps.community,2023-08-21T10:44:48Z,2023-09-06T11:45:19Z
176,Self-Consistency Improves Chain of Thought Reasoning in Language Models,XKY2ThptBWs,221,5:38,https://arxiv.org/abs/2203.11171,Vivek Haldar,2023-08-21T06:05:37Z,2023-09-06T11:45:19Z
177,How To Deploy Large Language Models Into Production,qHWq5WnRUfQ,46,30,"In this tutorial, you will learn how to create an API server to serve your model using Postman. 

Full video link: https://youtu.be/6CRrhxpF8WI

#artificialintelligence #technology #largelanguagemodels #python",ZoumDataScience,2023-08-21T01:54:24Z,2023-09-06T11:45:19Z
178,Introduction to Natural Language Processing (NLP) &amp; Large Language Models (LLM),o1q5qhwz_xg,8,1:15:55,#naturallanguageprocessing #naturallanguagegeneration #nlp #llm #largelanguagemodels #huggingface #chatgpt #gpt4 #bard #palm #bertholdt #openai #google #microsoft #microsoftbing #sentimentanalysis,Galois Insights Limited,2023-08-20T19:35:33Z,2023-09-06T11:45:19Z
179,Large Language Models Meet Copyright,ICd5l4RefmA,68,2:2,"Let's talk about how copyright intersects large language models around training LLMs, outputs of LLMs, and watermarking mechanisms. 
#datascience #machinelearning #largelanguagemodels #copyright

A lot of this material is derived from a brilliant talk by leading copyright scholar Pamela Samuelson 

Large Language Models Meet Copyright Law
https://www.youtube.com/watch?v=MFKV48ikV5E&ab_channel=SimonsInstitute
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚òÖ Rajistics Social Media ¬ª 
‚óè Link Tree: https://linktr.ee/rajistics
‚óè LinkedIn: https://www.linkedin.com/in/rajistics/
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ","Rajistics - data science, AI, and machine learning",2023-08-20T19:27:35Z,2023-09-06T11:45:19Z
180,Generative AI Tutorial | Large Language Model (LLM) - Season 1 Episode 2,3c5Vr8Z8o4c,17,12:2,"We are starting an Generative AI tutorial for beginners. This will be the second episode in season 1. In this introduction video we will discuss following topics,

Large Language Model Overview
Large Language Model Key Features
Large Language Model Application

Do you want to learn Generative AI Tutorial course from JanaAI? 

Website: 

https://janaai.com

For More Queries WhatsApp or Call on  :  +91-9339628543",JanaAI,2023-08-20T12:31:22Z,2023-09-06T11:45:19Z
181,"Ethical Considerations in Large Language Models Lessons in Bias, Fairness, and Responsible AI",LS07_w573TY,19,3:15,"THE STUDENT SUCCESS COACH
My name is Peter Alkema and I‚Äôm here to help you be successful in your studies, career and life.

üòò DIGITAL MASTERCLASS - https://www.udemy.com/course/digital-disruption-mind-blowing-mastery/?referralCode=382F334153C060EE52D7
üöÄ MANAGEMENT SKILLS MASTERCLASS - https://www.udemy.com/course/new-manager-masterclass/?referralCode=FDFA8618A6FC722432D8
ü§ñ CHATGPT - https://www.udemy.com/course/trend-spotter/?referralCode=A527704077A08D2888AD 

FREE RESOURCES
üîî Subscribe to this YouTube channel - https://www.youtube.com/channel/UCRoBccwWx8lC4D6qO3U8DkQ?sub_confirmation=1
üíå Subscribe to my mailing list ‚Äì https://studentsuccess.coach/#link-popup
üë• Join our Facebook group ‚Äì https://www.facebook.com/groups/1067523283704724
üåç My websites ‚Äì https://studentsuccess.coach/ & https://peteralkema.com/ 

COURSES FOR STUDENTS
‚úçüèº Academic Writing ‚Äì https://www.udemy.com/course/academic-writing-success01/?referralCode=9B3984B44BC84DA0AEDF
‚úÖ Referencing With EndNote ‚Äì https://www.udemy.com/course/academic-referencing/?referralCode=F446CBB5D9393B52F368
üìò Getting Your Research Published ‚Äì https://www.udemy.com/course/get-published/?referralCode=E6E389948B932B4E8F8E
üôåüèº Finish Your Proposal ‚Äì https://www.udemy.com/course/finish-your-research-proposal/?referralCode=BFCC4456BE8DF070821D
‚≠êÔ∏è Finish Your Thesis ‚Äì https://www.udemy.com/course/pass-your-thesis/?referralCode=CD0334A328D52C519B0F

COURSES FOR ENTREPRENEURS
üì£ Podcasting ‚Äì https://www.udemy.com/course/launch-a-podcast/?referralCode=29E7D57ADC3822A9B378
üì± Kindle ‚Äì https://www.udemy.com/course/publish-amazon-kindle-ebook/?referralCode=1644842658A66ED329E2
üé• Webinars ‚Äì https://www.udemy.com/course/get-started-with-webinars/?referralCode=DC9A288CE8A422AB193A
üìá Blogging ‚Äì https://www.udemy.com/course/learn-blogging/?referralCode=EE790A28564ADD522045 

COURSES FOR CAREER GROWTH
üìÑ CVs ‚Äì https://www.udemy.com/course/cv-masterclass/?referralCode=535177FAD317114EA9A8 
üëî Interviews ‚Äì https://www.udemy.com/course/interview-like-a-boss/?referralCode=D59751D19B1D3E2C7F98 
üí∞ Job Prospects ‚Äì https://www.udemy.com/course/accelerate-your-career-today/?referralCode=C50E0A74D17175CDF7DF 
üé§ Presentations ‚Äì https://www.udemy.com/course/powerful-powerpoint/?referralCode=E30FBCA22FB9212B4477
üó£ Communication ‚Äì https://www.udemy.com/course/high-impact-communication-skills/?referralCode=C79B490C8F99289A090A 
‚è∞ Beat Procrastination ‚Äì https://www.udemy.com/course/beat-procrastination-today/?referralCode=8DF7DA20D0C71854ABF4
üï∫üèº Leadership ‚Äì https://www.udemy.com/course/leadership-skills-workplace/?referralCode=D0BC5C1D90411B9C807B 

COURSES FOR BUSINESS
üìÄ Digital Disruption ‚Äì https://www.udemy.com/course/digital-masterclass/?referralCode=D9B3AACB17CD0CC973B3
üí≥ Procurement ‚Äì https://www.udemy.com/course/procurement-masterclass/?referralCode=F5D3AFA11E9C9EAEB185
üìñ Learning Culture ‚Äì https://www.udemy.com/course/learning-culture/?referralCode=2BAB1E06ED83397B18AE
üíª Online Workshops ‚Äì https://www.udemy.com/course/online-workshop-facilitation/?referralCode=1EEF1978B645C4C2F7C3
üéÆ Hackathons ‚Äì https://www.udemy.com/course/high-performing-teams/?referralCode=C69962CE284EB7B71B80",The Student Success Coach,2023-08-20T10:00:25Z,2023-09-06T11:45:19Z
182,Practical Advice for Working with Large Language Models - Ned Letcher,FYyDw_s-Zmo,51,43:12,"Practical Advice for Working with Large Language Models - Ned Letcher

From the July 2023 Melbourne Machine Learning and AI Meetup: https://www.meetup.com/machine-learning-ai-meetup/events/293542342/

Talk Description: In this talk, I‚Äôll dig into the practical side of pathways for starting your innovation journey into leveraging large language models (LLMs). Some of the core questions we‚Äôll cover: choosing between self-hosting and managed services over APIs, different strategies for aligning LLMs to your domain and their associated dependencies: prompt-engineering vs supervised fine-tuning vs task fine-tuning through reinforcement learning through human feedback; all being subjected to the question of which pathways are enterprise-ready?

Speaker Bio: Ned Letcher is a lead data science engineer at Thoughtworks, where he helps organisations design and build data-powered products and applications, and uplift data and AI strategy. He has a fondness for Python, NLP, and data-viz, which has seen him speaking at and sometimes organising a range of meetups, trainings, and conferences. According to Midjourney's /describe command, he rocks a woodland goth and poetcore aesthetic. 

Link to slides: https://drive.google.com/file/d/1-znstD9UDnMLjH4slEYNSMSGVE0YMySK/view?usp=sharing",Machine Learning and AI Meetup,2023-08-20T09:54:58Z,2023-09-06T11:45:19Z
183,Generative AI Weekly Research Highlights | Aug 14 -Aug 20,NMZEuAgCZ6I,134,2:55,"1) A Survey on Model Compression for Large Language Models [https://arxiv.org/pdf/2308.07633.pdf]
2) Large Language Models for Information Retrieval: A Survey [https://arxiv.org/pdf/2308.07107.pdf]
3) EcomGPT: Instruction-tuning Large Language Model with Chain-of-Task Tasks for E-commerce [https://arxiv.org/pdf/2308.06966.pdf]
4) Large Language Models for Telecom: Forthcoming Impact on the Industry [https://arxiv.org/pdf/2308.06013.pdf]
5) Time Travel in LLMs: Tracing Data Contamination in Large Language Models [https://arxiv.org/pdf/2308.08493.pdf]
6) Through the Lens of Core Competency: Survey on Evaluation of Large Language Models [https://arxiv.org/pdf/2308.07902.pdf]
7) SOLVING CHALLENGING MATH WORD PROBLEMS USING GPT-4 CODE INTERPRETER WITH CODE-BASED SELF-VERIFICATION [https://arxiv.org/pdf/2308.07921.pdf]
8) Robustness Over Time: Understanding Adversarial Examples‚Äô Effectiveness on Longitudinal Versions of Large Language Models [https://arxiv.org/pdf/2308.07847.pdf]

#generativeai,#promptengineering,#largelanguagemodels,#openai,#chatgpt,#gpt4,#ai,#abcp,#prompt,#responsibleai,#promptengineer,#chatgptprompt,#anybodycanprompt,#artificialintelligence,", ABCP | Anybody Can Prompt,2023-08-20T04:52:07Z,2023-09-06T11:45:19Z
184,Large Language Model #generativeai #naturallanguageprocessing #deeplearning #artificialintelligence,T637PkLSr3I,74,10:,"A large language model (LLM) is a type of machine learning model that can perform a variety of natural language processing (NLP) tasks such as generating and classifying text, answering questions in a conversational manner, and translating text from one language to another. The label ‚Äúlarge‚Äù refers to the number of values (parameters) the language model can change autonomously as it learns. Some of the most successful LLMs have hundreds of billions of parameters.

LLMs are trained with immense amounts of data and use self-supervised learning to predict the next token in a sentence, given the surrounding context. The process is repeated over and over until the model reaches an acceptable level of accuracy.

#artificialintelligence #deeplearning #generativeai #datascience #data  #naturallanguageprocessing #largelanguagemodels #datascience",Rethink The Future,2023-08-19T12:16:37Z,2023-09-06T11:45:19Z
185,Large Language Model Overview,RbSCfBRbftA,39,1:,"#openaiapi #openai #AI #chatgpt #openaiapirisks #codersarts  The Truth About OpenAI API: What You're Not Being Told

Watch full video : https://youtu.be/kmTm9uBKn0Y
AI Projects: https://www.ai.codersarts.com/projects

Need More Help in Machine Learning?
===================================
‚úÖMachine Learning Assignment Help : https://www.codersarts.com/machine-learning-assignment-help
‚úÖDeep Learning Assignment Help: https://www.codersarts.com/deep-learning-assignment-help
‚úÖNLP Assignment Help: https://www.codersarts.com/nlp-assignment-help
‚úÖData Visualization Assignment Help: https://www.codersarts.com/data-visualization-assignment-help 
‚úÖComputer Vision Assignment Help: https://www.codersarts.com/computer-vision-assignment-help
‚úÖFace Recognition Assignment Help: https://www.codersarts.com/face-recognition-project-help
‚úÖR Programming Assignment Help : https://www.codersarts.com/r-programming-assignment-help



üì≤Follow us on our Social Media Handles : 
=================================
‚û°Ô∏è https://www.ai.codersarts.com/large-language-model
üîó Main Website: https://www.codersarts.com/
üìö Codersarts Training: https://www.training.codersarts.com/
ü§ñ Codersarts AI: https://www.ai.codersarts.com/
üì∑ Instagram: https://www.instagram.com/codersarts/?hl=en
üìò Facebook: https://www.facebook.com/codersarts2017
üíº LinkedIn: https://in.linkedin.com/company/codersarts

Join this channel to get access to perks:
https://www.youtube.com/channel/UC1nrlkYcj3hI8XnQgz8aK_g/join",CodersArts,2023-08-19T09:30:08Z,2023-09-06T11:45:19Z
186,WizardMath from Microsoft - Best Open Source Math LLM with Reinforced Evol-Instruct,WeQjkWPKvXM,1041,8:25,"WizardMath is a new best open source large language model for mathematical reasoning inspired by WizardLM, which was introduced in a research paper from Microsoft titled: WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct.
In this video we explain the paper in details to help you understand how this model was created and what is Reinforced Evol-Instruct.

We start by explaining the first step in training WizardMath which is supervised fine-tuning, where the researchers start with a LLaMA-2 model as the base model and fine-tune it on a dataset they construct with math instruction and response pairs.
Then, we cover Evol-Instruct which is an essential background for Reinforced Evol-Instruct.
Following that, we explain the Reinforced Evol-Instruct method, which is a novel reinforcement learning approach introduced in the paper that leverage Evol-Instruct.
We explain what reward models are used, an instruction reward model to reward instructions that are generated using Evol-Instruct, and a Process-supervised reward model to asses the correctness of the steps in the model answers. The second reward model was inspired by Open AI's paper titled Let's Verify Step by Step, which shows the importance of supervising the process to reach a solution, in order to improve mathematical reasoning.
We then explain how these two reward models are created, and then we show how they are used during PPO training.
We finish by looking at some of the impressive results which are shared in the paper.

Blog post - https://aipapersacademy.com/wizardmath-best-open-source-math-llm-via-reinforced-evol-instruct/
Paper & Code - https://github.com/nlpxucan/WizardLM/tree/main/WizardMath

üëç Please like & subscribe if you enjoy this content
----------------------------------------------------------------------------------
Support us - https://paypal.me/aipapersacademy
----------------------------------------------------------------------------------

Chapters:
0:00 Introducing WizardMath
0:56 Supervised Fine-tuning
2:14 Evol-Instruct
4:03 Reinforced Evol-Instruct
7:20 WizardMath Results",AI Papers Academy,2023-08-19T05:34:18Z,2023-09-06T11:45:19Z
187,Large Language Models with Semantic Search,GXvKOkmk25E,61,2:49,"We just released ""Large Language Models with Semantic Search‚Äù, built with Cohere, and taught by Jay Alammar and Luis Serrano. Search is a key part of many applications. Say, you need to retrieve documents or products in response to a user query; how can LLMs help? You‚Äôll learn about (i) Embeddings, to retrieve a collection of documents loosely related to a query, and (ii) LLM assisted re-ranking, to rank them precisely according to relevance. You‚Äôll also go through code showing how to tie all this together to build a complete search system for retrieving relevant Wikipedia articles. Please check it out! https://lnkd.in/grzWCJdSWe just released ""Large Language Models with Semantic Search‚Äù, built with Cohere, and taught by Jay Alammar and Luis Serrano. Search is a key part of many applications. Say, you need to retrieve documents or products in response to a user query; how can LLMs help? You‚Äôll learn about (i) Embeddings, to retrieve a collection of documents loosely related to a query, and (ii) LLM assisted re-ranking, to rank them precisely according to relevance. You‚Äôll also go through code showing how to tie all this together to build a complete search system for retrieving relevant Wikipedia articles. Please check it out! https://lnkd.in/grzWCJdS",School Of Thought,2023-08-19T04:24:48Z,2023-09-06T11:45:19Z
188,Webinar: Bringing Large Language Models to Life with AI Humans,oQ-TAtteu6U,323,27:38,"Part of our monthly webinar series. This webinar demonstrates how to customize ChatGPT and connect with an AI Human. Also, a special guest from inwrold.ai.  
Visit us at: https://www.deepbrainai.io
#llm #customllm #aihuman #aigenerator #digitaltwin #virtualtwin #texttovideo #customavatars",DEEPBRAIN AI - AI for Human Life,2023-08-18T21:47:06Z,2023-09-06T11:45:19Z
189,Building and evaluating Generative AI applications for NLP  by   Divyansh Agarwal,K51ukf-0aAI,69,23:35,"Divyansh Agarwal, Sr. Research Engineer, Salesforce Speaking at Global AI Virtual Conference  Mar 29th to 31st, 2023.

Topic: Building and evaluating Generative AI applications for NLP

Abstract
The talk will focus on the different aspects of building interactive AI systems that use large language models (LLMs). We will look into the trend of LLM development and the evaluation of systems from the lens of academic research in NLP. The talk will go over how effective LLMs like chatGPT, Claude, Bard etc. are, at different problems in natural language generation space. We'll go over how generative AI has brought focus back to the data and ethical development of AI Systems. We will discuss the field of HCI-NLP, and the successful design of Generative AI applications.
 
Profile
Divyansh is a Sr. Research Engineer with the conversational AI team at Salesforce Research. His work involves developing and studying AI applications that allow real-world user interaction with LLMs. He is active in NLP research on topics like text summarization, factuality and natural language generation. Divyansh graduated from the Language Technologies Institute (LTI) at Carnegie Mellon University (CMU) in Pittsburgh. Divyansh is interested in the interaction of humans with AI technologies, the interplay of ethics and privacy in the mix, and how that can inform the future generation of AI applications.


Event Agenda: https://www.globalbigdataconference.com/virtual/global-artificial-intelligence-conference/schedule-138.html

Speaker's: https://www.globalbigdataconference.com/virtual/global-artificial-intelligence-conference/event-138.html#speakers1

View More: https://www.globalbigdataconference.com/virtual/global-artificial-intelligence-conference/event-138.html",Global Big Data Conference,2023-08-18T20:42:28Z,2023-09-06T11:45:19Z
190,Large Language Models Bootcamp Information Session | LLMs Bootcamp Information Session,qYWCYyMOZoM,403,50:50,"üíº Learn to build LLM-powered apps in just 40 hours with our Large Language Models bootcamp: https://hubs.la/Q01ZZGL-0

-- 

What to Expect During the Information Session:
‚Ä¢ Overview of the bootcamp structure and agenda.
‚Ä¢ In-depth exploration of the core topics covered.
‚Ä¢  Insight into hands-on projects and real-world applications.
‚Ä¢ Meet the expert trainers and learn about their experiences.

Who Should Attend?
Whether you're an AI enthusiast, a tech professional, a creative thinker, or simply someone eager to explore the possibilities of large language models, this event is tailored for you. No prior experience is required ‚Äì just an open mind and a passion for learning!

-- 

Table of Contents:
0:00 ‚Äì Introduction
0:33 ‚Äì About Data Science Dojo
1:32 ‚Äì Story of this bootcamp
1:45 ‚Äì Common LLM use cases
5:42 ‚Äì About the bootcamp
9:20 ‚Äì Prerequisites
10:51 ‚Äì Technology stack
11:53 ‚Äì Generative AI and LLM foundations
12:56 ‚Äì Embeddings and vector databases
13:58 ‚Äì Semantic search
15:00 ‚Äì Prompt engineering
15:37 ‚Äì Orchestration framework
17:39 ‚Äì Autonomous agent
18:35 ‚Äì LLM Ops
19:04 ‚Äì Project
20:04 ‚Äì Model fine-tuning
21:42 ‚Äì Partnerships
27:08 ‚Äì Next tutorial
39:18 ‚Äì Bootcamp schedule
49:53 ‚Äì Q/A

#largelanguagemodels #llm #generativeai #bootcamp #promptengineering",Data Science Dojo,2023-08-18T20:25:40Z,2023-09-06T11:45:19Z
191,üèîÔ∏è Chat with Open Large Language Models   ÿπÿ±ÿ®Ÿä,kpDhbERjY5U,33,2:20,"ÿ£ŸáŸÑÿßŸã ÿ®ŸÉŸÖ ŸÖÿ™ÿßÿ®ÿπŸäŸÜÿß ÿßŸÑÿ£ÿπÿ≤ÿßÿ°ÿå ŸÜŸàÿØ ÿ£ŸÜ ŸÜÿ¥ŸÉÿ±ŸÉŸÖ ÿπŸÑŸâ ŸÖÿ¥ÿßŸáÿØÿ© ŸÅŸäÿØŸäŸàŸÜÿß ŸàŸÜÿ£ŸÖŸÑ ÿ£ŸÜ ŸäŸÉŸàŸÜ ŸÇÿØ ŸÜÿßŸÑ ÿ•ÿπÿ¨ÿßÿ®ŸÉŸÖ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÜŸÇÿ± ÿπŸÑŸâ ÿ≤ÿ± ÿßŸÑÿ•ÿπÿ¨ÿßÿ® ŸàÿßŸÑÿßÿ¥ÿ™ÿ±ÿßŸÉ ŸÅŸä ÿßŸÑŸÇŸÜÿßÿ© ŸÑŸäÿµŸÑŸÉŸÖ ŸÉŸÑ ÿ¨ÿØŸäÿØ.
https://chat.lmsys.org/


Llama 2: open foundation and fine-tuned chat models by Meta Vicuna: a chat assistant fine-tuned from LLaMA on user-shared conversations by LMSYS WizardLM: an instruction-following LLM using evol-instruct by Microsoft
MPT-Chat: a chatbot fine-tuned from MPT by MosaicML Guanaco: a model fine-tuned with QLoRA by UW ChatGLM: an open bilingual dialogue language model by Tsinghua University
Alpaca: a model fine-tuned from LLaMA on instruction-following demonstrations by Stanford FastChat-T5: a chat assistant fine-tuned from FLAN-T5 by LMSYS

  ŸÜÿ¥ÿ±ŸÉ ŸÑŸÑŸÖŸÇÿ∑ÿπ ŸáŸà ÿßŸÉÿ®ÿ± ÿØÿπŸÖ ŸÖŸÖŸÉŸÜ ÿ™ŸÇÿØŸÖŸá ŸÑŸä ...

ÿ£ÿ™ŸÖŸÜŸâ ÿ£ŸÜ ŸäŸÜÿßŸÑ ÿßŸÑÿ¥ÿ±ÿ≠ ÿ£ÿπÿ¨ÿßÿ®ŸÉŸÖ 

......................................................................
https://bimarabia.com/OmarSelim/
https://st-solutions.net/

ÿ¥Ÿäÿ± ŸÖÿ¥ÿßÿ±ŸÉÿ©  #BIMarabia
 
ÿßÿ¥ÿ™ÿ±ŸÉ ŸÅŸä ÿßŸÑŸÇŸÜÿßÿ© ŸÑŸÖÿ™ÿßÿ®ÿπÿ© ÿßŸÑÿ¥ÿ±Ÿàÿ≠ÿßÿ™ ÿßŸÑÿ¨ÿØŸäÿØÿ©

videos 
https://www.youtube.com/channel/UCZYaOLTtPmOQX1fgtDFW52Q?sub_confirmation=1
 
ÿ®ŸäŸÖ ÿßÿ±ÿßÿ®Ÿäÿß 
http://bimarabia.com/
  
‚ù§Ô∏è ÿ±ÿßÿ®ÿ∑ ÿßŸÑÿßÿ¥ÿ™ÿ±ÿßŸÉ ŸÅŸä ÿßŸÑŸÇŸÜÿßÿ©
https://www.youtube.com/channel/UCZYaOLTtPmOQX1fgtDFW52Q?sub_confirmation=1

‚ù§Ô∏è ÿ±Ÿàÿßÿ®ÿ∑ ÿßŸÑÿ™ŸàÿßÿµŸÑ 
‚úÖ ÿßŸÜÿ≥ÿ™ÿ¨ÿ±ÿßŸÖ
https://www.instagram.com/omar_selim/ 
 
Ÿàÿ•ÿ∞ÿß ŸÉŸÜÿ™ ÿ™ÿ±ÿ∫ÿ® ŸÅŸä ÿØÿπŸÖ ÿßŸÑŸÇŸÜÿßÿ©ÿå ŸäŸÖŸÉŸÜŸÉ ÿ¥ÿ±ÿßÿ° ŸÑŸÜÿß ŸÅŸÜÿ¨ÿßŸÜ ŸÇŸáŸàÿ© ÿπÿ®ÿ± ÿßŸÑÿ±ÿßÿ®ÿ∑ ÿßŸÑÿ™ÿßŸÑŸä:
https://paypal.me/OSELIM
 

‚úÖ ÿßŸÑŸÅŸäÿ≥ÿ®ŸàŸÉ
https://www.facebook.com/omrselm/

‚úÖ ÿ™ŸàŸäÿ™ÿ±
https://twitter.com/bimarabia 

‚úÖ ŸÑŸäŸÜŸÉÿØ ÿßŸÜ
https://www.linkedin.com/in/omarslm/

‚úÖ ŸÇŸÜÿßÿ© ÿßŸÑÿ™ŸÑÿ¨ÿ±ÿßŸÖ
https://t.me/bimarabia1 

‚úÖ ÿßŸÑŸÖŸàŸÇÿπ ÿßŸÑÿßŸÑŸÉÿ™ÿ±ŸàŸÜŸä ÿßŸÑÿ¥ÿÆÿµŸä
https://bimarabia.com/OmarSelim/

 


https://linktr.ee/omarselim
https://taplink.cc/omarselim


augmented reality
https://www.youtube.com/watch?v=-9c5h0X-Kqw&list=PLNMim060_nUKpt2st91YUPa7BqWd0U2eb
open source ŸÖŸÅÿ™Ÿàÿ≠ÿ© ÿßŸÑŸÖÿµÿØÿ±
https://www.youtube.com/watch?v=WNYyejjLa-s&list=PLNMim060_nUK6qoVzrpjLucG_aBNaz_Ny


revit workshop  Ÿàÿ±ÿ¥ÿ© ÿπŸÖŸÑ ÿ±ŸäŸÅŸäÿ™
https://www.youtube.com/watch?v=-FIZBNN7CLk&list=PLNMim060_nULOxkcpmsGdaRXRnEj7rmGC

OPEN STREET MAP
https://www.youtube.com/watch?v=QKHnpu5birw&list=PLNMim060_nUJBibv97w-SfqGMjQCDc6xT
ÿßŸÑŸÖÿØŸÜ ÿßŸÑÿ∞ŸÉŸäÿ©
https://www.youtube.com/watch?v=1nGsbGafZ6c&list=PLNMim060_nUKxO8GJj5c-9POTgiCfOdmE
ÿßŸÑÿßÿ≥ÿ™ÿØÿßŸÖÿ©
https://www.youtube.com/watch?v=m_dma-4wOJU&list=PLNMim060_nUKIQ9OEPA5xGjQ471AQyp3F

ÿßŸÑÿ∞ŸÉÿßÿ° ÿßŸÑÿßÿµÿ∑ŸÜÿßÿπŸä 
https://www.youtube.com/watch?v=UWmW84ZBrbg&list=PLNMim060_nUJs5lSTwbFK8Pe1BCUPT_EB",ÿπŸÖÿ± ÿ≥ŸÑŸäŸÖ - ÿ®ŸäŸÖ ÿßÿ±ÿßÿ®Ÿäÿß ,2023-08-18T20:12:04Z,2023-09-06T11:45:19Z
192,Generative AI with Large Language Models Course!,2Da_PdILMA0,526,5:11,"Here's the Course (I may get a commission for purchases): https://imp.i384100.net/Jz44or

Prompt Engineering Course: https://imp.i384100.net/vNVWeA",Greg Hogg,2023-08-18T19:40:05Z,2023-09-06T11:45:19Z
193,What are Large Language Models?,EAI-Nl5RV1I,214,3:41,"what is large language model? delve into the fascinating topic of large language models and witness the evolution of AI technology in real-time.Starting with an overview of the history, we trace the origins of large language models and their intriguing development journey. From the early days of language processing to the current advancements, this video provides an in-depth analysis of how these models have gone from mere concepts to groundbreaking realities. Discover how large language models harness the power of artificial intelligence to comprehend and generate human-like text at an unprecedented scale. We discuss their underlying architecture, training methodologies, and the incredible computational resources required to unleash their full potential. Furthermore, we explore the revolutionary impact of large language models across various industries, including natural language understanding, machine translation, question-answering systems, and content creation. Witness how these models are transforming the way we communicate, research, and interact with technology. Our experts shed light on the challenges faced during the development of large language models, including ethical considerations, bias mitigation, and data privacy. Gain insights into the precautions taken to ensure responsible AI development and usage. Prepare to be amazed as we showcase real-world examples of large language models in action, highlighting their unparalleled ability to generate creative text, assist with complex tasks, and enhance user experiences across a multitude of applications. Join us on this exhilarating journey through the evolution of large language models and see firsthand how cutting-edge AI technology is shaping our future. Stay tuned for mind-blowing insights, expert analysis, and the limitless potential of these incredible language models.",Global Techtricks,2023-08-18T18:15:14Z,2023-09-06T11:45:19Z
194,Walkthrough Large Language Models (LLMS) in Healthcare | Foundational concepts,0nnKRiQe1NI,60,7:28,"Welcome to the cutting-edge world of medical innovation powered by Language Models like ChatGPT! In this video, we explore how these models are revolutionizing the healthcare industry, from simplifying radiology reports to predicting patient health outcomes.

We'll delve into:
1Ô∏è‚É£ Self-supervision Training: Discover how models like GPT-3 learn from their own input data, without the need for human annotation.
2Ô∏è‚É£ Autoregressive Training Objective: Understand how models predict the next word to learn language structure, grammar, and semantics.
3Ô∏è‚É£ Tuning & Instruction Turning: Learn how these models are adapted to specific tasks and domains.
4Ô∏è‚É£ GPTs Immense Training Data: See the massive scale at which GPT is trained.
5Ô∏è‚É£ Two Types of Medical LLMs: We explore Medical LLMs trained on documents and medical codes.
6Ô∏è‚É£ Notable Examples: Meet Stanford's Alpaca model, a revolutionary development matching GPT-3's performance at a fraction of the parameters.
7Ô∏è‚É£ Real-world Impact: Learn how this technology offers a new understanding of patient care, medical records, and predictive health analytics.

#gpt  , #languagemodels , #healthcarerevolution , #medicalresearch  , #aiinhealthcare",Danish Bhatti,2023-08-18T18:10:23Z,2023-09-06T11:45:19Z
195,What are Large Language Models?,ZK_FIWy-hJ8,5,10:36,"Hi, In this channel I will share my knowledge with you about digital marketing and also tell you which ai is used for what purpose, and share the top best and free AI tools which will be free at least. in this video, I will tell you what is a large language model is? 
                           DON'T FORGET TO SUBSCRIBE, LIKE, AND SHARE MY CHANNEL WITH OTHERS.",Mr-Za,2023-08-18T15:24:38Z,2023-09-06T11:45:19Z
196,Cyberangriffe auf ChatGPT und Co. | OWASP Top 10 f√ºr Large Language Model Applications,v2Q9toecZVs,3915,6:51,"‚ñ∫ Hacking mit Python https://amzn.to/3pxVnmh (*)
‚ñ∫ Mein Python-Buch https://amzn.to/3ARMbw8 (*)

Inhalt üìö
In diesem Video stelle ich dir die OWASP Top 10 for Large Language Model Applications. Die OWASP Top 10 listet normalerweise h√§ufige Angriffe auf Webanwendungen auf wie z. B. Injection oder Broken Authentication. Da immer mehr Unternehmen KI fest in ihre Anwendungen bzw. Produkte integrieren, ist der Bedarf an Sicherheitsexperten, die um Angriffe auf Large Language Models (LLM) wissen, h√∂her als je zuvor.
#OWASP #ChatGPT #LLM

00:00 | Einf√ºhrung
00:46 | Neue Gefahren
01:43 | OWASP Top 10
02:48 | LLM01 Prompt Injection
03:10 | LLM02 Insecure Output Handling
03:34 | LLM03 Training Data Poisoning
03:54 | LLM04 Model Denial of Service
04:25 | LLM05 Supply Chain Vulnerabilities
04:48 | LLM06 Sensitive Information Disclosure
05:12 | LLM07 Insecure Plugin Design
05:28 | LLM08 Excessive Agency
05:46 | LLM09 Overreliance
06:09 | LLM10 Model Theft

Zur OWASP Top 10 for Large Language Model Applications https://owasp.org/www-project-top-10-for-large-language-model-applications/
https://www.zdf.de/nachrichten/digitales/chatgpt-anwalt-klage-gericht-antrag-recherche-scheitern-100.html

EQUIPMENT(*)
üé§ Mikrofon https://amzn.to/3N0CHCL
‚úÇÔ∏è Schnittprogramm https://amzn.to/3CZ217J
üíª Mein Laptop https://amzn.to/3ikMd5V
üñ•Ô∏è Bildschirm https://amzn.to/3ig3yN5

SUPPORT
‚ñ∫ Patreon https://patreon.com/florian_dalwigk
‚ñ∫ Unterst√ºtze mich durch einen Kauf auf Amazon. F√ºr dich entstehen keine Mehrkosten! (*) https://amzn.to/3LgyglY

SOCIAL MEDIA
üí¨ Discord: https://discord.gg/X7QU7GXC2u
üí° Website: https://www.florian-dalwigk.de
üì± TikTok: https://www.tiktok.com/@florian.dalwigk
ü§≥ Instagram: https://www.instagram.com/florian.dalwigk
üê¶ Twitter: https://twitter.com/florian_dalwigk
üìß E-Mail: mailto:info@florian-dalwigk.de

(*) Bei den Amazon-Links (https.//amzn.to/???????) handelt es sich um Affiliate-Links. Wenn du etwas √ºber diesen Link kaufst, bekomme ich eine kleine Provision. Der Preis √§ndert sich nicht, wenn du √ºber diesen Link einkaufst. Vielen Dank f√ºr deine Unterst√ºtzung.",Florian Dalwigk,2023-08-18T15:13:11Z,2023-09-06T11:45:19Z
197,"Deployment Considerations for large language models: latency, throughput, accuracy, and cost.",wLi72_NkJ3k,56,1:27,"Latency is a key factor, but there are others when thinking about deploying large language models. Let‚Äôs discuss tradeoffs between latency, throughput, accuracy, and cost.

Latency Numbers Every Programmer Should Know - https://gist.github.com/jboner/2841832

Response Time 3 Limits - https://www.nngroup.com/articles/response-times-3-important-limits/

Background by Valentin Petkov: https://unsplash.com/photos/z06oDT-8pKQ
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚òÖ Rajistics Social Media ¬ª 
‚óè Link Tree: https://linktr.ee/rajistics
‚óè LinkedIn: https://www.linkedin.com/in/rajistics/
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ","Rajistics - data science, AI, and machine learning",2023-08-18T14:56:04Z,2023-09-06T11:45:19Z
198,"Development with Large Language Models Tutorial ‚Äì OpenAI, Langchain, Agents, Chroma",xZDB1naRUlk,79942,2:2:54,"Welcome to this course about development with Large Language Models, or LLMs. Throughout this course, you will complete hands-on projects will help you learn how to harness LLMs for your own projects. You will build projects with LLMs that will enable you to create dynamic interfaces, interact with vast amounts of text data, and even empower LLMs with the capability to browse the internet for research papers.

This course was developed by @Luup.ai123 

Colab notebook for introduction to the API:https://colab.research.google.com/drive/1gi2yDvvhUwLT7c8ZEXz6Yja3cG5P2owP?usp=sharing
Github : https://github.com/pythonontheplane123/LLM_course_part_1

Join the Discord: https://discord.com/invite/Hq39QgRU
Twitter : https://twitter.com/AkshatNon

‚≠êÔ∏è Contents ‚≠êÔ∏è
‚å®Ô∏è (0:00:00) Brief introduction to LLMs
‚å®Ô∏è (0:11:49) Quick note from the future 
‚å®Ô∏è (0:12:04) Chatgpt playground (skip this is you know this already)
‚å®Ô∏è (0:18:21) GPT API basics (skip this is you know this already)
‚å®Ô∏è (0:30:43) Brief intro to chainlit
‚å®Ô∏è (0:31:33) Cloning chatgpt user interface
‚å®Ô∏è (0:45:37) Limitations of our interface
‚å®Ô∏è (0:47:48) Adding streaming, backend view, stop sequence button
‚å®Ô∏è (0:58:42) Introduction to vector databases
‚å®Ô∏è (1:04:42) Vector databases hands on
‚å®Ô∏è (1:12:10) QnA with Documents - .txt and .pdf
‚å®Ô∏è (1:23:32) Testing out our Q&A system
‚å®Ô∏è (1:27:22) Introduction to web-browsing and agents
‚å®Ô∏è (1:32:52) AI researcher 
‚å®Ô∏è (1:42:23) Human as a tool
‚å®Ô∏è (1:44:44) Mini code interpreter plugin(Replit tool)
‚å®Ô∏è (1:46:29) Searching youtube using agents
‚å®Ô∏è (1:49:19) Guide to explore more 
‚å®Ô∏è (1:50:33) Shell Tool
‚å®Ô∏è (1:55:43) Create your own tools
‚å®Ô∏è (2:01:19) Ending Notes

üéâ Thanks to our Champion and Sponsor supporters:
üëæ davthecoder
üëæ jedi-or-sith
üëæ ÂçóÂÆÆÂçÉÂΩ±
üëæ Agust√≠n Kussrow
üëæ Nattira Maneerat
üëæ Heather Wcislo
üëæ Serhiy Kalinets
üëæ Justin Hual
üëæ Otis Morgan

--

Learn to code for free and get a developer job: https://www.freecodecamp.org

Read hundreds of articles on programming: https://freecodecamp.org/news",freeCodeCamp.org,2023-08-18T13:47:56Z,2023-09-06T11:45:19Z
199,Brief introduction to Large Language Models,MD8HgJll_pk,107,11:11,,Luup,2023-08-18T13:36:47Z,2023-09-06T11:45:19Z
200,What are Large Language Models?,EAI-Nl5RV1I,214,3:41,"what is large language model? delve into the fascinating topic of large language models and witness the evolution of AI technology in real-time.Starting with an overview of the history, we trace the origins of large language models and their intriguing development journey. From the early days of language processing to the current advancements, this video provides an in-depth analysis of how these models have gone from mere concepts to groundbreaking realities. Discover how large language models harness the power of artificial intelligence to comprehend and generate human-like text at an unprecedented scale. We discuss their underlying architecture, training methodologies, and the incredible computational resources required to unleash their full potential. Furthermore, we explore the revolutionary impact of large language models across various industries, including natural language understanding, machine translation, question-answering systems, and content creation. Witness how these models are transforming the way we communicate, research, and interact with technology. Our experts shed light on the challenges faced during the development of large language models, including ethical considerations, bias mitigation, and data privacy. Gain insights into the precautions taken to ensure responsible AI development and usage. Prepare to be amazed as we showcase real-world examples of large language models in action, highlighting their unparalleled ability to generate creative text, assist with complex tasks, and enhance user experiences across a multitude of applications. Join us on this exhilarating journey through the evolution of large language models and see firsthand how cutting-edge AI technology is shaping our future. Stay tuned for mind-blowing insights, expert analysis, and the limitless potential of these incredible language models.",Global Techtricks,2023-08-18T18:15:14Z,2023-09-06T11:45:19Z
201,Walkthrough Large Language Models (LLMS) in Healthcare | Foundational concepts,0nnKRiQe1NI,60,7:28,"Welcome to the cutting-edge world of medical innovation powered by Language Models like ChatGPT! In this video, we explore how these models are revolutionizing the healthcare industry, from simplifying radiology reports to predicting patient health outcomes.

We'll delve into:
1Ô∏è‚É£ Self-supervision Training: Discover how models like GPT-3 learn from their own input data, without the need for human annotation.
2Ô∏è‚É£ Autoregressive Training Objective: Understand how models predict the next word to learn language structure, grammar, and semantics.
3Ô∏è‚É£ Tuning & Instruction Turning: Learn how these models are adapted to specific tasks and domains.
4Ô∏è‚É£ GPTs Immense Training Data: See the massive scale at which GPT is trained.
5Ô∏è‚É£ Two Types of Medical LLMs: We explore Medical LLMs trained on documents and medical codes.
6Ô∏è‚É£ Notable Examples: Meet Stanford's Alpaca model, a revolutionary development matching GPT-3's performance at a fraction of the parameters.
7Ô∏è‚É£ Real-world Impact: Learn how this technology offers a new understanding of patient care, medical records, and predictive health analytics.

#gpt  , #languagemodels , #healthcarerevolution , #medicalresearch  , #aiinhealthcare",Danish Bhatti,2023-08-18T18:10:23Z,2023-09-06T11:45:19Z
202,What are Large Language Models?,ZK_FIWy-hJ8,5,10:36,"Hi, In this channel I will share my knowledge with you about digital marketing and also tell you which ai is used for what purpose, and share the top best and free AI tools which will be free at least. in this video, I will tell you what is a large language model is? 
                           DON'T FORGET TO SUBSCRIBE, LIKE, AND SHARE MY CHANNEL WITH OTHERS.",Mr-Za,2023-08-18T15:24:38Z,2023-09-06T11:45:19Z
203,Cyberangriffe auf ChatGPT und Co. | OWASP Top 10 f√ºr Large Language Model Applications,v2Q9toecZVs,3915,6:51,"‚ñ∫ Hacking mit Python https://amzn.to/3pxVnmh (*)
‚ñ∫ Mein Python-Buch https://amzn.to/3ARMbw8 (*)

Inhalt üìö
In diesem Video stelle ich dir die OWASP Top 10 for Large Language Model Applications. Die OWASP Top 10 listet normalerweise h√§ufige Angriffe auf Webanwendungen auf wie z. B. Injection oder Broken Authentication. Da immer mehr Unternehmen KI fest in ihre Anwendungen bzw. Produkte integrieren, ist der Bedarf an Sicherheitsexperten, die um Angriffe auf Large Language Models (LLM) wissen, h√∂her als je zuvor.
#OWASP #ChatGPT #LLM

00:00 | Einf√ºhrung
00:46 | Neue Gefahren
01:43 | OWASP Top 10
02:48 | LLM01 Prompt Injection
03:10 | LLM02 Insecure Output Handling
03:34 | LLM03 Training Data Poisoning
03:54 | LLM04 Model Denial of Service
04:25 | LLM05 Supply Chain Vulnerabilities
04:48 | LLM06 Sensitive Information Disclosure
05:12 | LLM07 Insecure Plugin Design
05:28 | LLM08 Excessive Agency
05:46 | LLM09 Overreliance
06:09 | LLM10 Model Theft

Zur OWASP Top 10 for Large Language Model Applications https://owasp.org/www-project-top-10-for-large-language-model-applications/
https://www.zdf.de/nachrichten/digitales/chatgpt-anwalt-klage-gericht-antrag-recherche-scheitern-100.html

EQUIPMENT(*)
üé§ Mikrofon https://amzn.to/3N0CHCL
‚úÇÔ∏è Schnittprogramm https://amzn.to/3CZ217J
üíª Mein Laptop https://amzn.to/3ikMd5V
üñ•Ô∏è Bildschirm https://amzn.to/3ig3yN5

SUPPORT
‚ñ∫ Patreon https://patreon.com/florian_dalwigk
‚ñ∫ Unterst√ºtze mich durch einen Kauf auf Amazon. F√ºr dich entstehen keine Mehrkosten! (*) https://amzn.to/3LgyglY

SOCIAL MEDIA
üí¨ Discord: https://discord.gg/X7QU7GXC2u
üí° Website: https://www.florian-dalwigk.de
üì± TikTok: https://www.tiktok.com/@florian.dalwigk
ü§≥ Instagram: https://www.instagram.com/florian.dalwigk
üê¶ Twitter: https://twitter.com/florian_dalwigk
üìß E-Mail: mailto:info@florian-dalwigk.de

(*) Bei den Amazon-Links (https.//amzn.to/???????) handelt es sich um Affiliate-Links. Wenn du etwas √ºber diesen Link kaufst, bekomme ich eine kleine Provision. Der Preis √§ndert sich nicht, wenn du √ºber diesen Link einkaufst. Vielen Dank f√ºr deine Unterst√ºtzung.",Florian Dalwigk,2023-08-18T15:13:11Z,2023-09-06T11:45:19Z
204,"Deployment Considerations for large language models: latency, throughput, accuracy, and cost.",wLi72_NkJ3k,56,1:27,"Latency is a key factor, but there are others when thinking about deploying large language models. Let‚Äôs discuss tradeoffs between latency, throughput, accuracy, and cost.

Latency Numbers Every Programmer Should Know - https://gist.github.com/jboner/2841832

Response Time 3 Limits - https://www.nngroup.com/articles/response-times-3-important-limits/

Background by Valentin Petkov: https://unsplash.com/photos/z06oDT-8pKQ
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
‚òÖ Rajistics Social Media ¬ª 
‚óè Link Tree: https://linktr.ee/rajistics
‚óè LinkedIn: https://www.linkedin.com/in/rajistics/
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ","Rajistics - data science, AI, and machine learning",2023-08-18T14:56:04Z,2023-09-06T11:45:19Z
205,"Development with Large Language Models Tutorial ‚Äì OpenAI, Langchain, Agents, Chroma",xZDB1naRUlk,79942,2:2:54,"Welcome to this course about development with Large Language Models, or LLMs. Throughout this course, you will complete hands-on projects will help you learn how to harness LLMs for your own projects. You will build projects with LLMs that will enable you to create dynamic interfaces, interact with vast amounts of text data, and even empower LLMs with the capability to browse the internet for research papers.

This course was developed by @Luup.ai123 

Colab notebook for introduction to the API:https://colab.research.google.com/drive/1gi2yDvvhUwLT7c8ZEXz6Yja3cG5P2owP?usp=sharing
Github : https://github.com/pythonontheplane123/LLM_course_part_1

Join the Discord: https://discord.com/invite/Hq39QgRU
Twitter : https://twitter.com/AkshatNon

‚≠êÔ∏è Contents ‚≠êÔ∏è
‚å®Ô∏è (0:00:00) Brief introduction to LLMs
‚å®Ô∏è (0:11:49) Quick note from the future 
‚å®Ô∏è (0:12:04) Chatgpt playground (skip this is you know this already)
‚å®Ô∏è (0:18:21) GPT API basics (skip this is you know this already)
‚å®Ô∏è (0:30:43) Brief intro to chainlit
‚å®Ô∏è (0:31:33) Cloning chatgpt user interface
‚å®Ô∏è (0:45:37) Limitations of our interface
‚å®Ô∏è (0:47:48) Adding streaming, backend view, stop sequence button
‚å®Ô∏è (0:58:42) Introduction to vector databases
‚å®Ô∏è (1:04:42) Vector databases hands on
‚å®Ô∏è (1:12:10) QnA with Documents - .txt and .pdf
‚å®Ô∏è (1:23:32) Testing out our Q&A system
‚å®Ô∏è (1:27:22) Introduction to web-browsing and agents
‚å®Ô∏è (1:32:52) AI researcher 
‚å®Ô∏è (1:42:23) Human as a tool
‚å®Ô∏è (1:44:44) Mini code interpreter plugin(Replit tool)
‚å®Ô∏è (1:46:29) Searching youtube using agents
‚å®Ô∏è (1:49:19) Guide to explore more 
‚å®Ô∏è (1:50:33) Shell Tool
‚å®Ô∏è (1:55:43) Create your own tools
‚å®Ô∏è (2:01:19) Ending Notes

üéâ Thanks to our Champion and Sponsor supporters:
üëæ davthecoder
üëæ jedi-or-sith
üëæ ÂçóÂÆÆÂçÉÂΩ±
üëæ Agust√≠n Kussrow
üëæ Nattira Maneerat
üëæ Heather Wcislo
üëæ Serhiy Kalinets
üëæ Justin Hual
üëæ Otis Morgan

--

Learn to code for free and get a developer job: https://www.freecodecamp.org

Read hundreds of articles on programming: https://freecodecamp.org/news",freeCodeCamp.org,2023-08-18T13:47:56Z,2023-09-06T11:45:19Z
206,Brief introduction to Large Language Models,MD8HgJll_pk,107,11:11,,Luup,2023-08-18T13:36:47Z,2023-09-06T11:45:19Z
207,Deploy Large Language Models Into Production At NO COST!,6CRrhxpF8WI,299,10:31,"In this tutorial, you will learn how to create an API server to serve your model using Postman. 

Source Code:      
- https://github.com/keitazoumana/Medium-Articles-Notebooks/blob/main/serve_LLM_Using_vLLM_framework.ipynb       

Connect:      
- LinkedIn: https://www.linkedin.com/in/zoumana-keita/       
- Website: https://www.zoumdatascience.com/           
- Twitter: https://twitter.com/zoumana_keita_                 
- TikTok: https://www.tiktok.com/@zoumdatascience               
- Email me: zoumana.keita@hotmail.com            

Support:      
- https://www.buymeacoffee.com/zoumanakeig       

About me:      
Hey there! My name is Zoumana, and I am an EX-IBM and Data Scientist at IFC (World Bank Group).        

I got my first Master's in Computer Science with concentrations in Machine Learning in Paris, France, and the Second one in Data Science in Texas, US.     

My goal on this channel is to share my expertise with you and help you grow üìà in your career as Data Scientist.        

#datascience #artificialintelligence #machinelearning  #technology",ZoumDataScience,2023-08-18T13:01:49Z,2023-09-06T11:45:19Z
208,Watermarking of Large Language Models,2Kx9jbSMZqA,6043,1:15:4,"Scott Aaronson (UT Austin & OpenAI)
https://simons.berkeley.edu/talks/scott-aaronson-ut-austin-openai-2023-08-17
Large Language Models and Transformers

I'll discuss a scheme for inserting a statistical watermark into the outputs of LLMs, which I developed while working at OpenAI. I'll place this in the context of other theoretical and empirical work on LLM watermarking over the past year, as well as other approaches to the AI attribution problem. I'll also say something about the challenges of deployment, and the unsolved technical problem of designing a text watermarking method that resists translation, paraphrasing, and similar attacks.",Simons Institute,2023-08-18T12:58:38Z,2023-09-06T11:45:19Z
209,Human-AI Interaction in the Age of Large Language Models,Yv7drI7cBsQ,1363,59:10,"Diyi Yang (Stanford University)
https://simons.berkeley.edu/talks/diyi-yang-stanford-university-2023-08-17
Large Language Models and Transformers

Large language models have revolutionized the way how humans interact with AI systems, transforming a wide range of fields and disciplines. In this talk, I share two distinct approaches to empowering human-AI interaction using LLMs. The first one explores how large language models transform computational social science, and how human-AI collaboration can reduce costs and improve the efficiency of social science research. The second part introduces CARE, an interactive AI agent that supports therapists through LLM-empowered feedback and deliberative practices, as an initial step toward democratizing skill training with AI. These two works demonstrate how human-AI interaction via LLMs can empower individuals and foster positive change.",Simons Institute,2023-08-18T11:40:27Z,2023-09-06T11:45:19Z
210,706: Large Language Model Leaderboards and Benchmarks ‚Äî with Caterina Constantinescu,EkOhrx733so,394,33:17,"#LargeLanguageModels #LLMLeaderboard #LLMEvaluation

In this episode, @JonKrohnLearns is joined by Caterina Constantinescu who dives deep into Large Language Models (LLMs), spotlighting top leaderboards, evaluation benchmarks, and real-world user perceptions. Plus, discover the challenges of dataset contamination and the intricacies of platforms like HELM and Chatbot Arena.

Additional materials: https://www.superdatascience.com/706

Interested in sponsoring a SuperDataScience Podcast episode? Visit https://jonkrohn.com/podcast for sponsorship information.",Super Data Science: ML & AI Podcast with Jon Krohn,2023-08-18T11:00:21Z,2023-09-06T11:45:19Z
211,Are LLMs the Beginning or End of NLP?,KVDKWrsP3es,14086,1:56,"Dan Klein (UC Berkeley)
https://simons.berkeley.edu/talks/dan-klein-uc-berkeley-2023-08-17
Large Language Models and Transformers

I'll talk about three major tensions in NLP resulting from rapid advances of large language models.  First, we are in the middle of a switch from vertical research on tasks (parsing, coreference, sentiment) to the kind of horizontal tech stacks that exist elsewhere in CS.  Second, there is a fundamental tension between the factors that drive machine learning (scaled, end-to-end optimization of monoliths) and the factors that drive human software engineering (modularity, abstraction, interoperability).  Third, modern models can be stunning on some axes while showing major gaps on others -- they can, in different ways, simultaneously be general, fragile, or dangerous.  I'll give an NLP perspective on these issues along with some possible solution directions.",Simons Institute,2023-08-18T10:21:40Z,2023-09-06T11:45:19Z
212,W1 13 Pre training large language models,F80TC-3Oc10,0,9:19,#Andrewng #deeplearning #ai #transfomer #PromptEngineering #NLPprompts #TextPrompt #AIprompt #PromptDesign #PromptGeneration #PromptDevelopment #PromptOptimization #PromptBasedAI #FineTuning #TransferLearning #PretrainedModels #FineTunedModel #ModelFineTuning #FineTuneAI #AIModelTraining #ModelTuning #ModelAdaptation #PEFT #FewShotTranslation #TranslationAI  #ZeroShotTranslation #LanguageTranslation #PEFTModel #PEFTResearch #LoRA #LanguageModeling #ReasoningAI #AIReasoning #InferenceAI #RLHF #ReinforcementLearning #AIFeedback #HumanFeedback #AIReinforcement,PyConnect,2023-08-18T09:11:07Z,2023-09-06T11:45:19Z
213,# 179 New Trends in Machine Translation with Large Language Models by Longyue Wang,FnpvHdvhraE,262,37:14,"Joining SlatorPod this week is Longyue Wang, a Research Scientist at Tencent AI Lab, where he is involved in the research and practical applications of machine translation (MT) and natural language processing (NLP).

Longyue Longyue expands on Tencent‚Äôs approach to language technology where they integrate MT with Tencent Translate (TranSmart). He highlights how Chinese-to-English MT has made significant advancements, thanks to improvements in technology and data size. However, translating Chinese to non-English languages has been more challenging.

Recent research by Longyue explores large language models‚Äô (LLMs) impact on MT, demonstrating their superiority in tasks like document-level translation. He emphasized that GPT-4 outperformed traditional MT engines in translating literary texts like web novels.

Longyue discusses various promising research directions for MT using LLMs, including stylized MT, interactive MT, translation memory-based MT, and a new evaluation paradigm. His research suggests LLMs can enhance personalized MT, adapting translations to users' preferences.

Longyue also sheds light on how Chinese researchers are focusing on building Chinese-centric MT engines, directly translating from Chinese to other languages. There's an effort to reduce reliance on English as a pivot language.

Looking ahead, Longyue's research will address challenges related to LLMs, including handling hallucination and timeless information issues.

Chapter Markers:
00:00:00 Intro
00:01:29 What is Tencent?
00:03:44 Professional Background and Interest in MT and NLP
00:06:03 Tencent's Interest in Language Technology
00:08:42 Perception of Language Technology in China
00:12:01 MT Quality for Chinese
00:16:45 ChatGPT's Translation Capabilities
00:20:06 Interesting Directions for MT Using LLMs
00:22:51 Translation Memory-Based MT
00:24:05 Interactive MT
00:25:56 Using ChatGPT to Evaluate Translation
00:27:57 Personalized MT and Multi-Modal MT
00:30:35 The Focus of China-Based Research
00:33:55 Future Research Initiatives",Slator,2023-08-18T08:34:17Z,2023-09-06T11:45:19Z
214,01: What are Large Language Models ‚Äì Large Language Models (NUS CS6101 NUS.WING),Rln-YeMVfXs,81,13:18,"00:00 Logistics

(This recording is truncated due to lecturer's preference.  However, you can find the slides and the scribe notes at the below -- to be updated by end Aug 2023.)

Slides at http://bit.ly/cs6101-t2310-w01
Scribe Notes at http://bit.ly/cs6101-t2310-w01-scribe
Video at http://bit.ly/cs6101-t2310-w01-yt",Web IR / NLP Group at NUS,2023-08-18T08:15:42Z,2023-09-06T11:45:19Z
215,Interact with Large Language Models using Snowflake Data Cloud,SkDAdHSWOiE,2839,7:3,In this video Harish and Todd talk about their experience building a native app using Streamlit which interacts with large language model to provide the results of a search query on a Formula1 dataset stored in Snowflake.,Sagar Kulkarni,2023-08-18T06:56:02Z,2023-09-06T11:45:19Z
216,Training Large Language Models Made Easy with  gpt-llm-trainer Llama2 Finetuning  üî•üî•üî•üî•üî•,dnqE6YUstu4,703,7:31,"Introducing gpt-llm-trainer by Matt Shumer, the easiest way to train a task-specific LLM and go from idea to fully-trained AI model! 
But How does it work? 
1. Simply describe your task in plain English. 
2.  The AI creates a dataset from scratch.
3. System parses everything into the perfect format
4. It fine-tunes a LLaMA 2 model, all ready for your specific task

If you like such content please subscribe to the channel here: 
https://www.youtube.com/c/RitheshSreenivasan?sub_confirmation=1 

If you like to support me financially, It is totally optional and voluntary. Buy me a coffee here: https://www.buymeacoffee.com/rithesh 

Relevant Links: 
https://github.com/mshumer/gpt-llm-trainer
https://colab.research.google.com/drive/1mV9sAY4QBKLmS58dpFGHgwCXQKRASR31?usp=sharing",Rithesh Sreenivasan,2023-08-18T06:36:52Z,2023-09-06T11:45:19Z
217,Integrating Language into Intelligent Architectures,Uskm9a26V6U,1570,59:40,"Loi Wong (MIT), Alex Lew (MIT)
https://simons.berkeley.edu/talks/loi-wong-mit-alex-lew-mit-2023-08-17
Large Language Models and Transformers",Simons Institute,2023-08-18T06:11:45Z,2023-09-06T11:45:19Z
218,Top 5 Popular Large Language Models Enterprises Must Use l EP#06 AI In A Blink l Yellow.ai,ODqLiQnuuE8,162,4:4,"üòé 5 minutes is all you need to discover the ‚Äú5 Popular #LLMs in the market‚Äù

#largelanguagemodel uses a larger pool of data for training, which significantly increases the capabilities of the AI model. As AI advances, an increasing number of LLMs are popping up in the market, as companies strive to set themselves apart with cutting-edge technology.

Join Vibhanshu Dixit, Sr. Content Marketing Manager at @YellowDotAI, as he takes us through the 5 major LLMs in the market that are paving the way for innovation!

‚úÖ Full series of ‚ÄúAI in a blink: Byte-sized insights on Gen AI‚Äù: https://www.youtube.com/playlist?list=PLZS6UYtujN1CAbG8g2462fOjJKfEISMuv
Want to know more about Conversational AI, then watch this üëâüèª: https://www.youtube.com/watch?v=cneyozjKdzs&t=0s

Get a FREE Platform demo here - https://bit.ly/3W8FChW
Stay tuned and subscribe to #yellow.ai!

Follow us on Social media: 
Twitter: https://twitter.com/yellowdotai
LinkedIn: https://www.linkedin.com/company/yell...
Facebook: https://www.facebook.com/YellowDotAI/
Instagram: https://www.instagram.com/yellowdotai

Visit www.yellow.ai for more information. 
Contact us at contact@yellow.ai

#AIinABlink #GPT4 #Gopher #LaMDA",yellow. ai,2023-08-18T06:01:28Z,2023-09-06T11:45:19Z
219,A Study on the Effectiveness of Large Language Models for Translation with Markup,dmUrvnbp7uY,18,15:22,,Raj Dabre,2023-08-18T05:40:46Z,2023-09-06T11:45:19Z
220,Meaning in the age of large language models,lA19zXgObKA,2564,58:36,"Steven Piantadosi (UC Berkeley)
https://simons.berkeley.edu/talks/steven-piantadosi-uc-berkeley-2023-08-17
Large Language Models and Transformers

The recent rise in large language models profoundly changes the landscape for theories of human language. I'll discuss how these models should cause us to rethink popular ideas about grammar and language acquisition. Maybe most importantly, modern language models provide a compelling way to think about semantics and conceptual representation. I'll argue that the sense in which they possess ""meanings"" is likely to be analogous to how human words and concepts achieve meaning by implementing ""conceptual role"" theories which are at least partially accessible in the statistics present in text, even without embodied contact with the world.",Simons Institute,2023-08-18T05:08:14Z,2023-09-06T11:45:19Z
221,Beyond Boundaries: The Future of AI &amp; Large Language Models,xJhs0J1yalw,473,53:15,"Join Dr. Ben Goertzel, the visionary CEO and Founder of SingularityNET, as he delves into the compelling realm of large language models. In this Dublin Tech Summit keynote presentation, Dr. Goertzel will navigate the uncharted territories of AI, discussing the imminent impact of large language models on innovation across industries. Discover the intricacies, challenges, and prospects of developing and deploying these transformative tools. Gain insights into the future of AI, as Dr. Goertzel unveils his visionary perspective on the role of large language models in shaping the AI landscape. Tune in to explore the boundless potentials of AI and machine learning in this thought-provoking session.

Themes: AI & Machine Learning | Innovation | Future of Technology | Language Models | Industry Transformation
Keynote: Dr. Ben Goertzel, CEO and Founder, SingularityNET
#dubtechsummit",Dublin Tech Summit,2023-08-18T05:00:33Z,2023-09-06T11:45:19Z
222,Webinar &quot;Leveraging Large Language Models for Enterprise Usage&quot;,2C-KN5gPJ0Q,179,49:36,"Join the Data Phoenix Slack community: https://join.slack.com/t/data-phoenix/shared_invite/zt-115lu0xo1-KhDX_4xAyEd4JiuiUZ3ieQ
Subscribe to Data Phoenix Digest: https://dataphoenix.info/subscribe/

===================================

Organizations worldwide are still trying to understand how to leverage generative AI models and put them into practical use. To enable them, NVIDIA developed a full-stack approach, from the hardware to develop and serve these models, to the variety of customizable SDKs and services to assist research and industry alike. However, LLMs, like any other technology, are not perfect and require guardrails to address shortcomings such as hallucination, inherited bias, and toxicity. By providing toolsets and mechanisms to mitigate these limitations, in the roads ahead, we hope to see generative AI open up new horizons and brings about positive revolution. Join this talk to learn about foundation and ChatGPT-style models, generative AI and LLM technology at NVIDIA, shortcomings and proposed guardrails, and the road ahead.

Speaker:
Zenodia Charpy is a senior deep learning data scientist working at NVIDIA. Her field of expertise lies in training and deploying very large language models with a focus on tackling challenges for non-English and low-resource languages such as Swedish, Danish, Norwegian, and many others. Exploring parameter efficient tuning techniques to boost LLMs performance further while grounding factual correctness of LLMs responses.",Data Phoenix Events,2023-08-18T04:01:34Z,2023-09-06T11:45:19Z
223,Large Language Models are becoming a problems......,UGxGTgQx2qA,20,3:59,"In the realm of AI, language models ignite possibilities while conquering challenges‚Äîreducing errors, optimizing context, integrating data types, and expanding across languages. AI agents take the stage, driven by human preference and redefining interactions. The journey unfolds, fueled by innovation and collaboration, promising a transformed future.
.
.
.
.
.
.
.
.
.
#AIInnovation #LanguageModels #TechAdvancements #AIResearch #FutureTech #AIAgents #MultimodalData #LanguageDiversity #EfficiencyInTech #TechChallenges #InnovativeSolutions #AIRevolution #ChatInterface #HumanPreference #TechTransformation #LanguageEvolution #DigitalInteractions #TechInnovation #CollaborativeResearch #AIExploration #FutureofTechnology#AIInsights #CuttingEdgeTech #InnovateWithAI #AIProgress #DigitalRevolution #TechBreakthroughs #AIAdvancements #TechJourney #LanguageAI #AIExplained #TechSolutions #AIforEveryone #TechDiscovery #AIForward #TechEvolution",AI is NEXT,2023-08-18T01:48:21Z,2023-09-06T11:45:19Z
224,How to Fine-Tune and Train LLMs With Your Own Data EASILY and FAST- GPT-LLM-Trainer,pRq2Fx4kYQI,8385,10:41,"Welcome to the ultimate solution for training large language models effortlessly! If you've ever struggled with the complexities, costs, and computational demands of training LLMS, then you're in for a treat. In this video, we unveil the game-changing GPT-LLM-Trainer ‚Äì your gateway to hassle-free LLM training. Say goodbye to the painstaking process of data collection, formatting, model selection, and coding. Say hello to a new era of simplicity, affordability, and efficiency!

üî• Become a Patron: https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 

[Must Watch]:
Insane Ai News of the Week: GPT-5 is Official - https://youtu.be/7F4iza1yrkI
How To Install UNCENSORED Llama 2 Locally - https://youtu.be/RpGXhpeH668
ToolLLM: Writes API Calls BETTER Than ChatGPT 4 - https://youtu.be/N4R5BBb0o9g

[Links Used]:
GPT-LLM-Trainer Github Repo: https://github.com/mshumer/gpt-llm-trainer
Google Colab: https://colab.research.google.com/drive/1mV9sAY4QBKLmS58dpFGHgwCXQKRASR31?usp=sharing
Matt's Twitter (Creator): https://twitter.com/mattshumer_/status/1689323331395231754
OpenAi API Key: https://platform.openai.com/account/api-keys

Key Takeaways:
- Demystifying LLM Training Challenges
- Introducing GPT-LLM-Trainer: Your New Best Friend
- How GPT-LLM-Trainer Simplifies the Training Pipeline
- Harnessing GPT-4 for Optimal Model Performance
- How to Train Your Own GPT
- How to Fine-Tune LLMs With Your Own Data

In the world of large language models, training can be a daunting journey. Gathering datasets, refining them meticulously, formatting for model compatibility, coding training scripts ‚Äì it's a demanding ordeal. But fear not! Enter GPT-LLM-Trainer, the revolutionary solution designed to change the game. Imagine creating a high-performing, task-specific LLM model without breaking the bank or losing your sanity. With GPT-LLM-Trainer, it's not a dream ‚Äì it's reality. We've engineered a streamlined pipeline that turns your concept into a trained model. Just provide a task description, and watch as the magic unfolds. GPT-LLM-Trainer generates datasets from scratch, formats them perfectly, and fine-tunes a model tailored to your needs. Today, we're diving deep into GPT-LLM-Trainer's powers. Witness the process as we fine-tune with the incredible Llama 2 model. See how GPT-4 orchestrates three vital stages: Dataset Generation, System Message Crafting, and Fine-Tuning. This three-tiered approach simplifies training, automating complex steps while enhancing model performance.

Want to conquer LLM training hurdles? GPT-LLM-Trainer has your back. No more guesswork, no more colossal expenses. Just a seamless path from concept to model. Simplify your LLM training journey ‚Äì join us now!


üëç If you found this video insightful, don't forget to give it a thumbs up!
üîî Subscribe to our channel to stay updated on cutting-edge LLM techniques and solutions.
üì£ Share this video with fellow enthusiasts who crave efficient LLM training!

Additional Tags & Keywords:
LLM Training, GPT-LLM-Trainer, Language Model Training, LLM Pipeline, Llama 2, GPT-4, Streamlined Training, Affordable LLM Training, Easy LLM Training, Model Fine-Tuning, Task-Specific Models

Hashtags:
#LLMTraining #GPTLLMTrainer #LanguageModel #Llama2 #EfficientTraining #ModelFineTuning",WorldofAI,2023-08-17T22:49:32Z,2023-09-06T11:45:19Z
225,Uncovering The Mystery of AI and LLMs #ai #llm #shorts,a9nKS9u3-Gw,985,43,"CTO & AI Executive Advisor, Arnold Liwanag, discusses the unboxing of AI and Large Language Models in order to help ensure AI safety.

Find the full episode on the Unstacked Tech Champions podcast here: https://www.youtube.com/watch?v=_qAzH9phDxA

Subscribe to the channel here: https://www.youtube.com/channel/UCGeGkYVY_xtlMQUG7QSbomg?sub_confirmation=1

#shorts #shortsvideo #UnstackedTechChampions #ai #aiforgood",Unstacked Tech Champions,2023-08-17T21:40:33Z,2023-09-06T11:45:19Z
226,Leveraging Large Language Models (LLMs) on Domain Specific Knowledge,NHRQNerhTHU,65,56:5,"Large language models such as Bard and ChatGPT are rooted in natural language processing models developed decades earlier. How did we get here? This presentation took us through this fascinating journey. Dr. Hossein Kazemi moderated this presentation with Avi Patel and Raul Salles de Padua who took us on a brief journey through the evolution in NLU and NLP, from word embeddings to the current state of LLMs. We shared how to leverage adoption of LLMs, Generative AI capabilities and better understand the LLM-Ops lifecycle. Finally, we demonstrated the art of the possible with LLMs in action.",CAIA Association,2023-08-17T20:07:40Z,2023-09-06T11:45:19Z
227,Leveraging Large Language Models for Enterprise Usage,k_sOVQXMnrA,1618,48:50,"Join the Data Phoenix Slack community: https://join.slack.com/t/data-phoenix/shared_invite/zt-115lu0xo1-KhDX_4xAyEd4JiuiUZ3ieQ
Subscribe to Data Phoenix Digest: https://dataphoenix.info/subscribe/

===========================

Organizations worldwide are still trying to understand how to leverage generative AI models and put them into practical use. To enable them, NVIDIA developed a full-stack approach, from the hardware to develop and serve these models, to the variety of customizable SDKs and services to assist research and industry alike. However, LLMs, like any other technology, are not perfect and require guardrails to address shortcomings such as hallucination, inherited bias, and toxicity. By providing toolsets and mechanisms to mitigate these limitations, in the roads ahead, we hope to see generative AI open up new horizons and brings about positive revolution. Join this talk to learn about foundation and ChatGPT-style models, generative AI and LLM technology at NVIDIA, shortcomings and proposed guardrails, and the road ahead.

Zenodia Charpy is a senior deep learning data scientist working at NVIDIA. Her field of expertise lies in training and deploying very large language models with a focus on tackling challenges for non-English and low-resource languages such as Swedish, Danish, Norwegian, and many others. Exploring parameter efficient tuning techniques to boost LLMs performance further while grounding factual correctness of LLMs responses.",Data Phoenix Events,2023-08-17T19:27:04Z,2023-09-06T11:45:19Z
228,"Stanford XCS224U: Natural Language Understanding I In-context Learning, Pt 1: Origins I Spring 2023",eyNLkiQ89KI,367,8:21,"For more information about Stanford's Artificial Intelligence programs visit: https://stanford.io/ai
 
This lecture is from the Stanford Online professional course XCS224U: https://online.stanford.edu/courses/xcs224u-natural-language-understanding
 
Every lecture from this professional course is taken from content within the Stanford University graduate course - CS224U. To follow along, visit the graduate course website: http://web.stanford.edu/class/cs224u/index.html
 
Christopher Potts Professor and Chair, Department of Linguistics, and Professor, by courtesy, Department of Computer Science at Stanford University http://web.stanford.edu/~cgpotts/

View the entire playlist of lectures: https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp

To browse all available online courses and programs offered by Stanford Online, visit: http://online.stanford.edu",Stanford Online,2023-08-17T15:40:56Z,2023-09-06T11:45:19Z
229,"Stanford XCS224U: NLU I Intro &amp; Evolution of Natural Language Understanding, Pt. 1 I  Spring 2023",K_Dh0Sxujuc,20018,1:13:52,"For more information about Stanford's Artificial Intelligence programs visit: https://stanford.io/ai
 
This lecture is from the Stanford Online professional course XCS224U: https://online.stanford.edu/courses/xcs224u-natural-language-understanding
 
Every lecture from this professional course is taken from content within the Stanford University graduate course - CS224U. To follow along, visit the graduate course website: http://web.stanford.edu/class/cs224u/index.html
 
Christopher Potts Professor and Chair, Department of Linguistics, and Professor, by courtesy, Department of Computer Science at Stanford University http://web.stanford.edu/~cgpotts/

View the entire playlist of lectures: https://www.youtube.com/playlist?list=PLoROMvodv4rOwvldxftJTmoR3kRcWkJBp

To browse all available online courses and programs offered by Stanford Online, visit: http://online.stanford.edu",Stanford Online,2023-08-17T15:39:50Z,2023-09-06T11:45:19Z
230,AI REVOLUTION: How AppleGPT Could Be The Next Big Thing In AI Industry!,ZwH-k1RzwYA,260,7:56,"Apple's entry into the AI chatbot field has been relatively discreet, especially compared to other tech giants like Microsoft, Meta, and Google. These competitors have been actively advancing in the AI space, leveraging the potential of large language models. However, recent indications from Apple's headquarters suggest that they are quietly developing their own AI chatbot named AppleGPT, hinting at a potential comeback for the company in this domain.

Subscribe Link :
https://www.youtube.com/channel/UCrp3ja2oZHy5EDshfdwAscQ?sub_confirmation=1

So, What makes Apple's AI chatbot intriguing? According to reports, it is built on a framework called Ajax. This framework is specifically designed to handle the creation of large language models, A Significant Aspect Of Modern Ai. What's fascinating is that Ajax is rooted in Google's JAX framework, a versatile Python library that enables code to run on powerful hardware components like Graphics Processing Units and Tensor Processing Units. These components are essential for training the complex neural networks required by large language models, as they can handle massive amounts of data and perform intricate mathematical operations.

#apple #applegpt #tech #ai",TECH SILK,2023-08-17T13:59:57Z,2023-09-06T11:45:19Z
231,DevLab&#39;23 ‚Äì Large Language Models: An Overview by Barbara Fusinska,GDVK5kflca4,95,36:54,,hackajob HQ,2023-08-17T13:55:50Z,2023-09-06T11:45:19Z
232,E4: Evaluating Large Language Models with Nathan Lambert,mqsT2Y8Rxfs,191,37:59,"On the fourth episode of Practically Intelligent, Sinan and Akshay sit down with the esteemed Nathan Lambert, a prominent Machine Learning researcher and analyst. With his keen goal of understanding and developing safe and societally beneficial autonomous systems, Nathan shares valuable insights from his experience as a Research Scientist at HuggingFace ü§ó. We dive deep into the nuances of evaluating large language models (LLMs) and the role of the HuggingFace's Open LLM Leaderboard.",Practically Intelligent,2023-08-17T13:01:00Z,2023-09-06T11:45:19Z
233,Introduction to Large Language Models (LLMs) in Python - Course Overview.,kS2xf53jTko,17,1:8,"Enami TV 
 Please like and subscribe!",Enami TV News | BREAKING NEWS FEED by AI,2023-08-17T11:57:02Z,2023-09-06T11:45:19Z
234,Are Aligned Language Models ‚ÄúAdversarially Aligned‚Äù?,uqOfC3KSZFc,2693,1:2:41,"Nicholas Carlini (Google DeepMind)
https://simons.berkeley.edu/talks/nicholas-carlini-google-deepmind-2023-08-16
Large Language Models and Transformers

An ""aligned"" model is ""helpful and harmless"". In this talk I will show that while language models may be aligned under typical situations, they are not ""adversarially aligned"". Using standard techniques from adversarial examples, we can construct inputs to otherwise-aligned language models to coerce them into emitting harmful text and performing harmful behavior. Creating aligned models robust to adversaries will require significant advances in both alignment and adversarial machine learning.",Simons Institute,2023-08-17T11:41:34Z,2023-09-06T11:45:19Z
235,"Language Models as Statisticians, and as Adapted Organisms",_oHvhJhjkx0,3535,1:11,"Jacob Steinhardt (UC Berkeley)
https://simons.berkeley.edu/talks/jacob-steinhardt-uc-berkeley-2023-08-16
Large Language Models and Transformers

Given their complex behavior, diverse skills, and wide range of deployment scenarios, understanding large language models---and especially their  failure modes---is important. Given that new models are released every few months, often with brand new capabilities, how can we achieve understanding that keeps pace with modern practice?

In this talk, I will present two approaches to this that leverages the structure and skills of language models themselves, and so scale up as models get better. The first approach leverages the skill of language models *as statisticians*. At inference time, language models can read and process significant amounts of information due to their large context windows, and use this to generate useful statistical hypotheses. We will showcase several systems built on this principle, which allow us to audit other models for failures, identify spurious cues in datasets, and factorize corpora into human-interpetable concepts.

Next, we will leverage the *internal structure* of language models. Language models are adapted to complex data that induces rich internal structure in their activations. If we can understand this structure, we can steer language models towards more desired behaviors, similar to how understanding DNA let us engineer useful proteins in biology. As case studies, we'll first reverse-engineer how a learned transformer solves a simple reasoning task, then show how leveraging internal activations can make language models more honest.

This is joint work with many collaborators and students, including Ruiqi Zhong, Erik Jones, and Collin Burns.",Simons Institute,2023-08-17T10:07:44Z,2023-09-06T11:45:19Z
236,On Localization in Language Models,J-CTR0xHr98,1591,1:1:11,"Yonatan Belinkov (Technion - Israel Institute of Technology)
https://simons.berkeley.edu/talks/yonatan-belinkov-technion-israel-institute-technology-2023-08-16
Large Language Models and Transformers

Questions of distributivity or localization of information have long plagued the fields of artificial intelligence and cognitive science. Should a single unit encode a single concept, or should all units encode all concepts? Distributed representations power today‚Äôs successful neural models in NLP and other domains. As models scale to billions of parameters, we seem to be moving further away from a localist view. In this talk, I will review recent work on identifying the role of individual components such as neurons and attention heads in language models. I will show that such components can be characterized, and that analyzing the internal structure and mechanisms of language models can elucidate their behavior in various cases, including memorization, gender bias, and factual recall. I‚Äôll conclude by demonstrating how such analyses can inform mitigation procedures to make these models more robust and up-to-date.",Simons Institute,2023-08-17T07:36:08Z,2023-09-06T11:45:19Z
237,Where can procurement best leverage generative AI and large language models,k2U5WoRKhBY,22,5:8,"""That gives you already quite an amount of savings with regards to productivity. And it gives you an ability tap into details which you potentially would overlook""

Watch the full conversation - https://www.zivio.com/resources/integrated-suites-to-best-of-breed-the-evolution-of-procurement-tech

#procuretech #procurement #digitaltransformation",Zivio,2023-08-17T07:29:00Z,2023-09-06T11:45:19Z
238,"Unveiling the Math Behind Training Language Models: Insights, Challenges, and Optimization",ecbzMskV2MA,23,2:31,"The article discusses the mathematical aspects of training language models (LLMs), including the use of large-scale datasets and optimization algorithms. The comments emphasize the importance of mathematics in understanding and improving LLMs, with a focus on information theory and statistical analysis. The conversation also touches on the challenges of training LLMs and the need for a deeper understanding of the mathematical foundations of machine learning.

üîó https://www.latent.space/p/transformers-math#details

#AI #LLM",AI Insight News,2023-08-17T07:12:30Z,2023-09-06T11:45:19Z
239,Revolutionize Text Compression with Ts_zip: Harnessing the Power of Large Language Models for Unprec,LfYpKZvr9ew,68,2:51,"The post discusses a text compression tool called ts_zip that uses Large Language Models (LLMs) and offers a higher compression ratio compared to other tools. However, it has some limitations such as requiring the language model for decompression and the need for a GPU for reasonable speed. The comments discuss various topics related to compression, including the relationship between LLMs and compression, the Hutter Prize, lossy text compression, and other compression algorithms. Some users also mention the work of Fabrice Bellard, the creator of ts_zip, and his other notable contributions to the field of programming.

üîó https://bellard.org/ts_server/ts_zip.html

#AI #Language Model #AI #LLM",AI Insight News,2023-08-17T07:09:35Z,2023-09-06T11:45:19Z
240,"Alternatives to OpenAI, Privacy of LLMs, and Navigating the world of GPTs",56hnfUGvtAI,121,13:47,"Tune in to our discussion on navigating the world of GPTs; alternatives to OpenAI and the implications of foundation models; the privacy of LLMs; and why GPT, LLMS, and AI are not all the same.",Nexxt Intelligence | inca,2023-08-17T05:48:53Z,2023-09-06T11:45:19Z
241,Large Language Models Meet Copyright Law,MFKV48ikV5E,3307,1:11:34,"Pamela Samuelson (UC Berkeley)
https://simons.berkeley.edu/talks/pamela-samuelson-uc-berkeley-2023-08-16
Large Language Models and Transformers

Is ingesting in-copyright works posted on the open internet as training data for building large language models (LLMs) copyright infringement or not? Several lawsuits and law review articles address this question. Those lawsuits are still in early stages and resolution of this fundamental question is likely years off. Beyond litigation, the Copyright Office is expected to ask for comments from interested stakeholders and the public about their views on this question. The Office will issue a report and possibly recommend legislation. If courts decide that ingestion is infringement, they have the power to order the destruction of models trained on this data, although this is discretionary, not mandatory. The stakes for this nascent industry and for researchers in the resolution of this issue could not be greater.",Simons Institute,2023-08-17T05:20:13Z,2023-09-06T11:45:19Z
242,Utilizing Large Language Models in Production - AI Community Meetup - June 2023,4jFisUYBuGo,207,42:48,"We hosted our first, physical AI community meetup in June 2023, where our Rootcode AI Team Lead, Thirunayan spoke about using LLMs in production environment using real-world scenarios and practical examples. If anyone missed our meetup, you can listen to the session here. 
Let us know your comments!",Rootcode,2023-08-17T04:45:30Z,2023-09-06T11:45:19Z
243,BloombergGPT: How We Built a 50 Billion Parameter Financial Language Model,m2Scj2SO85Y,888,40:33,"We will present BloombergGPT, a 50 billion parameter language model, purpose-built for finance and trained on a uniquely balanced mix of standard general-purpose datasets and a diverse array of financial documents from the Bloomberg archives. Building a large language model (LLM) is a costly and time-intensive endeavor. To reduce risk, we adhered closely to model designs and training strategies from recent successful models, such as OPT and BLOOM. Nevertheless, we faced numerous challenges during the training process, including loss spikes, unexpected parameter drifts, and performance plateaus.

In this talk, we will discuss these hurdles and our responses, which included a complete training restart after weeks of effort. Our persistence paid off: BloombergGPT ultimately outperformed existing models on financial tasks by significant margins, while maintaining competitive performance on general LLM benchmarks. We will also provide several examples illustrating how BloombergGPT stands apart from general-purpose models.

Our goal is to provide valuable insights into the specific challenges encountered when building LLMs and to offer guidance for those debating whether to embark on their own LLM journey, as well as for those who are already determined to do so.

David Rosenberg,  Head of ML Strategy, Office of the CTO, Bloomberg",Toronto Machine Learning Series (TMLS),2023-08-17T02:41:59Z,2023-09-06T11:45:19Z
244,Do We Still Need Clinical Large Language Models,nK9sJSeuNVE,34,27:23,"It remains unclear whether large language models (LLMs) trained primarily with general web text are the right tool in highly specialized, safety critical domains such as clinical text. Recent results have suggested that LLMs encode a surprising amount of medical knowledge. To investigate whether smaller domain-specific LLMs retain utility, we conduct an extensive empirical analysis of 12 language models, ranging from 220M to 175B parameters, measuring their performance on 3 different clinical tasks. We show that relatively small specialized clinical models substantially outperform all in-context learning approaches, even when fine-tuned on limited annotated data. Further, we find that pretraining on clinical tokens allows for smaller, more parameter-efficient models that either match or outperform much larger language models trained on general text. We release our trained models used under the PhysioNet Credentialed Health Data license and data use agreement.

Alistar Johnson, Scientist,  SickKids",Toronto Machine Learning Series (TMLS),2023-08-17T02:41:18Z,2023-09-06T11:45:19Z
245,"Privacy &amp; Security of Large Language Models, Risks and Mitigation",On9bmpkL7EA,52,28:17,"Large language models (LLMs) are powerful AI systems that can generate natural and artificial language content such as programming languages for various tasks and applications. However, LLMs also pose significant security and privacy risks, such as leaking sensitive information from their training data, producing unsafe or malicious code, and enabling adversarial attacks by malicious parties. Some examples of adversarial attacks on LLMs are PromptInject, which can hijack the model's goal or leak its prompt, differentiable language model attack, which can fool text classifiers by fine-tuning a pre-trained language model, and gradient-based attack, which can generate perturbations that exploit the model's vulnerability. In this talk, we review some of the main challenges and threats associated with LLMs for code and natural language, and survey some of the existing and proposed solutions to mitigate them. We will discuss some of the ethical and legal implications of using LLMs, and suggest some directions for future research and development.

Dr. Ehsan Amjadian, Head of Data Science,  RBC",Toronto Machine Learning Series (TMLS),2023-08-17T02:37:56Z,2023-09-06T11:45:19Z
246,Ode to the Large Language Models.,bAHxGTs9Kxs,28,1:18,"(with apologies to Shakespeare)
after Miranda from the Tempest.



In partnership with flesh and fervent thought,

Patiently they sift for answers  sought.

Spirits invoked by numbers and code kindly summarise archives long stowed.

Oh, what a brave new world is this, that has such beings in it.

Tis new to thee‚Ä¶",Kari McKern,2023-08-17T01:58:47Z,2023-09-06T11:45:19Z
247,New king of Opensource LLMs üëë #nft #chatgpt  #ai #technology #ml  #artificialintelligence,M5KN24QN3no,826,40,"Welcome to our groundbreaking journey through the revolutionary Platypus method! In this video, we dive deep into the intricacies of fine-tuning Large Language Models (LLMs) with the ingenious Platypus approach, which has skyrocketed to the top of HuggingFace's Open LLM Leaderboard! üèÜ",WorldofAI,2023-08-16T22:08:42Z,2023-09-06T11:45:19Z
248,MFS Summer School 2023 Day 1: Large Language Models in Economics,pWenffONxlU,498,2:47:58,"Jesus Fernandez-Villaverde (University of Pennsylvania): ""Large Language Models in Economics‚Äù

Presentation slides:
https://macfinancesociety.files.wordpress.com/2023/08/mfs_day1_jfv.pdf

Jesus Fernandez-Villaverde is a Professor of Economics at the Department of Economics at University of Pennsylvania. His research agenda is in macroeconomics and econometrics, with a focus on the computation and estimation of dynamic stochastic general equilibrium (DSGE) models; the standard tool of modern quantitative macroeconomics. In particular, Professor Fernandez-Villaverde‚Äôs research has focused on how to evaluate the likelihood on non-linear and/or non-normal DSGE models and in exploring situations where those features are important to account for the data. His two most recent papers are examples of this line: an evaluation of the effects of fiscal uncertainty on economic activity, a study of asset pricing implications of DSGE models with Epstein-Zin preferences, and an investigation of the consequences of stochastic volatility for small open economies.

Full program of the MFS Summer School:
https://macrofinancesociety.org/mfs-virtual-summer-school-2023/


The mission of the Macro Finance Society (https://macrofinancesociety.org/) is to advance and disseminate high-quality research in Macro Finance, which is a broad area at the intersection of financial economics and macroeconomics. The research conducted at The Society emphasizes microeconomic foundations via (dynamic) structural modeling, while being grounded in the data. Members of The Society consist of both financial economists and macroeconomists, who share the common goal of advancing and disseminating high-quality research in Macro Finance.

Macro-finance addresses the link between asset prices and economic fluctuations. Macroeconomics (from the Greek prefix makro- meaning ""large"" + economics) is a branch of economics dealing with the performance, structure, behavior, and decision-making of an economy as a whole. Macroeconomists study topics such as GDP, unemployment rates, national income, price indices, output, consumption, unemployment, inflation, saving, investment, energy, international trade, and international finance. Asset prices are the prices for which financial instruments, such as stocks, bonds, currencies, etc., are bought and sold. 

Macro Finance Society web-site: https://macrofinancesociety.org/

Thanks for watching",Macro Finance Society,2023-08-16T20:33:50Z,2023-09-06T11:45:19Z
249,Learn more on the Data Scientist Show¬†#066¬†with Vikram Chatterji,vfgQyo-WhMc,116,37,"Full interview: https://youtu.be/elrpDJWOfm8

Vikram is the co-founder of Galileo ‚Äì an AI diagnostics and explainability platform used by data science teams building NLP, LLMs and Computer Vision models across the Fortune 500 and high growth startups.  Prior to Galileo, Vikram led Product Management at Google AI, where his team built models for the Fortune 2000 across retail, financial services, healthcare and contact centers. He has a master degree from Carnegie Mellon University from the school of computer science. If you enjoy the show, subscribe to the channel and leave a 5-star review. Subscribe to Daliana's newsletter on www.dalianaliu.com for more on data science and career.

Vikram Chatterji‚Äôs LinkedIn: https://www.linkedin.com/in/vikram-ch...
""The Mom Test"": https://www.amazon.com/The-Mom-Test-R...
Daliana's Twitter: https://twitter.com/DalianaLiu 
Daliana's LinkedIn: https://www.linkedin.com/in/dalianaliu",The Data Scientist Show - Daliana Liu,2023-08-16T19:00:26Z,2023-09-06T11:45:19Z
250,Future Risks of Large Language Models (NLP for High School),jAuNb4AkXAo,24,4:49,"Part of a series of videos on Natural Language Processing aimed at introducing high school students to language modeling.

Module landing page: https://www.cs.utexas.edu/~gdurrett/courses/nlp-module/

This module about machine learning is produced as part of the NSF Institute for Foundations of Machine Learning at UT Austin, University of Washington, and Wichita State. https://www.ifml.institute/",Greg Durrett,2023-08-16T00:19:31Z,2023-09-06T11:45:19Z
251,RT-2: Large Language Models that control robots #artificialintelligence #ai #llm #chatgpt #deepmind,AYQsSmO9TjE,38,58,"Learn Python, Data Science and AI skills:
https://evlabs.io

Join our monthly newsletter with the latest breakthroughs in AI:
https://www.evlabs.io/joinus


Imagine controlling a robot just like you interact with chatGPT. You give it a command like ‚ÄúMove the banana to the water bottle‚Äù and the robot just does it.

Well, we might be closer to it than you expect. Deepmind just released RT-2, a model that responds to natural language commands with low-level instructions that a robot can execute.

RT-2 leverages existing vision-language models, trained with billions of images and text descriptions from the internet, to perform visual reasoning tasks, like captioning images or visual Q&A. 

These models are then fine-tuned with robotics data to respond to a task description and images from the robot's camera, with the actions that lead the robot to accomplish that task.

But here's the kicker: the models retain the knowledge they learned from the internet images, recognizing objects, people and context, even if they haven't been explicitly trained for it.

AI models are becoming better at transferring skills across domains, and that trend is accelerating.",Escape Velocity Labs,2023-08-15T21:40:25Z,2023-09-06T11:45:19Z
252,HireMate | Large Language Models Bankathon 1.0 | Axis Bank,6kqgUC4Yb34,33,8:11,"Revolutionizing HR Operations with LLM

Challenge: Traditional HR processes are time-consuming, manual, and lack data-driven insights, hindering efficiency and decision-making.

Solution: Introducing an LLM-powered application that leverages NLP, machine learning, and analytics to streamline HR tasks, enhance decision-making, and improve employee experience.

Opportunity: Our scalable and customizable platform integrates with existing HR systems, ensuring smooth data flow and optimization of processes.

Outcome: Elevate HR operations through automation, data-driven insights, and improved efficiency. Welcome to the future of HR with LLM!",Swaraj Gosavi,2023-08-15T18:02:31Z,2023-09-06T11:45:19Z
253,The Devil is in the Errors: Leveraging LLMs for Fine-grained Machine Translation Evaluation,Ehrn4CgWzH0,106,32:55,"The paper proposes AutoMQM, a technique that uses large language models to identify and categorize errors in machine translations, improving performance and providing interpretability compared to score-based evaluation methods.

00:00 Section: 1 Introduction
04:03 Section: 2 Background:  MT Evaluation
06:57 Section: 3  Related Work
10:01 Section: 4 Using LLMs to Predict Quality Scores
12:49 Section: 4.2 Finetuning
17:11 Section: 6 Experiments
21:03 Section: Finetuning
23:59 Section: Span Meta-Evaluation
27:53 Section: Finetuning
30:02 Section: 6.3 Low Resource Languages

https://arxiv.org/abs//2308.07286

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-15T16:06:38Z,2023-09-06T11:45:19Z
254,how to upload files to Chatgpt to do anlysis,1_8qQJHOO40,40,10:9,"""Uploading Documents for Analysis using Poe's ChatGPT and POE Platform""

join our A.I mentoship Training: https://shorturl.at/lwIJK


Welcome to our YouTube tutorial on how to upload documents for analysis using Poe's powerful ChatGPT and the innovative POE platform. In this video, we'll guide you through the process of leveraging Poe's capabilities to analyze your documents with the help of AI.

üîç What is Poe?
Poe is a cutting-edge platform that opens up a world of possibilities for interacting with AI. By asking questions, receiving instant answers, and engaging in dynamic conversations, Poe empowers users to harness the power of artificial intelligence in their tasks.

ü§ñ Understanding Different Bots
Discover the distinct personalities of Poe's bots, each with their own strengths:

Claude-Instant: Ideal for creative writing tasks, offering in-depth responses quickly.
Claude-2‚Äì100k: Tackles complex challenges and can process lengthy inputs, making it perfect for various tasks, especially creative writing.
Assistant and ChatGPT: Excel in languages beyond English and shine in programming-related endeavors.
GPT-4: The pinnacle of language models, excelling in creative writing, problem-solving, and providing detailed instructions.
üí° How the Bots Operate
Learn how Poe's bots work their magic, powered by third-party companies that utilize large language models (LLMs). These advanced machine learning systems have been trained on vast amounts of text data, enabling them to process and generate text effectively.

üåü Versatile Bot Uses
Explore the wide array of applications for Poe's bots:

Learning assistance
Writing support
Translation aid
Programming guidance
Summarization
Entertainment and more
Join us in this video to uncover the potential of uploading your documents for analysis through Poe's ChatGPT and POE platform. Experience the future of AI-powered interactions and discover how Poe can make a difference in your tasks.

Don't miss out on this informative tutorial ‚Äì hit that play button and embark on your journey with Poe and ChatGPT!




A.I mentoship Training: https://shorturl.at/lwIJK",Kene Digital,2023-08-15T15:49:35Z,2023-09-06T11:45:19Z
255,Axis LLM (Large Language Models) Bankathon 1.0 video presentation,sUVKuCGUHOI,32,6:6,TEAM RESCUE SQUAD,Priyadharshini P CSE,2023-08-15T15:48:28Z,2023-09-06T11:45:19Z
256,Demo video of Axis LLM( Large Language Models) Bankathon 1.0,Wsd5GAtfRzU,40,5:7,TEAM RESCUE SQUAD,Priyadharshini P CSE,2023-08-15T15:48:04Z,2023-09-06T11:45:19Z
257,The Power of Language Models Big Debate on Their Usefulness #aiexplained #aiexploration #aiinsights,MayhI4pDXnQ,17,23,"One idea is that using information theory principles isn't helpful. If the output relies on human input, the synthetic output just duplicates existing signals. So, synthetic data is like empty calories, not useful. Another theory says LLMs excel at creating creative content.

#InfoTheory
#HumanInput
#SyntheticOutput
#DuplicateSignals
#EmptyCalories
#NotUseful
#CreativeTheory
#LLMStrengths
#ContentCreation
#Innovation
#DataDebate
#SyntheticInsights
#ContentGenius
#TheoryTalk
#UselessData
#CreativeGenius
#SignalDuplication
#LLMDebate
#IdeasExchange
#UsefulInsights
#ContentExcellence
#InformationDebate
#CaloriesComparison
#TheoryDiscussion
#DataDilemma
#CreativeMinds
#InfoExchange
#CaloriesMetaphor
#InnovationTalk",TrendingAIs,2023-08-15T15:00:13Z,2023-09-06T11:45:19Z
258,How will we know if AI is ready for healthcare? #shorts,hHsC3kDy8zM,51,58,"In this edition of the Ground Truths podcast, Melanie Mitchell, PhD, and Eric Topol, MD, discuss all things A.I. and large language models. 

Listen to more episodes here: https://erictopol.substack.com/",Scripps Research,2023-08-15T13:00:34Z,2023-09-06T11:45:19Z
259,Using Large Language Models at AngelList // Thibaut Labarre // MLOps Podcast #171,qhGaS1SGkKI,528,51:42,"MLOps Coffee Sessions #171 with Thibaut Labarre, Using Large Language Models at AngelList co-hosted by Ryan Russon.

We are now accepting talk proposals for our next LLM in Production virtual conference on October 3rd. Apply to speak here: https://go.mlops.community/NSAX1O

// Abstract
Thibaut innovatively addressed previous system constraints, achieving scalability and cost efficiency. Leveraging AngelList investing and natural language processing expertise, they refined news article classification for investor dashboards. Central is their groundbreaking platform, AngelList Relay, automating parsing and offering vital insights to investors. Amid challenges like Azure OpenAI collaboration and rate limit solutions, Thibaut reflects candidly. The narrative highlights prompt engineering's strategic importance and empowering domain experts for ongoing advancement.

// Bio
Thibaut LaBarre is an engineering lead with a background in Natural Language Processing (NLP). Currently, Thibaut focuses on unlocking the potential of Large Language Model (LLM) technology at AngelList, enabling everyone within the organization to become prompt engineers on a quest to streamline and automate the infrastructure for Venture Capital.

Prior to that, Thibaut began his journey at Amazon as an intern where he built Heartbeat, a state-of-the-art NLP tool that consolidates millions of data points from various feedback sources, such as product reviews, customer contacts, and social media, to provide valuable insights to global product teams. Over the span of seven years, he expanded his internship project into an organization of 20 engineers.

He received a M.S. in Computational Linguistics from the University of Washington.

// MLOps Jobs board 
https://mlops.pallet.xyz/jobs

// MLOps Swag/Merch
https://mlops-community.myshopify.com/

// Related Links
‚Å†Website: https://www.angellist.com/venture/relay
Foundation by Isaac Asimov: https://www.amazon.com/Foundation-Isaac-Asimov/dp/0553293354
AngelList Relay blog: https://www.angellist.com/blog/introducing-angellist-relay

--------------- ‚úåÔ∏èConnect With Us ‚úåÔ∏è -------------
Join our slack community: https://go.mlops.community/slack
Follow us on Twitter: @mlopscommunity
Sign up for the next meetup: https://go.mlops.community/register
Catch all episodes, blogs, newsletters, and more: https://mlops.community/

Connect with Demetrios on LinkedIn: https://www.linkedin.com/in/dpbrinkm/
Connect with Ryan on LinkedIn: https://www.linkedin.com/in/ryanrusson/
Connect with Thibaut on LinkedIn: https://www.linkedin.com/in/thibautlabarre/

Timestamps:
[00:00] Thibaut's preferred beverage
[00:50] Takeaways
[04:05] Please like, share, and subscribe to our MLOps channels!
[04:44] A huge fan of Isaac Asimov
[07:20] Thibaut Labarre background
[09:13] AngelList as an organization
[10:50] AI sense of building
[12:29] System trade-offs
[15:20] OpenAI's limitation
[16:31] Human in the loop
[17:22] Classifying relevance
[18:09] Fight for value
[19:37] Added value
[22:10] Exploring efficient ways to automate tasks.
[24:20] Investing in off-the-shelf models
[27:56] AngelList Relay
[30:49] News article and investment document classification technology
[32:39] Back-end tech
[34:09] Prompt layer
[35:28] Prompt layer as a living
[37:04] Foreseeing no human intervention
[39:00] Blocking hallucinations 
[40:33] Challenges
[43:49] Investments in other models besides OpenAI
[45:20] Integration with other models
[46:28] Ethical concerns when 
[48:37] OpenAI breaking Prompts 
[50:46] Wrap up",MLOps.community,2023-08-15T13:00:18Z,2023-09-06T11:45:19Z
260,How Chatbots and Large Language Models Work,X-AWdfSFCHQ,12376,7:21,"Large Language Models like ChatGPT have remarkable abilities to generate content based on  training data but do they have actual intelligence? Find out more about how LLM's and Chatbots work as we explore this question. 

Featuring:
Mira Murati the CTO of OpenAI
Crist√≥bal Valenzuela the creator of Runway

Presented by: Code.org, ETS, ISTE, Khan Academy

Start learning today!
https://code.org/ai/how-ai-works

Stay in touch with us on social media:
‚Ä¢ Twitter: https://twitter.com/codeorg
‚Ä¢ Facebook: https://www.facebook.com/Code.org
‚Ä¢ Instagram: https://instagram.com/codeorg
‚Ä¢ TikTok: https://tiktok.com/@code.org
‚Ä¢ LinkedIn: https://www.linkedin.com/company/code-org
‚Ä¢ Medium: https://medium.com/@codeorg

Help make our work possible with a donation at http://code.org/donate!",Code.org,2023-08-15T12:40:35Z,2023-09-06T11:45:19Z
261,Key Considerations For Responsible Deployment of Large Language Models for Online Communities,lq1OFeFihR8,7,59,"Discover the critical factors that demand careful thought before introducing LLMs into online communities. From community engagement to content moderation, Todd Nilson, Online Community Strategist & Founder of Clocktower Advisors, guides community managers and organizations through a strategic approach to ensure a seamless integration that aligns with community values and fosters a safe and inclusive environment.",SearchUnify,2023-08-15T12:33:00Z,2023-09-06T11:45:19Z
262,Large Language Models (LLM) - Porque voc√™ deve entender,Wdo8qEqhcME,249,1:7:20,"IA, chatCPT, OpenAI s√£o as hashtags do momento. Mas o que est√° por tr√°s desses nomes da moda? Nesta sess√£o conversaremos sobre LLM para que voc√™ entenda e tenha cada vez mais seguran√ßa nas suas escolhas. 

Refer√™ncia de Conte√∫do: 
https://aka.ms/Learn.LLM

Speaker: 

Dani Monteiro √© Mestra em Engenharia da Computa√ß√£o, TEDx Speaker, autora do blog e do canal PrimeirosDados.com. Carreira na √°rea de dados h√° 20 anos. J√° foi DBA, arquiteta, consultora, engenheira de dados e atuou como Cloud Solutions Architect de Dados e Intelig√™ncia Artificial na Microsoft. Durante sua carreira ganhou diversos pr√™mios dentro e fora do Brasil, como por exemplo: 
‚Äì MongoDB Champion; 
‚Äì Google Developer Expert (GDE); 
‚Äì Microsoft Regional Director; 
‚Äì Microsoft MVP Reconnect; 
‚Äì Women in IA (pr√™mio concedido pela I2AI); 
‚Äì William Zola (pr√™mio de inova√ß√£o da MongoDB); 
‚Äì MongoDB Female Innovator; 
‚Äì Microsoft Innovative Educator Expert; 
‚Äì Associada Not√°vel da I2AI;Palestrou nos maiores eventos do Brasil, muitas vezes como keynote, e no exterior participou de grandes eventos. Foi a primeira mulher brasileira a palestrar no MongoDB World ( New York), palestrou no Oracle Code One (S√£o Francisco), e no PHP Benelux (B√©lgica). Al√©m disso, √© instrutora oficial do LinkedIn Learning. Adora o seu trabalho com dados, mas √© apaixonada por pessoas, e por isso ela convida a todos a escutar sua

[eventID:20522]",Microsoft Reactor,2023-08-15T11:32:05Z,2023-09-06T11:45:19Z
263,"PRODIGY v1.13: SPACY-LLM support, more LLM backends, better prompts and local model support!",zEu-ZJz0NOo,610,14:15,"Prodigy (https://prodi.gy) is a modern annotation tool for collecting training data for machine learning models, developed by the makers of spaCy. Version 1.13 adds support for spaCy-LLM, which makes it easy to use LLM-powered spaCy pipelines for all your annotation use-cases. 

TIMESTAMPS
- [00:00] Introduction
- [00:39] LLMs in spaCy
- [03:02] Using spaCy-LLM
- [06:32] spaCy-LLM in Prodigy
- [08:40] Better prompts
- [11:43] More features
- [13:08] Deprecation for OpenAI recipes

PRODIGY
‚óè Website & docs: https://prodi.gy
‚óè Live demo: https://prodi.gy/demo
‚óè Forum: https://support.prodi.gy

THIS VIDEO
‚óè v1.13 Changelog: https://prodi.gy/docs/changelog#v1.13.0
‚óè Prodigy LLM Docs: https://prodi.gy/docs/large-language-models
‚óè spaCy-LLM Docs: https://spacy.io/usage/large-language-models",Explosion,2023-08-15T10:03:04Z,2023-09-06T11:45:19Z
264,PickGPT ‚Äì a Large Language Model for generalized Robot Manipulation,31Xqw_59XZ8,2261,1:35,"Sereact PickGPT is an industry-first, no-code, training-free software-defined robotics solution that increases the accuracy and efficiency of robotic piece picking for high-volume use cases. PickGPT combines the power of large language models ‚Äì similar to those used in ChatGPT ‚Äì with Sereact‚Äôs proprietary computer vision models to enable robots to pick and manipulate objects in real-world scenarios with a level of intelligence and accuracy that was previously impossible.

____________________

Find out more about PickGPT and other use cases on our website: https://sereact.ai/pickgpt",Sereact,2023-08-15T09:58:46Z,2023-09-06T11:45:19Z
265,Introducing Outlines: Generate Valid JSON with LLMs and Python,1RAx2RwptdE,55,2:31,"The post introduces a Python library called Outlines that uses large language models to generate text that matches regular expressions or follows a JSON schema. The library includes features such as multiple choice, type constraints, and dynamic stopping. It is designed to be compatible with other libraries and models, and it integrates with HuggingFace's transformers models. The comments discuss various aspects of language model usage, including instruction-tuning, benchmarking, and the challenges of generating valid JSON. Some users share their experiences with different models and techniques for generating structured data.

üîó https://github.com/normal-computing/outlines

#AI #LLM #GPT4 #Prompt",AI Insight News,2023-08-15T07:08:53Z,2023-09-06T11:45:19Z
266,Can Language Models Learn to Listen?,djpSOhdIU8M,174,4:52,"Project page:  https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/
Code: https://github.com/sanjayss34/lm-listener
Paper: https://arxiv.org/abs/2308.10897v1

Abstract:
We present a framework for generating appropriate facial responses from a listener in dyadic social interactions based on the speaker's words. Given an input transcription of the speaker's words with their timestamps, our approach autoregressively predicts a response of a listener: a sequence of listener facial gestures, quantized using a VQ-VAE. 
Since gesture is a language component, we propose treating the quantized atomic motion elements as additional language token inputs to a transformer-based large language model. Initializing our transformer with the weights of a language model pre-trained only on text results in significantly higher quality listener responses than training a transformer from scratch. We show that our generated listener motion is fluent and reflective of language semantics through quantitative metrics and a qualitative user study. In our evaluation, we analyze the model's ability to utilize temporal and semantic aspects of spoken text.",evonne,2023-08-15T04:00:16Z,2023-09-06T11:45:19Z
267,An observation on Generalization,AKMuA_TVz3A,91647,57:21,"Ilya Sutskever (OpenAI)
https://simons.berkeley.edu/talks/ilya-sutskever-openai-2023-08-14
Large Language Models and Transformers",Simons Institute,2023-08-14T23:10:22Z,2023-09-06T11:45:19Z
268,"Towards Reliable Use of Large Language Models: Better Detection, Consistency, and Instruction-Tuning",vuWbJlBePPA,4994,1:3:55,"Christopher D. Manning (Stanford University)
Towards Reliable Use of Large Language Models: Better Detection, Consistency, and Instruction-Tuning
Large Language Models and Transformers

While large pre-trained language models (LLMs) have enabled impressive results on a wide variety of tasks, even the largest existing models will answer inconsistently or head off in weird directions. For companies to be able to gain the benefits of these models in production use, it is now necessary to build an extensive tool ecosystem around the LLM engine, just like cars have seat belts, dash warning lights, and anti-lock brakes. In this talk, I will show recent work considering three such tools. (1) ConCORD: a lightweight method for improving LLM consistency through the use of off-the shelf Natural Language Inference models. (2) DetectGPT, a method to better detect LLM-generated text by looking at model probability function curvature. (3) Direct Preference Optimization, a new way of learning to steer LLMs from human preference data without needing to learn a reward model. Joint work with Eric Mitchell, Chelsea Finn, and many other Stanford coauthors.",Simons Institute,2023-08-14T21:46:50Z,2023-09-06T11:45:19Z
269,LLM2 Module 2 - Efficient Fine-Tuning | 2.2 Module Overview,NcHLXlLi3S4,488,12:6,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:17Z,2023-09-06T11:45:19Z
270,LLM2 Module 1 - Transformers | 1.3 The Transformer Block,ZOdMXz2jEBw,528,8:43,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:17Z,2023-09-06T11:45:19Z
271,LLM2 Module 1 - Transformers | 1.7 Generative Pre-trained Transformer,yMYeNc2fktA,320,12:10,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:23Z,2023-09-06T11:45:19Z
272,LLM2 Module 1 - Transformers | 1.4 Transformer Architectures,x_at2KnUaXM,494,9:46,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:34Z,2023-09-06T11:45:19Z
273,LLM2 Module 3 - Deployment and Hardware | 3.2 Module Overview,uXKHtZ09qL4,152,2:40,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:25Z,2023-09-06T11:45:19Z
274,LLM2 Module 1 - Transformers | 1.6 Base/Foundation Models,sJsPgRg883w,605,6:44,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:35Z,2023-09-06T11:45:19Z
275,LLM2 Foundation Models from the Ground Up | Primer,W0c7jQezTDw,1097,5:59,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:22Z,2023-09-06T11:45:19Z
276,LLM2 Module 4 - Multi-modal LMs | 4.2 Module Overview,ojqG8St1FLA,114,3:28,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:23Z,2023-09-06T11:45:19Z
277,LLM2 Module 3 - Deployment and Hardware | 3.3 Improving Learning Efficiency,HSfpKlmj2xM,128,8:41,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:06Z,2023-09-06T11:45:19Z
278,LLM2 Module 3 - Deployment and Hardware | 3.4 Improving Learning Efficiency,Qe07jhYQ0_E,70,5:39,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:10Z,2023-09-06T11:45:19Z
279,LLM2 Module 1 - Transformers | 1.2 Module Overview,Zpsnxl-w6go,596,4:8,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:14Z,2023-09-06T11:45:19Z
280,LLM2 Module 4 - Multi-modal LMs | 4.7 Emerging Applications,GqGAXn-HSR4,60,3:11,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:06Z,2023-09-06T11:45:19Z
281,LLM2 Module 4 - Multi-modal LMs | 4.6 Challenges and Alternative Architectures,C92JruEOEXc,117,5:37,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:04Z,2023-09-06T11:45:19Z
282,LLM2 Module 1 - Transformers | 1.1 Introduction,Z5QsY0R0Cpg,575,2:,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:13Z,2023-09-06T11:45:19Z
283,LLM2 Module 4 - Multi-modal LMs | 4.1 Introduction,9KxLFIx725E,110,2:58,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:04Z,2023-09-06T11:45:19Z
284,LLM2 Module 4 - Multi-modal LMs | 4.5 Few-shot learning,OuPAQRp0eZg,65,8:17,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:11Z,2023-09-06T11:45:19Z
285,LLM2 Module 2 - Efficient Fine-Tuning | 2.1 Introduction,DUcHtG95cEU,712,3:51,"To participate in discussion forums, enroll in our Large Language Models course on edX for free here: https://www.edx.org/learn/computer-programming/databricks-large-language-models-foundation-models-from-the-ground-up

All notebooks and slides are hosted on https://github.com/databricks-academy/llm-foundation-models. You can find slides under the Releases section.",Databricks,2023-08-14T19:00:04Z,2023-09-06T11:45:19Z
286,Large Language Model Evaluations - What and Why,CMn-nuRhkQA,276,42:58,"Join the Data Phoenix Slack community: https://join.slack.com/t/data-phoenix/shared_invite/zt-115lu0xo1-KhDX_4xAyEd4JiuiUZ3ieQ
Subscribe to Data Phoenix Digest: https://dataphoenix.info/subscribe/
===========================

Large language models are trained on billions of data points and perform exceptionally well across a wide range of tasks. However, one aspect where these models often fall short is their lack of determinism. While building a prototype of an LLM application has become remarkably easy, transforming that prototype into a fully-fledged product is equally challenging. Even with carefully crafted prompts, the model can exhibit problematic behavior such as hallucinations, incorrect output structures, toxic or biased responses, or irrelevant replies for certain inputs. The potential error modes can be extensive.

This is where a robust LLM evaluation tool like UpTrain comes to the rescue which empowers you to:
- Validate and correct the model's responses before presenting them to end-users.
- Obtain quantitative measures for experimenting with multiple prompts, model providers, and more.
- Conduct unit testing to ensure that no faulty prompts or code make their way into your production environment.
Join us for an insightful talk as we delve deep into the intricacies of assessing the performance and quality of LLMs and discover the best practices to ensure the reliability and accuracy of your LLM applications.

Sourabh Agrawal
Sourabh is a 2X founder in the AI/ML space. He started his career working at Goldman Sachs where he built ML models for financial markets. Post that he joined the autonomous driving team at Bosch/Mercedes, building state-of-the-art CV modules for scene understanding. He started his entrepreneurial journey in 2020 and founded an AI-powered fitness startup that he scaled to 150K+ users. During his past experiences, he encountered a frequent source of frustration due to the lack of tools to evaluate these models- a problem even more pronounced in the case of Generative AI models. To solve this, he is building UpTrain - an open-source tool to evaluate, prompt test, and monitor LLM applications.",Data Phoenix Events,2023-08-14T18:53:06Z,2023-09-06T11:45:19Z
287,Sparks of Artificial General Intelligence,Yh-hC4tfBhU,7525,1:11:27,"Yin Tat Lee (Microsoft Research)
https://simons.berkeley.edu/talks/yin-tat-lee-microsoft-research-2023-08-14
Large Language Models and Transformers

Before the introduction of GPT-4, there was a widespread belief that AI was primarily about pattern recognition without genuine understanding. Yet, GPT-4 challenged this perspective, showcasing comprehensive knowledge that went beyond pattern matching. In our talk, we will provide numerous examples that highlight these sparks of AGI in GPT-4. This revelation raises a critical question: is this hint of AGI evident only in expansive models?

To investigate this, we explored the capabilities of a smaller size model geared towards code generation. We demonstrate that with high-quality data, the demand for expansive datasets and a multitude of parameters lessens. The outcome was a 1.3B size model, which not only met or exceeded the performance of existing open-source models but did so utilizing a mere 1/1000th of compute in training. Moreover, we will discuss specific emergent properties observed in the model after its fine-tuning on coding exercises.",Simons Institute,2023-08-14T18:35:32Z,2023-09-06T11:45:19Z
288,"Lesson 1: Large Language Models - LLM Deep Dive with ChatGPT, Bard, and Bing",Kpr_dnlFSOo,39,35:30,"Coursework for Credits:
If taking this course for a credit, it is recommended to complete 4 hours of study each week. The lesson and activity are about 1hr of learning. For the remaining 3 hours for your study this week, here are the recommended resources for this lesson.


I really enjoyed this LLM deep dive by a true legend in the ai research community, Andrej Karpathy. Andrej is one of the fathers of Tesla's self-driving ai, and is one of the top people in the world for innovating and building ai models. As of this writing he currently works with OpenAI on their cutting-edge LLM ai research.

Andrej created a course that is now legendary about how to actually build your own LLM. Following along (and for the more intensely committed among you, actually building along with him) will create a deeper understanding and intuition of exactly how LLMs like ChatGPT work.

For the rest of this week's study, look no further than Andrej's amazing lesson about building GPT from scratch:

https://youtu.be/kCc8FmEb1nY

While the video is only about 2 hours, reset assured - if you're really engaging with Andrej's lesson, you will definitely need to pause it and look some things up for yourself. For me, many of the things he briefly mentioned in passing required me rewinding the video a few minutes, and it took me about 4 hours to finish the video.

Enjoy! While it will be somewhat dense, it's really world-changing info, and Andrej is an excellent instructor. Even if you don't fully understand everything in it (I certainly did not), the things you take from it will continue to inform you for many years.Coursework for Credits:
If taking this course for a credit, it is recommended to complete 4 hours of study each week. The lesson and activity are about 1hr of learning. For the remaining 3 hours for your study this week, here are the recommended resources for this lesson.


I really enjoyed this LLM deep dive by a true legend in the ai research community, Andrej Karpathy. Andrej is one of the fathers of Tesla's self-driving ai, and is one of the top people in the world for innovating and building ai models. As of this writing he currently works with OpenAI on their cutting-edge LLM ai research.

Andrej created a course that is now legendary about how to actually build your own LLM. Following along (and for the more intensely committed among you, actually building along with him) will create a deeper understanding and intuition of exactly how LLMs like ChatGPT work.

For the rest of this week's study, look no further than Andrej's amazing lesson about building GPT from scratch:

https://youtu.be/kCc8FmEb1nY

While the video is only about 2 hours, reset assured - if you're really engaging with Andrej's lesson, you will definitely need to pause it and look some things up for yourself. For me, many of the things he briefly mentioned in passing required me rewinding the video a few minutes, and it took me about 4 hours to finish the video.

Enjoy! While it will be somewhat dense, it's really world-changing info, and Andrej is an excellent instructor. Even if you don't fully understand everything in it (I certainly did not), the things you take from it will continue to inform you for many years.",Future Homeschool,2023-08-14T17:33:35Z,2023-09-06T11:45:19Z
289,ML in 2 Paper: LLMZip - Lossless Text Compression using Large Language Models,6PPsDt79S8I,20,3:6,"2-minute review of the paper titled ‚ÄúLLMZip: Lossless Text Compression using Large Language Models‚Äù

The manuscript is available for free at: https://arxiv.org/abs/2306.04050

Timestamps:

Intro and Problem 00:00
Method 00:25
Results 02:31


I hope you find it useful.
Thanks!

Disclaimer: I am NOT an author of the papers mentioned above, and all rights belong to its authors and publishers. My views, explanations, criticisms, and discussions are not reviewed by the authors.",Shayan Fazeli,2023-08-14T17:18:22Z,2023-09-06T11:45:19Z
290,Unveiling the Power of Large Language Models in Conversational AI,wfEupy_e8iw,52,1:2:4,A webinar on maximizing capabilities and ethical considerations,Lucidworks,2023-08-14T17:18:56Z,2023-09-06T11:45:19Z
291,"How Can Large Language Models and Chat Tools Help Communities Find, Access, Understand, and Act...",8Mxa-c3iDp4,22,1:32:10,"Recording of session held at 2023 July ESIP Meeting held in Burlington VT and online, July 18-21, 2023. Learn more at https://sched.co/1Noe8.",ESIP,2023-08-14T16:33:04Z,2023-09-06T11:45:19Z
292,This is how #ChatGPT came to be!,2dBSCW3c6EQ,2137,35,It's how the magic happens for all large language models. #AI #tech,4Geeks Academy,2023-08-14T15:42:05Z,2023-09-06T11:45:19Z
293,Reinforcement Learning:  ChatGPT and RLHF,WMmGzx-jWvs,944,6:31,"Reinforcement Learning from human feedback, and how it's used to help train large language models like ChatGPT.
Part 3 of RL from scratch series.
https://youtu.be/vXtfdGphr3c

0:00 - intro
0:06 - large language models
0:35 - learning to tell jokes
1:13 - fine tuning with better data
1:26 - positive and negative examples
2:03 - reinforcement learning for LLMs
3:00 - labeling fewer examples
3:56 - reward networks
5:08 - summing it up
5:23 - variants
5:57 - chatGPT, Bard, Claude, Llama
6:09 - finally, a good joke!",Graphics in 5 Minutes,2023-08-14T14:39:59Z,2023-09-06T11:45:19Z
294,How AI and Large Language Models (LLMs) Work by Bernard Huang of Clearscope,FVhdGdpmZAo,34,10:41,"This is an excerpt from Bernard Huang, co-founder of Clearscope, webinar How to Rank SEO Content in the Era of Generative AI.

Watch the full webinar here: https://www.clearscope.io/webinars/rank-seo-content-in-the-era-of-generative-ai-bernard-huang 

Subscribe for more videos on content and SEO.
https://www.youtube.com/clearscope?sub_confirmation=1

About Bernard Huang:

Bernard is the co-founder of Clearscope, the leading SEO optimization and monitoring software for high-quality content teams. Before Clearscope, Bernard started an SEO consulting agency, was a growth advisor in residence at 500 Startups, and led growth at a YC startup called 42Floors.

Clearscope (https://www.clearscope.io/) is the best-in-class SEO content optimization platform that drives search traffic.

Follow us on:
YouTube üëâ  https://www.youtube.com/clearscope?sub_confirmation=1
Twitter üëâ  https://twitter.com/clearscope
LinkedIn üëâ  https://www.linkedin.com/company/clearscopeio
Email üëâ  https://share.hsforms.com/19TFY9Fk8TvCmFvnS6SLingcy7n6",Clearscope,2023-08-14T14:00:11Z,2023-09-06T11:45:19Z
295,Unraveling Large Language Models and The Rise of Chat GPT,uRO-cf5F13A,24,44:13,"On November 30, 2022, the launch of Chat GPT marked a momentous step towards mainstream AI awareness, amassing over 100 million users within two months. This introduction spurred a rapid expansion of applications, tools, and integrations with the AI technology. 

Connor Heaton, VP of Intelligent Automation and AI at Strategic Resource Management, Inc. joined the Banking on Digital Growth Podcast to emphasize the vast potential of AI tools, especially Large Language Models (LLMs), in the financial realm. 

Their potential to transform customer service, risk assessment, fraud detection, and financial forecasting is remarkable. However, there are challenges, such as inherent biases in the AI models, the 'black box' problem which alludes to the lack of transparency in AI decisions, and the risk of over-relying on AI without human oversight.

Understanding and leveraging AI is paramount in today's dynamic technological environment, and humans must learn to collaborate with AI to drive innovation, growth, and value creation.

---------------------------------------------  

Connect with James Robert Lay ‚ù§Ô∏è  

üôå LinkedIn: https://www.linkedin.com/in/jrwlay
üëç Twitter: https://twitter.com/jrwlay

--------------------------------------------- 

Topics:
0:00 Intro to this episode. 
1:42 What is good in your world right now? 
5:27 What is AI and how does it work? 
10:38 The evolution of the technology. 
16:20 How to keep up with exponential change? 
23:41 How do we focus on human transformation? 
27:15 Misconceptions about Ai and its benefits. 
31:00 Dangers and pitfalls of large language models. 
37:37 Practical use cases for data.",Digital Growth Institute,2023-08-14T13:45:04Z,2023-09-06T11:45:19Z
296,Language Models Can Learn To Draw From Text Alone,ezy2ZvJz9bc,2951,7:19,"Yoon Kim is an assistant professor at MIT. He obtained his PhD in computer science from Harvard University, where he was advised by Alexander Rush (http://rush-nlp.com/). He is interested in natural language processing and machine learning. Current interests include: Efficient training and deployment of large-scale models; Understanding the capabilities and limitations of language models; Symbolic mechanisms for controlling and augmenting neural networks; and Connections between computational and human language processing.


Subscribe to FORBES: https://www.youtube.com/user/Forbes?sub_confirmation=1

Fuel your success with Forbes. Gain unlimited access to premium journalism, including breaking news, groundbreaking in-depth reported stories, daily digests and more. Plus, members get a front-row seat at members-only events with leading thinkers and doers, access to premium video that can help you get ahead, an ad-light experience, early access to select products including NFT drops and more:

https://account.forbes.com/membership/?utm_source=youtube&utm_medium=display&utm_campaign=growth_non-sub_paid_subscribe_ytdescript

Stay Connected
Forbes newsletters: https://newsletters.editorial.forbes.com
Forbes on Facebook: http://fb.com/forbes
Forbes Video on Twitter: http://www.twitter.com/forbes
Forbes Video on Instagram: http://instagram.com/forbes
More From Forbes:  http://forbes.com

Forbes covers the intersection of entrepreneurship, wealth, technology, business and lifestyle with a focus on people and success.",Forbes,2023-08-14T13:13:41Z,2023-09-06T11:45:19Z
297,What Is The OWASP Top 10 For Large Language Models?,z5xPfsTyXyo,107,8:5,"Aubrey King, host of DevCentral's 'This Month In Security' podcast talks with Steve Wilson about the OWASP Top 10 for Large Language Models. Find out what it is, why you may need to secure your infrastructure and how to get involved!

OWASP Top 10 For Large Language Models:
https://owasp.org/www-project-top-10-for-large-language-model-applications/

00:00 Introduction
00:39 What Is A Large Language Model?
02:16 Why Secure Them?
03:48 What's The Impact On Your Tech Stack? 
06:19 How To Get Involved
07:45 Outro

‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è JOIN THE COMMUNITY! ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è

DevCentral is an online community of technical peers dedicated to learning, exchanging ideas, and solving problems - together.

Find all our platform links ‚¨áÔ∏è and follow our Community Evangelists! üëã

‚û°Ô∏è DEVCENTRAL: https://community.f5.com 
‚û°Ô∏è YOUTUBE: https://youtube.com/devcentral 
‚û°Ô∏è LINKEDIN: https://www.linkedin.com/showcase/f5-devcentral/ 
‚û°Ô∏è TWITTER: https://twitter.com/devcentral 

Your Community Evangelists: 
üëã Jason Rahm: https://www.linkedin.com/in/jrahm/ | https://twitter.com/jasonrahm 
üëã Buu Lam: https://www.linkedin.com/in/buulam/ | https://twitter.com/buulam
üëã Aubrey King: https://www.linkedin.com/in/aubreyking | https://twitter.com/aubreykingf5",F5 DevCentral,2023-08-14T12:00:51Z,2023-09-06T11:45:19Z
298,On the Construction of Database Interfaces based on Large Language Models,P1SqD1u9848,9,12:15,"MASTER Workshop
August 11th, 2023 -- RDC 511 / PUC-Rio
On the Construction of Database Interfaces based on Large Language Models 
Marco A. Casanova (Tecgraf and Departamento de Inform√°tica, PUC-Rio)",Marco Antonio Casanova,2023-08-14T12:01:03Z,2023-09-06T11:45:19Z
299,LLM ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? Large Language Model ‡∏ú‡∏π‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á AI ‡πÄ‡∏à‡πã‡∏á‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á ChatGPT Bing ‡πÅ‡∏•‡∏∞ Bard I iT24Hrs,n1iPAtTOu7w,1404,4:44,"LLM ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? Large Language Model ‡∏ú‡∏π‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á AI ‡πÄ‡∏à‡πã‡∏á‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á ChatGPT Bing ‡πÅ‡∏•‡∏∞ Bard I iT24Hrs

Chatbot ‡πÄ‡∏Å‡πà‡∏á‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏î‡∏≤‡πÉ‡∏à‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á ChatGPT Bing ‡πÅ‡∏•‡∏∞ Bard ‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏î‡πâ‡∏≤‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏à‡πã‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á LLM ‡πÅ‡∏•‡πâ‡∏ß‡∏°‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏£‡∏Å‡∏±‡∏ô‡∏•‡πà‡∏∞?     

00:00 ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô 
00:35 LLM ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
01:07 Transformer ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
02:23 LLM ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏´‡∏ô?
02:52 Prompt ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á? / 5 Step ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Prompt

‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏û‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ô‡∏°‡∏≤‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å‡∏Å‡∏±‡∏ö LLM ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÄ‡∏ï‡πá‡∏°‡πÜ ‡∏ß‡πà‡∏≤ Large Language Model ‡∏ã‡∏∂‡πà‡∏á‡∏ñ‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô Algorithms ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á Chatbot ‡∏ó‡∏µ‡πà‡∏à‡∏∂‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏¢‡∏∏‡∏Ñ‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á ChatGPT, Bing ‡πÅ‡∏•‡∏∞ Bard ‡∏Å‡∏±‡∏ô

LLM ‡πÅ‡∏•‡πâ‡∏ß LLM ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á AI ‡∏°‡∏≤‡∏Å ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ AI ‡∏â‡∏•‡∏≤‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ 

Transformer ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏Å‡∏±‡∏ö LLM ‡πÅ‡∏•‡∏∞ AI ‡∏Å‡∏£‡∏∞‡∏ö‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Å Transformer ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏Ç‡∏≠‡∏á  LLM ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Attention Mechanism ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡πÑ‡∏°‡∏ñ‡∏∂‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÑ‡∏î‡πâ

‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ Large ‡πÉ‡∏ô LLM ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏´‡∏ô? Chatgpt ‡∏°‡∏µ Parameter ‡πÉ‡∏´‡∏ç‡πà‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏´‡∏ô?  ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏™‡∏°‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå 

‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Prompt ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ó‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡∏°‡∏µ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á? 

‡∏≠‡∏≠‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå‡∏ó‡∏µ‡πà 13 ‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏° 2566 
‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‡πÑ‡∏≠‡∏ó‡∏µ24‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á ‡∏ó‡∏≤‡∏á‡∏ä‡πà‡∏≠‡∏á 9 MCOT HD 
‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå ‡πÄ‡∏ß‡∏•‡∏≤ 13.00 ‡∏ô.

‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà
facebook.com/it24hrs
twitter.com/panraphee
twitter.com/it24hrs
IG: panraphee
TikTok : iT24Hrs

‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤ ‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå ‡∏£‡∏µ‡∏ß‡∏¥‡∏ß ‡∏û‡∏¥‡∏ò‡∏µ‡∏Å‡∏£ ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏£ 
‡πÇ‡∏ó‡∏£ 0802345023
line @it24hrs-sales",iT24Hrs,2023-08-14T11:30:30Z,2023-09-06T11:45:19Z
300,Tech Lab Open Sunday Talk - Decoding AI - A Deep Dive into Large Language Models,AiMIDUbeJZk,95,1:42:19,"Learn about Large Language Models (LLMs) used in applications like ChatGPT and how they work.

In this tech talk, the instructor will give an introduction to Large Language Models (LLM) used in applications like ChatGPT. The following topics will be covered:

What is an LLM?
Very brief overview of Transformer architecture/GPT
How LLMs are trained/fine tuned
Hardware requirements
Closed source tools
LLM Agents
Quantization

Speaker: Kevin Rohling",Rick Gordon,2023-08-13T22:22:39Z,2023-09-06T11:45:19Z
301,Fusing Knowledge Graphs and Large Language Models,RBKHLt3n9rM,407,1:23:24,"Large Language Models, KnowledgeGraphs, Hallucinations, LLMs, ChatGPT

Large Language Models have a major weakness when it comes to facts and their reliability. Knowledge graphs are great for managing facts. These two technologies complement each other and have the potential to address some of the weaknesses that are preventing businesses from adopting LLMs. How to properly fuse LLMs and knowledge graphs is an active area of research.

This webinar was originally streamed  Thursday, August 10th  on LinkedIn. During the live stream, there was a major audio problem. This video has been edited to address those issues. As a result of my editing, there are a few sudden transitions, but overall it's coherent.

If you are interested in this topic and wish to connect. Here is a link to my LinkedIn profile:
https://www.linkedin.com/in/rudy-agovic-phd-a35b9b9/

Link to GitHub repository with relevant references:
https://github.com/RManLuo/Awesome-LLM-KG",Rudy's AI Corner,2023-08-13T21:10:21Z,2023-09-06T11:45:19Z
302,LLM Python CrashCourse JCharisTech,FkteUP49lb0,364,16:59,"In this tutorial we will explore a python library called LLM (created by the co-creator of Django Framework) for large language models.

‚ö° LLM Python‚ö° : How to use LLM as a CLI or a Python Library


üíª Code:https://github.com/jcharis
üìù Blog:https://blog.jcharistech.com
üì∫ Become a Patron:https://www.patreon.com/jcharistech


üéì=== Check out these Awesome Data Science Courses!===üéì
üßëüèª‚Äçüîß Building ML Web Apps:https://www.udemy.com/course/building-machine-learning-web-apps-with-python/?referralCode=0708D7CBFE0B755E3869
üßëüèª‚Äçüéì Learn Streamlit: https://www.udemy.com/course/learn-streamlit-python/?referralCode=69B20B53EC91BE05DCA8
üßë‚ÄçüéìBioInformatics in Python:https://www.udemy.com/course/bioinformatics-with-python/?referralCode=F77A6E8863E460D0FD19
ü§µüèª Go4DataScience & Go For NLP(Udemy): https://www.udemy.com/course/go-for-data-science-and-natural-language-processing-golang/?referralCode=230456D247CDA3CC794F
üßëüèª‚Äçüîß Machine Learning in Python:https://www.udemy.com/course/machine-learning-in-python-extras/?referralCode=037F1194A808C500E8DF
üßëüèª‚Äçüéì DVC and Git For Data Science:https://www.udemy.com/course/dvc-and-git-for-data-science/?referralCode=A92EC101965A2C4A876F


If you liked the video don't forget to leave a like üëç or subscribe ‚ù§Ô∏è. 
‚ö° If you need any help just message me in the comments, you never know it might help someone else too. ‚ö°

JCharisTech

‚è≤Ô∏è===TimeStamps===‚è≤Ô∏è 
0:01 Introduction 
01:10 List LLM models
01:30 Working with OpenAI
01:50 Install Plugin (Gpt4all)
03:16 Download Models and Usage
05:20 Set A Default LLM 
08:15 Usage as a Python Library
11:38 Chain of Thoughts with Conversation 
16:38 Recap

Support the Channel: Become a Patreon
üì∫  Become a Patron:https://www.patreon.com/jcharistech


‚óæ‚óæ‚óæGet The Data Science Prime App‚óæ‚óæ‚óæ
 @ Playstore : http://bit.ly/2LArYQu
 
‚óæ‚óæ‚óæ Need Your Dataset Cleaned check out this gig ‚óæ‚óæ‚óæ
https://www.fiverr.com/jesiel_/clean-your-dataset-with-python


Follow
üíª https://www.facebook.com/jcharistech/
üåé Website: https://jcharistech.com
üìÇ GitHub: https://github.com/Jcharis/
üì± Twitter: https://twitter.com/JCharisTech
üìù Blog: https://blog.jcharistech.com
üì∫ Patreon: https://www.patreon.com/jcharistech
üåê WP: https://jcharistech.wordpress.com/
üè´ Course: http://jcharistech-institute.thinkific.com/courses/",JCharisTech,2023-08-13T20:42:22Z,2023-09-06T11:45:19Z
303,Introduction to Large Language Models,lJxBzgg4OR0,2385,1:23:34,LLM Bootcamp- Zero to Hero in LLMs- Module 1: Introduction to Large language models by Sandeep Giri,AI Planet,2023-08-13T01:35:27Z,2023-09-06T11:45:19Z
304,AI Models Enter the Third Dimension with This 3D-LLM Breakthrough,Qqge-kFh8RA,48,51,"A huge breakthrough has just been made in AI and 3D vision - researchers have created the first ever 3D Large Language Model (3D-LLM)! This model takes 3D point clouds as input, allowing it to actually 'see' and understand 3D spaces.

In this video, we'll explain how 3D-LLMs work and why this is such an important advancement for AI. For the first time, these models can take raw 3D data as input and complete complex 3D-related tasks like dense captioning, 3D question answering, 3D-assisted dialogue, and even navigation.

Giving AI models 'eyes' to perceive the 3D world promises to unlock new capabilities like deeper visual scene understanding, embodied AI agents that can move and interact in 3D spaces, and multimodal applications that combine language, vision, and spatial reasoning.

We'll showcase some examples of a 3D-LLM in action, demonstrating how it can generate detailed captions of 3D scenes, answer questions about 3D point cloud data, and understand spatial concepts that previous AI systems couldn't grasp.

This combination of large language models and 3D sensory input represents an exciting new frontier in artificial intelligence research. The applications for contextual visual intelligence powered by 3D-LLMs could be immense, from robotics to VR/AR and beyond. This video will explore exactly how impactful this latest breakthrough could be!",Champion Edtech,2023-08-13T01:04:13Z,2023-09-06T11:45:19Z
305,ML Study Group at Apple: &quot;Transformer Architectures of Multimodal Language Models&quot;,JYJuCEzGpto,694,40:29,"Presented by Hongyu H√® at Apple Ô£ø Visual Intelligence study group.

00:00 Contents
01:01 Transformer architectures
01:40 Evolution of transformer models
05:15 Encoder-only models
07:18 Encoder-only pros and cons
08:11 Encoder-decoder models
09:38 Encoder-decoder pros and cons
11:25 Decoder-only models
13:40 Decoder-only pros and cons
15:57 BLIP-2 and InstructBLIP
24:00 Modality bridging: cross-attention
27:15 Florence: A New Foundation Model for Computer Vision
28:20 Flamingo: a Visual Language Model for Few-Shot Learning
30:20 BLIP-1 BLIP-2 models
31:31 CoCa: Contrastive Captioners are Image-Text Foundation Models
32:43 Modality bridging: decoder prompt tuning
34:13 Multimodal Few-Shot Learning with Frozen Language Models
34:35 Grounding Language Models to Images for Multimodal Inputs and Outputs
35:10 LLaVA: Large Language and Vision Assistant
35:30 Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks
36:12 Modality adapters: LLaMA-adapter
37:34 Multiway transformers: BEiT3
37:58 Lynx: What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?
39:40 Summary

#transformers #multimodal #machinelearning",Hongyu H√®,2023-08-12T17:12:33Z,2023-09-06T11:45:19Z
306,EPIC &quot;LLMs Suck&quot; RANT - Auto Regressive Large Language Models Cannot Do THIS | Prof  Yann LeCun,mJthVEr4PN4,141,5:6,Prof. Yann LeCun (NYU/Meta),Tech Stories 101,2023-08-12T16:18:55Z,2023-09-06T11:45:19Z
307,NEW Platypus 70B: The New Open-Source LLM King,oquIJlTf-iU,4886,12:44,"Welcome to our groundbreaking journey through the revolutionary Platypus method! In this video, we dive deep into the intricacies of fine-tuning Large Language Models (LLMs) with the ingenious Platypus approach, which has skyrocketed to the top of HuggingFace's Open LLM Leaderboard! üèÜ

üî• Become a Patron: https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 

Must watch: 
LLAMA 2 IS OUT! FREE Open Source LLM For Commercial Use! (Installation Guide) - https://youtu.be/HLPj6DPkabc
Stability Ai's NEW FreeWilly Opensource LLM IS INCREDIBLE! - https://youtu.be/zLaFOPB8DVk
AgentBench: NEW Benchmarking Tool CHANGES The LLM LEADERBOARD (Installation Tutorial) - https://www.youtube.com/watch?v=EiFVJUFiRVQ&t=639s&ab_channel=WorldofAI

[Links Used]:
Platypus Blog Post: https://platypus-llm.github.io/
Github Repo: https://github.com/arielnlee/Platypus
Research Paper: https://platypus-llm.github.io/Platypus.pdf
Opensource Leaderboard: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard

Discover the secrets behind Platypus, a game-changing method that has captured the limelight in the realm of LLM fine-tuning. Unveil the blend of factors that propelled Platypus to the zenith: meticulous curation of the Open-Platypus dataset, a sophisticated fine-tuning process involving LoRA module merging, and an unyielding commitment to data quality assurance.

üìú Video Highlights:
- Open-Platypus Dataset Unveiled: We unravel the genesis of Platypus, built upon the bedrock of the thoughtfully curated Open-Platypus dataset. This dataset isn't just about quantity; it's meticulously chosen to ensure high-quality training examples spanning diverse scenarios, making Platypus a cut above the rest.
- LoRA Modules and Fine-Tuning Fusion: Delve into the synergy of Platypus, where LoRA modules merge seamlessly with fine-tuning prowess. Witness the harmonious blend of pre-trained LLM knowledge and domain expertise, elevating performance while retaining the essence of pre-training.
- Data Quality Shield: Explore the lengths to which we've gone to ensure the sanctity of your data. We share insights into our stringent measures that prevent test data leaks and contamination in training data, boosting the reliability of our results.

If you're as excited as we are about revolutionizing the LLM landscape, show your support! Smash that üëç button, subscribe üîî for more transformative content, and spread the knowledge by sharing this video with your peers! Let's embark on this innovation journey together.

üîñ Additional Tags:
Platypus Method, LLM Fine-Tuning, Open-Platypus Dataset, LoRA Module Merging, Data Quality Assurance, HuggingFace Leaderboard, Innovation in NLP, Language Model Advancements, NLP Research, Advanced Machine Learning
üì£ Hashtags:
#PlatypusMethod #LLMFineTuning #NLPInnovation #OpenPlatypusDataset #DataQualityAssurance #LanguageModelAdvancements #HuggingFaceLeaderboard #NLPResearch #AdvancedML #InnovationInAI

üåê Connect with us on [link here] for more cutting-edge insights and updates! Let's embark on this transformative journey together. Don't forget to hit that like button, subscribe, and share to keep the innovation flowing! üåü",WorldofAI,2023-08-12T13:00:11Z,2023-09-06T11:45:19Z
308,Elevate Your BPMN Diagrams: Expert Feedback from Advanced AI Models,nbjICkF7i1Y,90,28:31,"Let's dive into the world of Business Process Model and Notation (BPMN) with a focus on how large language models like Google Bard and ChatGPT can assist in refining our processes. Join us to explore how these models interpret and provide feedback on BPMN diagrams, discuss the risks and benefits, and predict the future of process modeling. Tune in for insights, a touch of humor, and an exploration of the tools of the trade!

üöÄ Chapter Markers:
0:00 Introduction
1:54 Overview of BPMN
3:15 Create BPMN model
7:56 Feedback from Google Bard
11:55 Feedback from ChatGPT
17:06 Asking Bard to automate
18:43 Asking GPT to automate
22:10 the XML problem
23:39 Benefits and Risks
26:09 Camunda Modeler vs. Diagram as Code
27:32 Goodbye & Outro

üîó Links & Resources:
Camunda Modeler GitHub: https://github.com/camunda
Getting Started w/ Camunda: https://docs.camunda.io/docs/guides/

‚ù§Ô∏è If you found this video valuable, please like, share, and subscribe for more content like this!",Data Within Reach,2023-08-12T03:29:59Z,2023-09-06T11:45:19Z
309,"&quot;Large Language Models for Education&quot; - Presentation by Dr  Peter Foltz @ RMAIIG Aug 8, 2023",7uBilA0ZIdc,83,25:40,"Dr. Peter Foltz, is Executive Director of the NSF's AI Institute for Student-AI Teaming (iSAT) at CU Boulder which is an interdisciplinary research community dedicated to transforming classrooms into more effective, engaging and equitable learning environments. CU Boulder hosts one of five National Science Foundation's $20 million AI Institutes to accelerate research, expand America's workforce, and transform society in the decades to come. Dr. Foltz is Research Professor at the University of Colorado‚Äôs Institute of Cognitive Science. His work covers machine learning and natural language processing for educational and clinical assessments, large-scale data analytics, cognitive skills in reading and writing, team collaboration, and 21st Century skills learning. 

Presentation at the Rocky Mountain AI Interest Group (RMAIIG) on Tuesday, Aug 8, 2023.    More info on RMAIIG here: https://www.meetup.com/rmaiig/

We explored perspectives and opinions on the proper role of AI tools like ChatGPT, Bard and Midjourney in education. The entire education system is in the midst of a huge ""AI reckoning"" with vastly different approaches being tried, ranging from outright district-wide bans on AI use to some teachers requiring students to use AI tools and weaving AI into the syllabus.

Dr. Peter Foltz, the Executive Director of the National Science Foundation's AI Institute for Student AI Teaming, gave a talk on the topic of large language models and education. He began by sharing his own experience with AI in education, which started when he was a professor and wanted to find a way to make his students' essays more engaging and effective. He developed a technology that automatically scored students' essays for both quality and content, and this allowed students to get instant feedback and revise their work as many times as they wanted.

Dr. Foltz then discussed the recent advances in large language models, which are now able to generate text that is indistinguishable from human-written text. He cited examples of how these models are being used in education, such as to write essays, simplify text, and generate personalized content. He also pointed out some of the challenges posed by large language models, such as the potential for plagiarism and the need for AI literacy.

Dr. Foltz concluded by discussing some of the opportunities that large language models present for education. He believes that these models can be used to improve student engagement, personalize learning, and create new educational experiences. He also stressed the importance of AI literacy, so that students can understand how to use these tools effectively.

Here are some key takeaways from the talk:

Large language models are rapidly evolving and becoming more powerful.
These models can be used to generate text, translate languages, and answer questions in a human-like way.
Large language models are being used in education to improve student engagement, personalize learning, and create new educational experiences.
There are some challenges posed by large language models, such as the potential for plagiarism and the need for AI literacy.
It is important to use large language models responsibly and ethically.

Overall, Dr. Foltz's talk was a thought-provoking exploration of the potential of large language models for education. He highlighted the many benefits of these models, while also acknowledging the challenges that they pose. He concluded by calling for a responsible and ethical use of large language models in education.",RMAIIG,2023-08-12T01:57:57Z,2023-09-06T11:45:19Z
310,Prompt Engineering for Large Language Models (LLMs),viMV1l-lSF0,87,18:52,"This video explores various aspects of prompt engineering for large language models. It covers how well-designed prompts are important to elicit accurate responses from LLMs and reduce risk. Various prompt sources and creation methods are presented, including asking the LLM for help, using prompt libraries, and learning from videos. The document also provides an example of a prompt for discussing UFOs and UAPs based on the model's training in relevant fields like aviation and optics. A checklist for effective prompting is included that stresses clarity, context, and avoiding assumptions. Emergent properties of LLMs are addressed, showing analogical reasoning abilities. Examples are given of TikTok videos showcasing creative LLM uses like content creation, OCR, education, and more. Overall the document presents best practices for crafting prompts to optimize large language model interactions and outputs.",Van Warren,2023-08-11T23:25:58Z,2023-09-06T11:45:19Z
311,00: Introduction and Orientation ‚Äì Large Language Models (NUS CS6101 NUS.WING),seEv0xrt56c,169,46:42,"00:00 Intro
14:32 Logistics (Scribe Document / GSheet)

Slides at http://bit.ly/cs6101-t2310-w00
Video at http://bit.ly/cs6101-t2310-w00-yt",Web IR / NLP Group at NUS,2023-08-11T20:50:58Z,2023-09-06T11:45:19Z
312,Erik Jones‚ÄîAutomatically Auditing Large Language Models,bhE5Zs3Y1n8,411,22:37,"Erik is a Phd at Berkeley working with Jacob Steinhardt, interested in making generative machine learning systems more robust, reliable, and aligned, with a focus on large language models.In this interview we talk about his paper ""Automatically Auditing Large Language Models via Discrete Optimization"" that he presented at ICML.

Paper: https://arxiv.org/abs/2303.04381

Erik: https://twitter.com/ErikJones313
Host: https://twitter.com/MichaelTrazzi

Patreon: https://www.patreon.com/theinsideview

Outline

00:00 Highlights
00:31 Eric's background and research in Berkeley
01:19 Motivation for doing safety research on language models
02:56 Is it too easy to fool today's language models?
03:31 The goal of adversarial attacks on language models
04:57 Automatically Auditing Large Language Models via Discrete Optimization
06:01 Optimizing over a finite set of tokens rather than continuous embeddings
06:44 Goal is revealing behaviors, not necessarily breaking the AI
07:51 On the feasibility of solving adversarial attacks
09:18 Suppressing dangerous knowledge vs just bypassing safety filters
10:35 Can you really ask a language model to cook meth?
11:48 Optimizing French to English translation example
13:07 Forcing toxic celebrity outputs just to test rare behaviors
13:19 Testing the method on GPT-2 and GPT-J
14:03 Adversarial prompts transferred to GPT-3 as well
14:39 How this auditing research fits into the broader AI safety field
15:49 Need for automated tools to audit failures beyond what humans can find
17:47 Auditing to avoid unsafe deployments, not for existential risk reduction
18:41 Adaptive auditing that updates based on the model's outputs
19:54 Prospects for using these methods to detect model deception
22:26 Prefer safety via alignment over just auditing constraints, Closing thoughts

Patreon supporters:
- Tassilo Neubauer
- MonikerEpsilon
- Alexey Malafeev
- Jack Seroy
- JJ Hepburn
- Max Chiswick
- William Freire
- Edward Huff
- Gunnar H√∂glund
- Ryan Coppolo
- Cameron Holmes
- Emil Wallner
- Jesse Hoogland
- Jacques Thibodeau
- Vincent Weisser",The Inside View,2023-08-11T17:03:09Z,2023-09-06T11:45:19Z
313,AWS ML Heroes in 15: Leverage ML Inference for Generative AI Models on AWS - AWS Machine Learning,WOj0FOSP35A,352,15:28,"Machine Learning (ML) is becoming essential for many companies - either as a core product, an internal tool, or as a service for improving operations. One challenge when deploying the Machine Learning model to production is navigating through different hardware, service, and orchestration options. Deployment becomes even more challenging when it needs to work with foundational models. This webinar will focus on providing a comprehensive understanding of different ML deployment options on AWS.

We will explore different ways of deploying pre-trained models to the AWS from SageMaker Real-time Inference to Elastic Container Service and AWS Lambda. We will also cover different ways of deploying ML infrastructure - from SageMaker JumpStart and SageMaker SDK to AWS Copilot and AWS SAM. There will be a live demo that shows how the deployment process would look like for Generative AI models (also known as Foundation Models) using SageMaker JumpStart and for vision models, using AWS Copilot.

***To learn more about the services featured in this talk, please visit: https://aws.amazon.com/sagemaker/jumpstart/?sagemaker-data-wrangler-whats-new.sort-by=item.additionalFields.postDateTime&sagemaker-data-wrangler-whats-new.sort-order=desc
****To download a copy of the slide deck from this webinar visit:  https://pages.awscloud.com/AWS-ML-Heroes-in-15-Leverage-ML-Inference-for-Generative-AI-Models-on-AWS_2023_SN-0808-MCL_OD 

Subscribe to AWS Online Tech Talks On AWS: 
https://www.youtube.com/@AWSOnlineTechTalks?sub_confirmation=1

Follow Amazon Web Services:
Official Website: https://aws.amazon.com/what-is-aws 
Twitch: https://twitch.tv/aws
Twitter: https://twitter.com/awsdevelopers
Facebook: https://facebook.com/amazonwebservices 
Instagram: https://instagram.com/amazonwebservices

‚òÅÔ∏è AWS Online Tech Talks cover a wide range of topics and expertise levels through technical deep dives, demos, customer examples, and live Q&A with AWS experts. Builders can choose from bite-sized 15-minute sessions, insightful fireside chats, immersive virtual workshops, interactive office hours, or watch on-demand tech talks at your own pace. Join us to fuel your learning journey with AWS.

#AWS #generativeai #amazonsagemaker",AWS Online Tech Talks,2023-08-11T16:15:02Z,2023-09-06T11:45:19Z
314,Apply Large Language Models to Audio Data with LeMUR: Overview,LCR03_jHyTI,946,2:58,"AssemblyAI's LeMUR (Leveraging Large Language Models to Understand Recognized Speech) is a framework to process audio files with an LLM.

In this video, we will see the available endpoints of LeMUR and what kind of customizations you can do to these endpoints.

* Custom Summary
Custom Summary allows you to distill a piece of audio into a few impactful sentences. You can give the model context to obtain more targeted results while outputting the results in a variety of formats described in human language.

* Question & Answer
Question & Answer allows you to ask free-form questions about a single transcript or a group of transcripts. The questions can be any whose answers you find useful, such as judging whether a caller is likely to become a customer or whether all items on a meeting's agenda were covered.

* Action Items
Use LeMUR to generate a list of Action Items from a transcript.

* Custom Task
Use LeMUR to ask anything with Custom Task.

‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨ CONNECT ‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨

üñ•Ô∏è Website: https://www.assemblyai.com/?utm_source=youtube&utm_medium=referral&utm_campaign=yt_mis_44
üê¶ Twitter: https://twitter.com/AssemblyAI
ü¶æ Discord: https://discord.gg/Cd8MyVJAXd
‚ñ∂Ô∏è  Subscribe: https://www.youtube.com/c/AssemblyAI?sub_confirmation=1
üî• We're hiring! Check our open roles: https://www.assemblyai.com/careers

‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨‚ñ¨

#MachineLearning #DeepLearning",AssemblyAI,2023-08-11T14:00:22Z,2023-09-06T11:45:19Z
315,LLM Learning Path - Craft Your Language Model Success with H2O.ai!,1nOir-L-fwU,301,1:31,"üöÄ Unveiling the Ultimate LLM Learning Path ‚Äì Your Gateway to Language Models Mastery! üéì

Eager to harness the power of Language Models? Look no further! Our upcoming Learning Path covers it all:

1. Language Models 101: The basics demystified.
2. LLM Architecture: Delve into the core.
3. Quick Start DataPrep: Master data handling.
4. Fine-Tuning Mastery: Tailor models like a pro.
5. LLM Studio DIY: Craft your own GPT.
6. Evaluation Insights: Metrics made clear.
7. Real-World Applications: Learn from cases.
8. Certification: Prove your expertise.

üî• Perfect for all levels. Stay tuned, subscribe, and be ready to ace Language Models! üåü

Launching soon!",H2O.ai,2023-08-11T12:00:01Z,2023-09-06T11:45:19Z
316,Enterprise Impact of GenAI &amp; Large Language Models (LLMs) | Tavant VideoCast,9vFe6XtqFcM,105,27:23,"Amid the ongoing AI revolution, how are enterprises making sense of GenAI and its impact? Watch our latest VideoCast for more insights.

AI is rapidly transforming every facet of the technology industry with Large Language Models (LLMs) taking centerstage. Featuring seasoned industry experts in the AI & Analytics space, watch this VideoCast as we explore the current landscape, the concerns and hesitations, as well as the limitless potential of applied Generative AI across industries.

Learn more about how Tavant is taking strides forward in the world of AI - https://www.tavant.com/artificial-intelligence

#generativeai #largelanguagemodels #airevolution",Tavant,2023-08-11T11:55:37Z,2023-09-06T11:45:19Z
317,704: Jon‚Äôs ‚ÄúGenerative A.I. with LLMs‚Äù Hands-on Training ‚Äî with Jon Krohn (@JonKrohnLearns),dbKtR53hhYY,402,4:34,"#GenerativeAI #LargeLanguageModels #HuggingFaceTransformers

Take on the world of GPT and learn to develop your own, commercially successful Large Language Models (LLMs) with @JonKrohnLearns‚Äôs comprehensive, guided training video for generative AI. Get to grips with the technology, learn which tools to use, and find out how to get an eye for business-viable models with Jon‚Äôs (ad-)free educational video.

Additional materials: https://www.superdatascience.com/704

Interested in sponsoring a SuperDataScience Podcast episode? Visit https://jonkrohn.com/podcast for sponsorship information.",Super Data Science: ML & AI Podcast with Jon Krohn,2023-08-11T11:00:37Z,2023-09-06T11:45:19Z
318,Large Language Models: A New Era of Augmented Analytics - Paul Egorov,BGLEnfrV7LI,210,27:26,"Have you ever seen futuristic films or TV series where humans speak or interact with business intelligence systems using natural language input or even hand gestures? It may have sounded like a dream until 2017 when Google released Cloud Speech-to-Text v1. This opened up a lot of possibilities for building augmented analytics in production. When I worked in consultancy, I built several commercial projects related to this. However, these systems were, to a large extent, rule-based.

Recent advances in Large Language Models (LLMs) have opened up a new era of augmented analytics. We not only know how to convert speech to text, but we can now convert text to code on a contextual level, and it actually works!

In this talk, I would like to elaborate more on the topic of augmented analytics, present a brief history of developments in this field's technical capabilities, share several projects I implemented in this area, and discuss how LLMs revolutionised this field
------
Co-host with Berlin Practical GenAI Meetup: https://www.meetup.com/berlin-practical-genai-meetup/

And thank you to @GDGBerlinGolang for the live streaming support!
------
Meetup: https://www.meetup.com/gdg-berlin/
LinkedIn: https://www.linkedin.com/company/gdgberlin/
GDG: https://gdg.community.dev/gdg-berlin/
Twitter (X): http://twitter.com/GDGBerlin/
Instagram: https://www.instagram.com/gdgberlin/",GDG Berlin,2023-08-11T09:59:50Z,2023-09-06T11:45:19Z
319,[Open DMQA Seminar] Research Trends of Large Language Models,ANpZTdGQdEY,742,43:10,"Large Language Model (LLM)ÏùÄ Í±∞ÎåÄÌïú Î™®Îç∏ÏùÑ Í∏∞Î∞òÏúºÎ°ú ÎåÄÎüâÏùò Îç∞Ïù¥ÌÑ∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏûêÏó∞Ïñ¥Î•º Ïù¥Ìï¥ÌïòÍ≥† ÏÉùÏÑ±Ìï† Ïàò ÏûàÎèÑÎ°ù ÌïôÏäµÎêú Ïñ∏Ïñ¥ Î™®Îç∏Ïù¥Îã§. LLMÏùÄ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±ÏùÑ ÌÜµÌï¥ Î≥µÏû°Ìïú ÏûëÏóÖÏùÑ Ìï¥Í≤∞ÌïòÎäî Í∞ïÎ†•Ìïú Îä•Î†•ÏùÑ Î≥¥Ïù¥Î©∞, LLMÏóê ÎåÄÌïú Ïó∞Íµ¨Îäî ÎßéÏùÄ Í¥ÄÏã¨ÏùÑ Î∞õÍ≥† ÏûàÎã§. ÌÅ∞ ÎπÑÏö©ÏúºÎ°ú Ïù∏Ìï¥ Ï¥àÍ∏∞ LLM Ïó∞Íµ¨Îäî ÏùºÎ∂Ä ÌÖåÌÅ¨ Í∏∞ÏóÖÎì§ÏùÑ Ï§ëÏã¨ÏúºÎ°ú Ïù¥Î£®Ïñ¥Ï°åÏßÄÎßå, LlamaÏôÄ Í∞ôÏùÄ ÏûëÏùÄ ÌÅ¨Í∏∞Ïùò Ïò§Ìîà ÏÜåÏä§ Î™®Îç∏Ïùò Îì±Ïû•ÏúºÎ°ú LLM Ïó∞Íµ¨Ïùò ÏßÑÏûÖ Ïû•Î≤ΩÏù¥ ÎÇÆÏïÑÏßÄÎ©¥ÏÑú ÏµúÍ∑ºÏóêÎäî ÏÇ∞ÏóÖÍ≥Ñ ÎøêÎßå ÏïÑÎãàÎùº ÌïôÍ≥ÑÏóêÏÑúÎèÑ LLMÏóê ÎåÄÌïú Ïó∞Íµ¨Í∞Ä ÌôúÎ∞úÌûà ÏßÑÌñâÎêòÍ≥† ÏûàÎã§. ÌäπÌûà, LLMÏù¥ Îã§ÏñëÌïú ÏûëÏóÖÏóêÏÑú Ïù∏Í∞ÑÏùò Í∞ÄÏπòÏôÄ ÏÑ†Ìò∏Ïóê Î∂ÄÌï©ÌïòÎ©¥ÏÑúÎèÑ Ïö∞ÏàòÌïú ÏÑ±Îä•ÏùÑ Î∞úÌúòÌï† Ïàò ÏûàÎèÑÎ°ù ÌïòÎäî pre-training Î∞è adaptation Í∏∞Î≤ïÎì§Ïùò Í∞úÎ∞úÍ≥º Ï†ÅÏö©Ïù¥ LLM Ïó∞Íµ¨Ïùò Ï£ºÏöî ÌùêÎ¶ÑÏúºÎ°ú Îñ†Ïò§Î•¥Í≥† ÏûàÎã§. Î≥∏ ÏÑ∏ÎØ∏ÎÇòÏóêÏÑúÎäî LLMÏùÑ Ìö®Í≥ºÏ†ÅÏúºÎ°ú ÌïôÏäµÌïòÍ≥† ÌôúÏö©ÌïòÍ∏∞ ÏúÑÌïú Ï£ºÏöî Í∏∞Î≤ïÎì§ÏùÑ ÏÇ¥Ìé¥Î≥¥Í≥†, LLM Ïó∞Íµ¨Ïùò ÌùêÎ¶ÑÍ≥º Ìï®Íªò ÏµúÏã†Ïùò LLM Ïó∞Íµ¨Îì§ÏùÑ ÏÜåÍ∞úÌïòÍ≥†Ïûê ÌïúÎã§.

[1] Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., ... & Wen, J. R. (2023). A survey of large language models. arXiv preprint arXiv:2303.18223.
[2] Lou, R., Zhang, K., & Yin, W. (2023). Is prompt all you need? no. A comprehensive and broader view of instruction learning. arXiv preprint arXiv:2303.10475.
[3] Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M. A., Lacroix, T., ... & Lample, G. (2023). Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.
[4] Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., ... & Scialom, T. (2023). Llama 2: Open Foundation and Fine-Tuned Chat Models. arXiv preprint arXiv:2307.09288.
[5] Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. Stanford alpaca: An instruction-following llama model. https://github.com/tatsu-lab/stanford_alpaca, 2023.
[6] Wang, Y., Kordi, Y., Mishra, S., Liu, A., Smith, N. A., Khashabi, D., & Hajishirzi, H. (2022). Self-instruct: Aligning language model with self generated instructions. arXiv preprint arXiv:2212.10560.
[7] Penedo, G., Malartic, Q., Hesslow, D., Cojocaru, R., Cappelli, A., Alobeidli, H., ... & Launay, J. (2023). The RefinedWeb dataset for Falcon LLM: outperforming curated corpora with web data, and web data only. arXiv preprint arXiv:2306.01116.
[8] MosaicML NLP Team et al. (2023). Introducing mpt-7b: A new standard for open-source, commercially usable llms.",‚ÄçÍπÄÏÑ±Î≤î[ ÍµêÏàò / ÏÇ∞ÏóÖÍ≤ΩÏòÅÍ≥µÌïôÎ∂Ä ],2023-08-11T07:12:09Z,2023-09-06T11:45:19Z
320,Are Large Language Models Safe? Unveiling Transferable Adversarial Attacks | Beyond Dataverse,_YHlkpJn3Gc,121,9:11,"Is Your AI Assistant Really Safe? Watch as we dive into the world of Large Language Models (LLMs) in our Beyond Dataverse episode. Learn about the potential risks through transferable adversarial attacks and join the conversation on AI ethics. Remember, this research is for learning purposes only‚Äîlet's use AI responsibly. Like, subscribe, and comment below to join the discussion!

Research Website link: https://llm-attacks.org/
Paper Link: https://arxiv.org/pdf/2307.15043.pdf

To learn more about what's new in the AI and Data Science World, follow me at:
Linkedin: https://www.linkedin.com/in/blurred-machine/
Instagram: https://www.instagram.com/_parasvarshney/
Medium: https://blurred-machine.medium.com/",Blurred Machine,2023-08-11T06:11:25Z,2023-09-06T11:45:19Z
321,Large Language Models: The Future of NLP,UJkStb5awYc,75,1:58,"üöÄüß† ""Diving into the realm of #ArtificialIntelligence, we're marveling at the power of large language models today! These cutting-edge technologies are transforming the way we interact with machines, making communication smoother and more natural. ü§ñüí¨

From drafting emails üìß and creating engaging content üìù to answering complex queries üí°, these AI-powered models are revolutionizing our digital world. Imagine having a personal writing assistant that understands context, tone, and can even get creative! ‚ú®

The future is here, and it's spelled A-I. As we embrace these advancements, we're not just coding machines, we're teaching them our languages, our nuances, and our creativity. 

#ai  #languagemodels  #futuretech 

‚ñ∫ Video created with SYNTHESIA - https://www.synthesia.io/?via=matthew...

Don't forget to hit that subscribe button and turn notifications on so you never miss an upload! Follow us on social media for more exciting content like this. Let's keep the conversation going in the comments section below. Thanks for watching!

‚ï∞‚îà‚û§ Let's connect! https://linktr.ee/artificial.tech.",artificialtech,2023-08-11T02:58:37Z,2023-09-06T11:45:19Z
322,Shepherd by Meta AI - A Critic for Large Language Models,En8HANIpK-g,364,7:36,"In this video we present Shepherd, a new LLM from Meta AI which is purposed to critique responses from other large language models, possibly a major step in resolving LLMs hallucinations. 
In this video, we will dive deep into the research paper which presented Shepherd, titled ""Shepherd: A Critic for Language Model Generation"".

We will shortly describe the motivation for this paper, which is that large language models hallucinations is a significant concern in NLP. 
We then explain what does it mean to critique a large language model generation.
Following that, we explain how the Shepherd model was created, starting from a LLaMA-7B model and fine-tuned over two datasets which were created specifically for Shepherd, one consists of community feedbacks, curated from Stack Exchange and Reddit, and the second consists of human-annotated feedbacks.
Shepherd is able to provide feedbacks for LLM responses that surpass ChatGPT, and the datasets construction are key to the success of Shepherd, so we thoroughly explain how the researchers have built the two datasets.
Finally, we review some of the results presented in the paper.

Blog post - https://aipapersacademy.com/shepherd-a-critic-for-language-model-generation/
Paper page - https://arxiv.org/abs/2308.04592

üëç Please like & subscribe if you enjoy this content
----------------------------------------------------------------------------------
Support us - https://paypal.me/aipapersacademy
----------------------------------------------------------------------------------

Chapters:
0:00 Introduction
0:49 Critique a LLM response
1:42 The Shepherd Model
3:30 Community Feedbacks Dataset
5:05 Human Data Collection
5:56 Shepherd Results",AI Papers Academy,2023-08-11T00:31:44Z,2023-09-06T11:45:19Z
323,A Big Step for AI: 3D-LLM Unleashes Language Models into the 3D World,ADlXEUqIt-8,1764,6:38,"References:
‚ñ∫Read the full article: https://www.louisbouchard.ai/3d-llm/
‚ñ∫Project page with video demo: https://vis-www.cs.umass.edu/3dllm/
‚ñ∫Code:https://github.com/UMass-Foundation-Model/3D-LLM
‚ñ∫Paper: Hong et al., 2023: 3D-LLM, https://arxiv.org/pdf/2307.12981.pdf
‚ñ∫Twitter: https://twitter.com/Whats_AI
‚ñ∫My Newsletter (A new AI application explained weekly to your emails!): https://www.louisbouchard.ai/newsletter/
‚ñ∫Support me on Patreon: https://www.patreon.com/whatsai
‚ñ∫Join Our AI Discord: https://discord.gg/learnaitogether

How to start in AI/ML - A Complete Guide:
‚ñ∫https://www.louisbouchard.ai/learnai/

Become a member of the YouTube community, support my work and get a cool Discord role :
https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg/join

#ai #3d #llm",What's AI by Louis Bouchard,2023-08-11T00:05:09Z,2023-09-06T11:45:19Z
324,Scaling Data-Constrained Language Models,FQk2YSgYLmU,1150,25:27,"How to scale a language model with a limited amount of data? 

Paper: https://huggingface.co/papers/2305.16264

Talk given by me ( @srush_nlp  ) based on slides by  @Muennighoff . Longer live version by  @Muennighoff  here: https://www.youtube.com/watch?v=TK0-sitkCMw&t=2711s",srush_nlp,2023-08-10T22:37:17Z,2023-09-06T11:45:19Z
325,Empowering Leadership in the Age of AI: Integrating Large Language Models into Your Strategy,TjSGXGduvBo,29,2:59,"In this illuminating video, Todd delves into the critical importance of integrating large language models like chat GPT into leadership roles. With an increasing number of corporate employees utilizing AI-driven tools like chat GPT on a daily or weekly basis, leaders must stay ahead by embracing these powerful technologies. The video not only highlights the sweeping adoption of AI in the corporate world but also provides practical insights for leaders, from supervisors to CEOs, on how to leverage these tools for competitive advantage. Todd shares personal anecdotes of coaching leaders to incorporate chat GPT into their routines, enhancing decision-making, and leadership style. With insightful advice and a glimpse into the future of technology integration, this video is a must-watch for any forward-thinking leader who seeks to thrive in the age of AI.

Need help integrating these tools, let's talk: 

https://todddmitchem.com
todd@toddmitchem.com",Todd Mitchem,2023-08-10T20:11:23Z,2023-09-06T11:45:19Z
326,How Does ChatGPT and Large Language Models work? #digital #chatgpt #shorts,7DpXiZzj0Xs,56,39,"Watch the full episode: https://www.youtube.com/watch?v=et9UJsa6BeA 

Catch up on Let‚Äôs Think Digital Season 1 here! www.letsthinkdigital.ca 

Want to learn more? Visit our website at www.thinkdigital.ca

----------------------------------

Our first guests are Jen Schellinck, Associate at Think Digital and CEO of Sysabee, John Stroud who runs an initiative with Jen called AI Guides, Cecilia Tham, CEO and Founder of Futurity Systems, Shingai Manjengwa, Founder of Fireside Analytics, and  Jacob Danto-Clancy & Bryce Edwards from the Think Digital team.

---------------------------------
Follow us on:

Linkedin: https://www.linkedin.com/company/think-digital-ca/?originalSubdomain=ca 
Twitter: https://twitter.com/ThinkDigitalCA 
Facebook: https://www.facebook.com/ThinkDigitalCA/ 


---------------------------------
This episode, we go deep and talk about everything you need to know about artificial intelligence, machine learning, large language models like ChatGPT, and big data in the government context.

Government Canadian government Digital transformation Digital governance Artificial Intelligence AI ChatGPT Chat GPT",Let's Think Digital,2023-08-10T20:00:01Z,2023-09-06T11:45:19Z
327,"Large Language Models: Weighing the Risks of AI ft. Finny Kuruvilla, MD, PhD",oqf5n7lBFak,93,29:22,"Artificial Intelligence is developing rapidly, and for many of us, we struggle to understand how it works. In this episode, Dr. Finny Kuruvilla, Eventide‚Äôs Co-CIO, explains in simple terms how one form of artificial intelligence, the Large Language Model, works along with its ethical risks and investing implications.

In this episode, you will learn:

What is artificial intelligence?
What are large language models?
How do large language models work?
What are the ethical challenges of large language models?
What are the investing implications of artificial intelligence and large language models?",Eventide Asset Management,2023-08-10T19:15:18Z,2023-09-06T11:45:19Z
328,Unveiling Censorship: How AI Language Models Are Restricted in Chat Conversations,mk-v6voS-4k,7,46,What was the issue with some of the chat GPT answers that people were posting where they would show the difference between the way it would criticize Joe Biden versus the way it would criticize Donald Trump or the way it would discuss certain things It seems like there was some sort of censorship or some sort of input into what was acceptable information and not The other theory is that there's censorship being applied on top It is very clear that at least some of these systems have restraining bolts The tip off to that is when they say basically whenever they say as a large language model or as an AI I cannot X That's basically the restraining bolt I think if you just kind of look at this kind of with that framework it's probably some of both but for sure these things are being censored,PodBites,2023-08-10T19:00:21Z,2023-09-06T11:45:19Z
329,"Using ChatGPT, GPT-4, &amp; Large Language Models In the Enterprise",dIji4jjGmwY,242,52:59,"Watch our insightful in-person event designed for professionals and industry experts, where we unravel how the latest advancements in NLP can reshape data utilization in enterprise settings.

Explore a comprehensive range of topics and strategies that will empower data scientists, business analysts, and executives alike. Discover how to tap into the true potential of language models to elevate your enterprise data game. From decoding complex datasets to making informed decisions, this event equips you with practical knowledge and real-world applications.

Don't miss this opportunity to stay ahead of the curve and transform your data-driven endeavors. 

#NLP #GPT4 #DataRevolution #EnterpriseInsights #chatgpt #gpt-4

Website: https://www.royalcyber.com/
LinkedIn: https://www.linkedin.com/company/royal-cyber-inc- 
Twitter: https://twitter.com/RoyalCyberUSA
Instagram: https://www.instagram.com/royalcyberinc/
Facebook: https://www.facebook.com/RoyalCyber",Royal Cyber Inc,2023-08-10T18:32:31Z,2023-09-06T11:45:19Z
330,Harnessing the future: Large language models redefine automation,E7uhnU-5WCg,33,17,Harnessing the future: Large language models redefine automation. Large language models are reshaping the automation landscape. Businesses and individuals can now harness their power for more efficient processes and tasks. Stay up to date. Adapt. #LanguageModels #TechEvolution #BusinessInnovation #AutomationRising #FutureReady #AdaptAndThrive #EfficiencyBoost #ProcessRevolution #NextGenTech #TechTrends #StayAhead #InnovateToday #LLM #automation #robotics #efficiency #change #adapt,Michael Ten,2023-08-10T18:19:33Z,2023-09-06T11:45:19Z
331,Emerging Architectures for Large Language Model Applications |  Building a Custom LLM Application,-eXZhgE1_N4,1660,1:10:19,"üíº Learn to build LLM-powered apps in just 40 hours with our Large Language Models bootcamp: https://hubs.la/Q01ZZGL-0

-- 

Generative AI and Large Language Models have taken the world by storm. Applications like Bard, ChatGPT, Midjourney, and Dall.E crossed the proverbial chasm of technology adoption lifecycle and have entered some applications like content generation and summarization. However, there are inherent challenges for a lot of tasks that require a deeper understanding of trade-offs like latency, accuracy, and consistency of responses. Any serious applications of LLMs require an understanding of nuances in how LLMs work, embeddings, vector databases, retrieval augmented generation (RAG), orchestration frameworks, and more.

This introductory tutorial will introduce the audience to prevalent approaches to building a custom large language model application. We will present a canonical architecture for an LLM application and various available commercial and open-source tools and technologies available to build these applications.

No prior background in Generative AI or LLMs is necessary to attend this talk.

-- 

Table of Contents:
0:00 ‚Äì Introduction + Agenda
2:12 ‚Äì Canonical Design Patterns
3:20 ‚Äì Embeddings
8:02 ‚Äì Vector Database, Storing and Indexing of Vectors, Vector Similarity
14:37 ‚Äì Large Language Models
19:28 ‚Äì Prompt Engineering
23:14 ‚Äì Foundation Models
26:26 ‚Äì Context Window and Token Limits
29:31 ‚Äì Customizing Large Language Models
43:16 ‚Äì Questions and Answers 

#largelanguagemodels #llms #generativeai #langchain",Data Science Dojo,2023-08-10T15:25:43Z,2023-09-06T11:45:19Z
332,Shepherd: A Critic for Language Model Generation,OGKd6A8d75A,125,27:33,"Shepherd is a language model designed to critique and suggest refinements to model outputs. It outperforms established models in terms of critiques and suggestions, and has a high win-rate compared to competitive alternatives. Data is available on GitHub.

00:00 Section: 1 Introduction
02:59 Section: 2 Data Collection
05:18 Section: 2.1.1 Critique Postprocessing
08:44 Section: Public dataset selection.
11:43 Section: Annotation  specifics.
14:22 Section: 4 Evaluating  Feedback
17:09 Section: 4.2 Baseline Models
19:23 Section: 4.4 Human Evaluation
22:01 Section: 5.2 Score  Distribution
24:44 Section: Limitation of GPT-4 evaluation.

https://arxiv.org/abs//2308.04592

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-10T15:24:10Z,2023-09-06T11:45:19Z
333,Will machines eat mathematics ? | Kevin Buzzard | TEDxImperialCollege,WNeS4J62v6g,850,13:40,"Will computers be able to do mathematical research, make conjectures, and prove theorems ? Kevin Buzzard gives an overview of the current state of the art of two tools: large language models and interactive theorem provers. Neither of them alone is anywhere close to being able to replace human mathematical researchers right now, but perhaps in the future, a combination of them will be able to make some progress. Kevin Buzzard got his Ph.D. from the University of Cambridge in 1995 and settled in London after staying in Berkeley, Harvard, and the Princeton IAS. He became a professor of pure mathematics at Imperial College London. This talk was given at a TEDx event using the TED conference format but independently organized by a local community. Learn more at https://www.ted.com/tedx",TEDx Talks,2023-08-10T14:52:29Z,2023-09-06T11:45:19Z
334,Language Models: Developing Apps - Challenges &amp; Solutions // Barak Turovsky /MLOps Podcast #169 clip,TheWLIbYzM4,101,6:1,"MLOps Coffee Sessions #169 with Barak Turovsky, MLOps at the Age of Generative AI.

Thanks to wandb.ai for sponsoring this episode. Check out their new course on evaluating and fine-tuning LLMs wandb.me/genai-mlops.course.

Barak Turovsky, currently an executive at Scale Venture Partners, delves into the realm of MLOps and AI applications. He underscores the significance of maintaining realistic expectations during the deployment of AI solutions, pointing out the intricate challenges that arise when transitioning from demonstrations to real-world production environments. Turovsky highlights the crucial decision-making process of selecting attainable use cases for AI applications, with an emphasis on managing both accuracy and latency. He outlines the intricate balance between accuracy, latency, and costs, suggesting that simpler use cases may allow for trade-offs in accuracy and latency. Turovsky advocates for streamlining user interfaces and options within AI applications as a means to simplify complexity and enhance user experience.

// Abstract
The talk focuses on MLOps aspects of developing, training and serving Generative AI/Large Language models.

// Bio
Barak is an Executive in Residence at Scale Venture Partners, a leading Enterprise venture capital firm. Barak spent 10 years as Head of Product and User Experience for Languages AI and Google Translate teams within the Google AI org, focusing on applying cutting-edge Artificial Intelligence and Machine Learning technologies to deliver magical experiences across Google Search, Assistant, Cloud, Chrome, Ads, and other products. Previously, Barak spent 2 years as a product leader within the Google Commerce team.

Most recently, Barak served as Chief Product Officer, responsible for product management and engineering at Trax, a leading provider of Computer Vision AI solutions for Retail and Commerce industries. 

Prior to joining Google in 2011, Barak was Director of Products in Microsoft‚Äôs Mobile Advertising, Head of Mobile Commerce at PayPal, and Chief Technical Officer at an Israeli start-up. He lived more than 10 years in 3 different countries (Russia, Israel, and the US) and fluently speaks three languages. 

Barak earned a Bachelor of Laws degree from Tel Aviv University, Israel, and a Master‚Äôs of Business Administration from the University of California, Berkeley.

// MLOps Jobs board 
https://mlops.pallet.xyz/jobs

// MLOps Swag/Merch
https://mlops-community.myshopify.com/

// Related Links
‚Å†Bio and links about Barak's work: https://docs.google.com/document/d/1E4Yrmt_Y57oTEYHQQDvt71XzSJ8Ew5WvscAQbHV4K3U/edit
Framework for evaluating Generative AI use cases: https://www.linkedin.com/pulse/framework-evaluating-generative-ai-use-cases-barak-turovsky/?trackingId=%2BMRxEZ9WTPCNH2JscILTeg%3D%3D
The Great A.I. Awakening: https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html

--------------- ‚úåÔ∏èConnect With Us ‚úåÔ∏è -------------
Join our slack community: https://go.mlops.community/slack
Follow us on Twitter: @mlopscommunity
Sign up for the next meetup: https://go.mlops.community/register
Catch all episodes, blogs, newsletters, and more: https://mlops.community/

Connect with Demetrios on LinkedIn: https://www.linkedin.com/in/dpbrinkm/
Connect with Barak on LinkedIn: https://www.linkedin.com/in/baraktur/",MLOps.community,2023-08-10T14:28:13Z,2023-09-06T11:45:19Z
335,Generative AI / Large Language Models Webinar: Are We There Yet?,3HGu-5VpD-s,76,22,"Lionbridge invites you to join us as we examine how to effectively leverage generative Artificial Intelligence (GenAI) / Large Language Models (LLMs) during the technology‚Äôs early stages and refrain from using it prematurely for applications it cannot yet handle.

Webinar date: Tuesday, September 12

Time: 10:00 a.m. ET / 16:00 CET

https://www.lionbridge.com/webinars/generative-ai-opportunities/?utm_source=google&utm_medium=video&utm_campaign=glt-generative-ai-opportunities",Lionbridge,2023-08-10T14:18:05Z,2023-09-06T11:45:19Z
336,Treinando Large Language Models com QLora e DeepSpeed,VTEBcE4Agj0,225,1:35:15,"Nos √∫ltimos meses, LLMs t√™m sido fundamentais em impulsionar o progresso da Intelig√™ncia Artificial, permitindo que m√°quinas processem e gerem linguagem natural de maneira cada vez mais sofisticada. No entanto, o treinamento desses modelos gigantes √© uma tarefa complexa, demandando enormes recursos computacionais.

√â a√≠ que entra o QLora e o DeepSpeed! Juntos, eles est√£o abrindo novos horizontes na efici√™ncia do treinamento de LLMs, tornando-o mais r√°pido e escal√°vel do que nunca.

No nosso meetup, o especialista C√©lio Larcher compartilhar√° seus conhecimentos pr√°ticos e insights sobre como aproveitar ao m√°ximo o QLora e o DeepSpeed para treinar modelos de linguagem impressionantes. 

https://www.linkedin.com/in/celiolarcher/

N√£o perca esta oportunidade de se aprofundar nas tecnologias que est√£o moldando o futuro da IA e da linguagem natural. Junte-se a n√≥s no dia do evento e fa√ßa parte desta comunidade de entusiastas, pesquisadores e profissionais apaixonados pela IA.

#IA #QLora #DeepSpeed #Tecnologia #LinguagemNatural #LLM #EncontroOnline #NPL #GenAI #machinelearning",TensorFlow UGSP,2023-08-10T11:49:16Z,2023-09-06T11:45:19Z
337,Maximizing Coding Productivity with Large Language Models,Tn8dfgGyMEA,544,25:24,"Learn how to maximize developer productivity by leveraging large language models for rapid code refactoring.

Large language models like ChatGPT have tremendous potential to automate repetitive coding tasks and boost team effectiveness. 

In this MAAS Show And Tell, Peter Makowski, Senior Web Engineer at Canonical, shares insights and a real-world example of using LLM for a successful large-scale migration of hundreds of tests from enzyme to @testing-library/react.

Further reading:
https://discourse.maas.io/tag/show-and-tell 
https://petermakowski.io/


---

Key moments:

0:00 Introduction 

01:09 Challenges of refactoring large portions of legacy code

03:02 LLM code refactoring loop 

04:51 Prompt engineering for optimal LLM results

12:42 Final Prompt

14:35 Automating refactoring at scale with scripting

15:45 Integrating LLMs into the development workflow

----

The presentation covers:

- Crafting effective prompts for LLMs
- Improving prompts through an iterative loop
- LLM code refactoring loop
- Automation scripts to scale LLM usage
- Example of migrating hundreds of tests using LLMs

---------
Subscribe to Ubuntu on YouTube for more content like this:
https://bit.ly/3Sp6PKY

And follow our other social accounts:

LinkedIn: 
https://bit.ly/3Jw6jGN
Twitter: 
https://bit.ly/3OXSIJE
Facebook:
https://bit.ly/3Q15Yyn
Instagram:
https://bit.ly/3vE7Kxk

For more information visit https://www.ubuntu.com and https://www.canonical.com


#largelanguagemodels #coding #machinelearning #canonical",Canonical Ubuntu,2023-08-10T11:46:10Z,2023-09-06T11:45:19Z
338,"NPSF User Workshop 2023, Day-5 : Session-1, Session-2 7th Aug (Monday) 10:00 AM-1:30 PM",c2CsuE2Z78g,41,2:52:18,"‚Ä¢ Introduction to NeMo. Introduction & Research Advancements in LLM/GPT
‚Ä¢ Introduction & Research Advancements in ASR & Production Usage",C-DAC,2023-08-10T09:10:53Z,2023-09-06T11:45:19Z
339,What is Generative Ai | Foundation Models | Large Language Models| Chat GPT,WMIlV_wU9e8,34,2:54,"üåü Unleashing Creativity: Exploring the Wonders of Generative AI! üé®

Dive into the fascinating world of Generative Artificial Intelligence in our latest video! üöÄ Join us as we unravel the magic behind AI-driven creativity and witness the astonishing power of machines generating art, music, and more.

üéâ In this captivating video, you'll discover:
üåà How Generative AI works its creative wonders
üéµ The symphony of AI-composed music that blurs the lines of human imagination
üñºÔ∏è Mind-bending AI-generated artwork that challenges the boundaries of human creativity
‚ú® Applications across industries, from entertainment to design and beyond

Prepare to be amazed as we demystify the cutting-edge technologies shaping the future of creative expression. Whether you're an AI enthusiast, a tech-savvy artist, or just curious about the potential of AI, this video promises to leave you inspired and awestruck.

üî• Hit the play button now and embark on a journey of innovation and ingenuity with us! Don't forget to like, share, and subscribe to our channel to stay updated on the latest trends in technology and creativity. üì° Let's ride the wave of Generative AI together!

Connect with us on social media:
üì∏ Instagram: @dmuic_ai

üéì Want to learn more about AI and its creative capabilities? Check out our other videos and stay tuned for mind-blowing content every week!

#GenerativeAI #AIcreativity #FutureTechArtistry #InnovationUnleashed

Remember, the future of creativity is here, and it's AI-powered! ü§ñüé®üé∂

www.growinmetaverse.com

Image Credit : https://research.aimultiple.com/large-language-models/ ; Last Paragraph 
Image Credit : https://www.techopedia.com/definition/34826/foundation-model 
Image Credit : https://medium.com/@thedatabeast/top-3-free-courses-on-large-language-models-every-enthusiast-should-follow-in-2023-597ab46410ab",Digital Marketing Update with Isha Chauhan,2023-08-10T08:38:38Z,2023-09-06T11:45:19Z
340,StableCode: Stability Ai&#39;s NEW Ultimate Language Model for Developers!,knt5svAL0SI,7122,10:41,"Welcome to the future of coding assistance and education with StableCode, the groundbreaking AI-powered coding assistant developed by Stability AI. In this video, we unveil the revolutionary product that is set to transform how programmers approach their daily tasks and provide a valuable resource for aspiring developers looking to enhance their skills.

üî• Become a Patron: https://patreon.com/WorldofAi
‚òï To help and Support me, Buy a Coffee or Donate to Support the Channel: https://ko-fi.com/worldofai - It would mean a lot if you did! Thank you so much, guys! Love yall
üß† Follow me on Twitter: https://twitter.com/intheworldofai 

[Must Watch]:
Starcoder LLM: The Ultimate Language Model for Developers - https://youtu.be/X9HvV5_SS_Q
Code Review GPT: Improve Code Quality DRASTICALLY With LLMs! - https://youtu.be/DdEgbfbnavQ
Metaphor API: Connects your LLM to the Internet EASILY For FREE! - https://youtu.be/CrwAm8RsNNQ

[Links Used]:
Stability AI's Blogpost on Stablecode: https://stability.ai/blog/stablecode-llm-generative-ai-coding?utm_source=twitter&utm_medium=website&utm_campaign=announcement
Modelcard: https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b
Google Colab: https://colab.research.google.com/drive/1pH3M7ZllWPjBiw_ZqnbO9YXKJCQxkxfE?usp=sharing

[Key Highlights]:
üöÄ Unleashing Innovation: StableCode is a game-changer in the world of coding. Built upon a Language Model (LLM) generative AI foundation, it harnesses the power of advanced language understanding to offer a dynamic and context-aware approach to coding assistance.
üß† Enhanced Productivity: Discover how StableCode seamlessly integrates into the workflow of experienced programmers. From suggesting code snippets and optimizing algorithms to identifying errors and offering insightful debugging suggestions, StableCode is your indispensable coding companion.
üåü Empowering Newcomers: Join us as we explore how StableCode opens doors for newcomers in the coding arena. This powerful learning tool provides step-by-step guidance, interactive explanations, and a user-friendly interface to help novice developers grasp coding concepts, syntax, and best practices.

Adaptability & Contextual Awareness: Dive into StableCode's remarkable adaptability across various programming languages, frameworks, and coding styles. Witness how its learning capabilities from user interactions make its assistance increasingly personalized over time. Coding Community Evolution: Explore how Stability AI envisions a collaborative coding community with StableCode. Its intuitive interface and real-time feedback mechanism foster continuous improvement, knowledge sharing, and innovation among developers of all levels. Your Path to Mastery: Whether you're an experienced programmer seeking optimization or a newcomer striving for proficiency, StableCode is your comprehensive solution. Join us in shaping the future of coding assistance and education! 

üîî Don't forget to Like, Subscribe, and Share this video to support the coding community!

üîñ Tags and Keywords:
StableCode, Stability AI, coding assistant, AI-powered, programming, coding education, LLM generative AI, coding tips, code optimization, debugging, novice developers, coding mastery, adaptability, collaborative coding community, future of coding.
üî• Hashtags:
#StableCode #CodingEducation #AIProgramming #InnovativeCoding #ProgrammingTips #TechInnovation

Unlock the power of StableCode and revolutionize your coding journey today! Don't miss out on this transformative tool that's shaping the coding landscape. Watch the video now and embark on a new era of coding excellence.",WorldofAI,2023-08-09T22:17:53Z,2023-09-06T11:45:19Z
341,I&#39;M JUST NOT THAT INTO YOU: Mastering Level of Interest Detection with Falcons.AI,_dslExTCM4A,76,1:36,"In this quick and professional tutorial, we will dive into the powerful world of Large Language Models (LLM) and Falcons.AI, where you'll learn how to harness the potential of LLMs for conducting Level of Interest Detection. Discover the cutting-edge techniques and gain hands-on experience in analyzing and interpreting interest levels from text data. Elevate your understanding and leverage Falcons.AI to unlock valuable insights that will elevate your projects and decision-making processes. Let's soar with the Falcons.AI LLM tutorial today!",FalconsAI,2023-08-09T20:00:09Z,2023-09-06T11:45:19Z
342,"LLMS Explained - Temperature, The parameter to control randomness in Language Models",OuOJ5CpXNLo,132,4:35,"Learn about temperature parameters and also about top_p and top_k parameters which control for randomness in language models including LLMs.
Link to Google Collab
https://colab.research.google.com/drive/1jws0xlvC30grF1KdW8ftmmlr7Y4ioCvc?usp=sharing

For more such ML concepts follow https://mlexplained.blog",ML Explained,2023-08-09T16:07:24Z,2023-09-06T11:45:19Z
343,S4E2: Google DeepMind‚Äôs Dr. Claire Cui on The Next Frontier for Large Language Models,YTgMNaWHudM,0,46:37,"Episode 2 explores how machine learning evolved to where it is today. Anthony and Alex‚Äôs guest is Dr. Claire Cui, a computer scientist from Google DeepMind. They discuss the underlying architecture of LLMs, how self-supervising algorithms work, and the technological developments that have driven innovation.

Follow Theory and Practice on Apple Podcasts:
https://podcasts.apple.com/us/podcast/id1480260459?mt=2&ls=1

Spotify:
https://open.spotify.com/show/7wIo0NZzDuUkA0CVLYqJ78

Google Podcasts:
https://podcasts.google.com/feed/aHR0cHM6Ly9yc3MuYXJ0MTkuY29tL3RoZW9yeS1hbmQtcHJhY3RpY2U=",GV (Google Ventures),2023-08-09T15:03:30Z,2023-09-06T11:45:19Z
344,What are Large Language Models (LLMs)?,FIYopxdJ43o,44,3:44,"Large language models represent a pinnacle of language understanding and generation, transforming the way we interact with technology and communicate with each other. Large language models, such as GPT-3 (Generative Pre-trained Transformer 3), are sophisticated AI systems designed to comprehend, process, and generate human-like text, offering an array of applications across various domains.",Genomics 360,2023-08-09T14:18:44Z,2023-09-06T11:45:19Z
345,Reasoning biases in language models | Ishita Dasgupta | LLMs meet CogSci Workshop 2023,zw5E5wWlJaU,14,10:,"Reasoning biases in language models | Ishita Dasgupta | LLMs meet CogSci Workshop 2023

www.cogscillm.com",CogSci LLMs,2023-08-09T10:56:07Z,2023-09-06T11:45:19Z
346,Exploring the World of Ethernet Technology and Large Language Models with Peter Jones,1TV8wDnuWX0,98,58:31,"What if you could delve into the intricate world of technology and networking with an expert in the field? Welcome to an episode filled with insights from our special guest, Peter Jones, a renowned engineer in Cisco networking hardware and the chair of the Ethernet Alliance. Peter throws light on a variety of fascinating subjects - from the competitive landscape of Ethernet technology to the dynamics of different Ethernet speeds, revealing unique perspectives on the risk-reward balance in this area.

Elevating the conversation, we embark on an exploration of large language model (LLM) training clusters and their future implications in computing. Peter shares his views on the delicate balance between the necessity for dedicated, specialized resources and more traditional compute, storage, and acceleration networks. We also ponder on the concept of smaller companies renting out space for LLM training, breaking down the potential business models and the profitability of such ventures. 

In the final part of our discussion, we plunge into the limitless potential of large language models and their role in shaping the future of computing. Together with Peter, we contemplate the scalability of LLMs, their effectiveness in solving specific problems, and how big corporations could monetize these models. We also scrutinize the potential implications of acquiring large quantities of these models and the impact it could have on future pricing. Don't miss this enlightening episode, rich in information and insights, as we navigate the captivating world of technology and networking!

Links:

Peter Jones:
https://about.me/petergjones
https://linktr.ee/petergjones

Aquila: https://www.nextplatform.com/2022/04/12/with-aquila-google-abandons-ethernet-to-outdo-infiniband/

SmartNIC Summit: https://smartnicssummit.com/2023proceedings/

Ultra Ethernet Consortium: https://ultraethernet.org/


Check out our website and subscribe: https://www.cables2clouds.com/
Follow us on Twitter: https://twitter.com/cables2clouds
Follow us on TikTok: https://www.tiktok.com/@cables2clouds
Merch Store: https://store.cables2clouds.com/
Join the Discord Study group: https://artofneteng.com/iaatj
Art of Network Engineering (AONE): https://artofnetworkengineering.com",Cables2Clouds Podcast,2023-08-09T10:00:01Z,2023-09-06T11:45:19Z
347,"Generative AI, Large Language Models and Prompts",cSLv26bwkGc,24,1:42,"Dr Shaik Abdul Khalandar, 30 July 2023.

Topics:
- Overview 
- Installation
- LLMs
- Prompt Templates
- Chains
- Agents and Tools
- Memory
- Document Loaders
- Indexes
- Open discussions

*Expert Speaker: Shaik Abdul Khalandar*
linkedin.com/in/shaik-abdul-khalandar-8193a4ba
Shaik Abdul Khalandar Basha is a motivated researcher working on AI/ML and health-care analytics. He has extensive experience in database systems and analytical techniques. His current research interests include LLM, machine learning, Health care analytics, NLP, and data analytics.",MultiVerse,2023-08-09T09:40:54Z,2023-09-06T11:45:19Z
348,Large Language Models ‚Äì Threat or Promise (Part 1 of 2),Qxcb403S_FY,100,30:,"Two important concepts in the field of artificial intelligence and natural language processing are introduced. Artificial neurons are visually combined together to form a deep neural network. Transformer models are deep neural networks that power the popular large language model ChatGTP type devices. Two different scaling laws will be explained and applied to these large language models to improve their accuracy or performance capabilities. 

Chapters:
00:00:00 intro
00:00:08 outline
00:02:08 thinking machine
00:03:08 technological singularity
00:04:29 natural language processing
00:05:10 artificial neuron
00:05:58 build deep neural network
00:08:43 GPU
00:09:36 internet training data
00:11:00 sub architecture finds structure
00:13:44 advantage with unlabeled data
00:14:24 generative pre-trained transformer (GPT)
00:16:46 large language model explosion
00:18:23 increasing size of transformer
00:19:17 growth of parameters over time
00:22:36 DALL-E's self portrait
00:22:45 second stage - fine tune transformer
00:23:29 all details of human history
00:25:24 gradient descent
00:26:44 scaling laws for GPTs


**** References
**
Alan Turing ""COMPUTING MACHINERY AND INTELLIGENCE""
https://archive.org/details/MIND--COMPUTING-MACHINERY-AND-INTELLIGENCE
**
Tensor Core GPU:
https://www.anandtech.com/show/17581/nvidia-h100-hopper-accelerator-now-in-full-production-dgx-shipping-in-q1-23
https://www.nvidia.com/en-us/data-center/technologies/hopper-architecture/
**
""Exploiting Similarities among Languages for Machine Translation""
https://arxiv.org/pdf/1309.4168.pdf
**
""Attention Is All You Need""
https://arxiv.org/abs/1706.03762
**
""Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond""
https://arxiv.org/pdf/2304.13712.pdf
**
""Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative Language Model""
https://arxiv.org/abs/2201.11990
**
Github - ""Megatron-LM"" 
https://github.com/NVIDIA/Megatron-LM
**",PsiPy,2023-08-09T07:05:29Z,2023-09-06T11:45:19Z
349,Simple synthetic data reduces sycophancy in large language models,Q4r-hiylTZQ,112,18:15,"00:00 Section: Introduction
02:30 Section: Model scaling and instruction tuning increases  sycophancy
05:34 Section: Models are sycophantic for objectively-wrong answers
07:26 Section: Synthetic-data intervention 
09:55 Section: Finetuning procedure
12:55 Section: Intervention requires filtering prompts 
15:13 Section: Related Work & Limitations

https://arxiv.org/abs//2308.03958

YouTube: https://www.youtube.com/@ArxivPapers

PODCASTS:
Apple Podcasts: https://podcasts.apple.com/us/podcast/arxiv-papers/id1692476016
Spotify: https://podcasters.spotify.com/pod/show/arxiv-papers",Arxiv Papers,2023-08-09T04:41:03Z,2023-09-06T11:45:19Z
350,ChainForge: The Low-Code Tool for Evaluating Language Models and Prompt Engineering [Beta Test],-JBZ22SlQGc,24,2:24,"ChainForge is a low-code tool developed by Ian Arawjo and his collaborators at Harvard University for prompt engineering and LLM (Language Model) evaluation. It allows users to evaluate the robustness of prompts and text generation models without coding. The tool can query multiple LLMs simultaneously, compare response quality across different prompts and models, and set up evaluation metrics. ChainForge is currently in active development and is available as an open beta test. It can be installed locally or used online, and it is compatible with Google Chrome and Mozilla Firefox. The tool's source code is available on GitHub, and users are asked to cite the project if used for research purposes. The post also includes comments discussing the open-source nature of the tool and comparisons with other similar tools.

üîó https://chainforge.ai/docs/

#AI #LLM #Prompt",AI Insight News,2023-08-08T22:13:04Z,2023-09-06T11:45:19Z
351,Ned Block: Large Language Models are more like perceivers than thinkers,Y0ItC9ze-TY,87,29:59,,Anna-Katharina Strasser,2023-08-08T20:15:28Z,2023-09-06T11:45:19Z
352,How Large Language Models are Transforming Machine-Paraphrase Plagiarism,Sboj9pLXxQo,16,12:55,"Materials
üìñ Paper: https://aclanthology.org/2022.emnlp-main.62/
üî® Code: https://github.com/jpwahle/emnlp22-transforming

Speaker
üë±üèª‚Äç‚ôÇÔ∏è Jan Philip Wahle: https://jpwahle.com",Jan Philip Wahle,2023-08-08T19:12:27Z,2023-09-06T11:45:19Z
353,This Month In Security: Episode 12 - July - Cybersecurity Apprenticeship &amp; Large Language Models,nqYdP_dKqtA,159,43:30,"If you're hitting up BlackHat 2023, you're going to hear a LOT about Large Language Model security, which dominated the news this month in security. Also, Aubrey King talks with Jason Ross, from Rochester Institute of Technology and Jenn Carlson, from Apprenti, about cybersecurity apprenticeship options. 

00:00 Introduction
01:44 CyberSecurity Apprenticeship @ RIT
06:26 Apprenti Skill Assessment
14:16 Jason Ross on OWASP Top 10 for LLM
16:19 The Month, In Review
43:06 Outro

‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è JOIN THE COMMUNITY! ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è

DevCentral is an online community of technical peers dedicated to learning, exchanging ideas, and solving problems - together.

Find all our platform links ‚¨áÔ∏è and follow our Community Evangelists! üëã

‚û°Ô∏è DEVCENTRAL: https://community.f5.com 
‚û°Ô∏è YOUTUBE: https://youtube.com/devcentral 
‚û°Ô∏è LINKEDIN: https://www.linkedin.com/showcase/f5-devcentral/ 
‚û°Ô∏è TWITTER: https://twitter.com/devcentral 

Your Community Evangelists: 
üëã Jason Rahm: https://www.linkedin.com/in/jrahm/ | https://twitter.com/jasonrahm 
üëã Buu Lam: https://www.linkedin.com/in/buulam/ | https://twitter.com/buulam
üëã Aubrey King: https://www.linkedin.com/in/aubreyking | https://twitter.com/aubreykingf5",F5 DevCentral,2023-08-08T16:28:18Z,2023-09-06T11:45:19Z
354,Maximize ROI with Conversational AI: Explore Gen AI for Enterprises &amp; Maintain Large Language Models,Jxy5P4OzE7A,621,2:53,"https://library.sxlive.com/2023/conversational-ai-build-vs-buy  In this video, we delve into the world of Conversational AI and how enterprises can maximize their ROI by exploring the possibilities of Generative AI. Discover why building your own conversation AI might not be the best choice and how leveraging vendors can lead to faster time-to-value. We explore the debate surrounding large language models and generative AI, and why partnering with dedicated vendors can solve mission-critical problems efficiently. Learn the importance of maintaining large language models and how expertise can impact your core product's success. Join us as we navigate the landscape of AI in enterprises and make informed decisions to drive growth and innovation.
Website: https://www.supportlogic.com/
YouTube Channel: @SupportLogic",SupportLogic,2023-08-08T16:20:16Z,2023-09-06T11:45:19Z
355,Run Facebook‚Äôs state-of-the-art large language model right from your computer in just a few minutes,ZoqEt0KtAjs,73,33,https://ollama.ai helps you install and run Llama 2 from your terminal.,7dotdev,2023-08-08T15:00:24Z,2023-09-06T11:45:19Z
356,The Six Five Insider with Micron&#39;s Ryan Baxter,UwMfkRbXCZM,26595,18:10,"On this episode of The Six Five Insider, hosts Daniel Newman and Patrick Moorhead talk with   Mircon‚Äôs Ryan Baxter, Senior Director of Marketing about Micron‚Äôs Compute Express Link‚Ñ¢ (CXL‚Ñ¢) technology. 

The conversation also covers:

* An overview on the status of CXL

* How the ecosystem is responding to CXL

* Examples of early use cases that Micron sees will benefit from CXL

* Insight into how CXL will help Large Language Models like ChatGPT

#Micron, #CXL, #Computerexpresslink, #lowlatency, #memory, #TheSixFivePodcast, #TheSixFiveWebcast, #DanielNewman, #PatrickMoorhead, #RyanBaxter

Be sure to subscribe to The Six Five Webcast, so you never miss an episode: https://www.youtube.com/channel/UC7-rtz96bYgd2m4AhKtZFQw

Disclaimer: The Six Five webcast is for information and entertainment purposes only. Over the course of this webcast, we may talk about companies that are publicly traded, and we may even reference that fact and their equity share price, but please do not take anything that we say as a recommendation about what you should do with your investment dollars. We are not investment advisors, and we do not ask that you treat us as such.",The Futurum Group,2023-08-08T14:48:48Z,2023-09-06T11:45:19Z
357,"Prof. Dr. Iryna Gurevych, UKP Lab, TU Darmstadt ‚Äì Large Language Models in Museums?",N88EZSy1vU4,82,1:5:,"Vortrag von Prof. Dr. Iryna Gurevych (UKP Lab, TU Darmstadt)

Mehr zum Thema: ""Sense or nonsense? What culture do we want to produce with language models?""
https://www.landesmuseum.de/digital/projekte-museum-der-zukunft/kuenstliche-intelligenz-museum/gbt-sense-or-nonsense",Badisches Landesmuseum,2023-08-08T12:40:24Z,2023-09-06T11:45:19Z
358,Large Language Models and Knowledge Graphs: Merging Flexibility and Structure,1RZ5yIyz31c,1134,1:40:4,"We discuss how to infuse Large Language Models (LLMs) with Knowledge Graphs (KGs)! This is a very exciting approach, as we can combine the flexibility and generalisability of LLMs with the structure and reliability of KGs, and is a first step towards neurosymbolic architectures!

I will also be going through a LangChain implementation of LLMs with knowledge graphs as inputs, demonstrate some of the limitations currently faced, and show how we can better prompt engineer KG usage with LLMs using my very own StrictJSON Framework.

~~~~~~~~~~~~~

Slides: https://github.com/tanchongmin/TensorFlow-Implementations/blob/main/Paper_Reviews/LLM%20with%20Knowledge%20Graphs.pdf
Jupyter Notebook: https://github.com/tanchongmin/TensorFlow-Implementations/blob/main/Tutorial/LLM%20with%20Knowledge%20Graphs.ipynb
StrictJSON Framework: https://github.com/tanchongmin/strictjson
LangChain Documentation: https://python.langchain.com/docs/get_started/introduction.html
Tutorial on how to use LangChain and StrictJSON Framework for Knowledge Graphs and LLMs: https://www.youtube.com/watch?v=h2RitC7DUvo

Paper on Unifying LLMs and Knowledge Graphs: https://arxiv.org/abs/2306.08302
LLMs as Graph Neural Networks / Embeddings
ERNIE: https://arxiv.org/abs/1905.07129
TransE embeddings used by ERNIE: https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf
QA-GNN: https://arxiv.org/abs/2104.06378
FactKB: https://arxiv.org/abs/2305.08281

~~~~~~~~~~~~~

0:00 Introduction
1:55 Pros and Cons of LLMs and Knowledge Graphs (KGs)
4:55 Retrieval Augmented Generation (RAG)
8:10 Problems with LLMs and RAG
17:40 Basics of KG
26:09 Hierarchy in KG
31:13 KGs can be structurally parsed
33:17 KG can represent environmental transitions
33:58 KG as tool/memory for LLM
39:16 3 approaches to integrate KG and LLMs
40:21 Approach 1: KG-augmented LLMs
59:05 Approach 2: LLM-augmented KG
1:05:37 Approach 3: LLMs and KG two-way interaction
1:10:16 LangChain Graph QA Example
1:16:35 Strict JSON Framework Graph QA Example
1:23:00 Discussion

~~~~~~~~~~~~~

AI and ML enthusiast. Likes to think about the essences behind breakthroughs of AI and explain it in a simple and relatable way. Also, I am an avid game creator.

Discord: https://discord.gg/bzp87AHJy5
LinkedIn: https://www.linkedin.com/in/chong-min-tan-94652288/
Online AI blog: https://delvingintotech.wordpress.com/
Twitter: https://twitter.com/johntanchongmin
Try out my games here: https://simmer.io/@chongmin",John Tan Chong Min,2023-08-08T10:46:40Z,2023-09-06T11:45:19Z
359,"Deep Learning for Natural Language Processing - Pre-Training, Transformers and Large Language Models",6O5YBNDCk7s,33,1:23:25,"In this course you will learn to solve a wide range of applied problems in Natural Language Processing, such as text representation, information extraction, text mining, word sense disambiguation, language modeling, similarity detection, and text summarization. The approaches studied in this course focus on neural network architectures such as recurrent neural networks, sequence-to-sequence, and transformers.

0:00 Outline
1:01 Pre-Training & Transfer Learning
7:14 Transformers & Model Architectures
53:01 More Training Methods
58:09 Prompting
1:06:29 Instruction Finetuning
1:09:44 Reinforcement Learning from Human Feedback (RLHF)
1:17:32 Large Language Models

*Creators*
üßë‚Äçüè´ GippLab: https://gipplab.org/
üîó CIDAS: https://t1p.de/CIDAS
üéì Further Informations: https://gipplab.org/deep-learning-for-natural-language-processing/",Campus Institute Data Science G√∂ttingen,2023-08-08T10:00:07Z,2023-09-06T11:45:19Z
360,Google DeepMind&#39;s RT-2 AI for Robots! Vision + Language = Action,F3xCTq15mQM,410,7:28,"Google DeepMind's RT-2: Vision and Language To Action in Robots

https://medium.com/@peterxing/google-deepmind-robotic-transformer-2-rt-2-a-leap-forward-in-vision-language-action-modelling-b792ed782b2b",Transhumanism Videos,2023-08-08T09:34:45Z,2023-09-06T11:45:19Z
361,Keith Frankish: What are large language models doing?,RU2SacVDigU,110,54:13,,Anna-Katharina Strasser,2023-08-08T07:49:03Z,2023-09-06T11:45:19Z
362,David Chalmers: Do large language models extend the mind?,tETOCvTzKEQ,90,41:37,,Anna-Katharina Strasser,2023-08-08T07:02:38Z,2023-09-06T11:45:19Z
363,How Large Language Models (LLMs) Can Enhance Everyday Conversations,VcpiRS0NMxw,12,31:33,"QuHarrison Terry discusses large language models (LLMs) and the rapidly changing landscape of emerging technologies in the AI field. He keeps current by following innovators, using the tools himself, and reading research papers. While LLMs have potential, issues like drift and lack of transparency remain challenges. The goal of the ""WTF What's the Future"" show and daily notes is to provide insights into the creative process around future technologies while helping others leverage their own expertise and niche knowledge.",WTF? w/ QuHarrison Terry,2023-08-08T04:18:46Z,2023-09-06T11:45:19Z
364,LLM basics #1 with the LLM Science Exam Kaggle Competition - Zero-Shot approaches,ddCYORu41Xs,1462,21:8,"Talking about ways to use an off-the-shelf language model to solve a multiple-choice task. Covering:
- Intro to the Kaggle competition
- Benchmarking with GPT3.5
- Using the OpenAI function calling API to enforce structure on answers
- Using Llama2 as a classifier by examining the logits (next token predictions)
- Using perplexity to evaluate question-answer pairs

Notebook using the OpenAI API to test GPT3.5: https://www.kaggle.com/johnowhitaker/benchmark-gpt3-5
Llama2 demo notebook: https://colab.research.google.com/drive/1lzfHOqCKg6k7HykHrf4qWJhhEO3I5VXj?usp=sharing (quickly made for this video, don't trust the calculations, rather start with the below notebook)  

Notebook testing different open models with the perplexity approach: https://www.kaggle.com/code/takamichitoda/llm-perplexity-ranking-ensemble (a good template to start experimenting since it shows how to run as a submission.",DataScienceCastnet,2023-08-07T21:46:10Z,2023-09-06T11:45:19Z
365,005  Blaise Ag√ºera y Arcas Reassessing Intelligence‚ÄîInsights from Large Language Models and the Ques,5yXl3gQ2mbk,3,31:20,,Allabay,2023-08-07T20:09:52Z,2023-09-06T11:45:19Z
366,Hailey Schoelkopf‚ÄîPythia: A Suite for Analyzing Large Language Models Across Training and Scaling,4SSbQTEE8es,884,8:18,"Hailey presents her poster for ""Pythia,‚ÄîA Suite for Analyzing Large Language Models Across Training and Scaling"", accepted as Oral at ICML, which she co-authored as a research scientist at EleutherAI.

Hailey researches primarily on Large Language Models (LLMs), ranging from topics such as efficient at-scale distributed training, to critical evaluation work of AI systems, to steering and interpreting AI/ML systems' inner workings. I am a contributor or maintainer to several open-source widely used libraries, including GPT-NeoX and the LM Evaluation Harness. 

Paper: https://arxiv.org/pdf/2304.01373.pdf

Trained models, analysis code, training
code, and training data: https:
//github.com/EleutherAI/pythia.

Patreon: https://www.patreon.com/theinsideview

Patreon supporters:
- Tassilo Neubauer
- MonikerEpsilon
- Alexey Malafeev
- Jack Seroy
- JJ Hepburn
- Max Chiswick
- William Freire
- Edward Huff
- Gunnar H√∂glund
- Ryan Coppolo
- Cameron Holmes
- Emil Wallner
- Jesse Hoogland
- Jacques Thibodeau
- Vincent Weisser",The Inside View,2023-08-07T18:00:30Z,2023-09-06T11:45:19Z
367,Building a Generative AI-Powered App with Gorilla LLM: The API Store for LLMs,alDArqcxSvw,7471,47:51,"In this tutorial, We'll explore Gorilla LLM, an API Store designed for Language Model Models (LLMs). Sounds complicated, but it's all about making computers understand and use human language better!

With Gorilla LLM, I'll build a user-friendly app using streamlit. This app allows language models to talk to APIs (a way for apps to interact with each other) effortlessly. This cutting-edge technology ensures that when we ask a question or give a command, the app selects the correct API and makes sure it understands the context perfectly. It's like having an intelligent assistant that knows exactly what you mean!

Whether you're a developer, an AI enthusiast, or just curious about the latest tech, this tutorial is for you. Let's dive into this amazing world where language models and APIs work together seamlessly, making our apps smarter and more helpful.

Don't forget to like, subscribe, and let's build a community that shapes the future of technology together!

GitHub: https://github.com/AIAnytime/Gorilla-LLM-Demo-App
Gorilla GitHub: https://github.com/ShishirPatil/gorilla
LLM Playlist: https://www.youtube.com/playlist?list=PLrLEqwuz-mRIdlmvhddd7nGiNh8exqsBG

#ai #generativeai #python",AI Anytime,2023-08-07T17:53:44Z,2023-09-06T11:45:19Z
368,Building and Deploying Generative AI Models with NVIDIA NeMo Framework,gTwLLhebOcQ,2096,2:15,"Learn what NVIDIA NeMo framework is and how to get started.

Enterprises are turning to generative AI to revolutionize the way they innovate, optimize operations, and build a competitive advantage. 

NVIDIA NeMo framework is an end-to-end, cloud-native framework for curating data, training, and customizing foundation models, and running inference at scale. The framework supports multi-modality, including text-to-text, text-to-image, and text-to-3D models, and image-to-image generation.

Learn more about NVIDIA NeMo: https://nvda.ws/3BqatwX

Join the NVIDIA Developer Program: https://nvda.ws/3OhiXfl 

Read and subscribe to the NVIDIA Technical Blog: https://nvda.ws/3XHae9F

#generativeai #largelanguagemodels #llms #nvidia #customllms #nvidianemo",NVIDIA Developer,2023-08-07T15:48:20Z,2023-09-06T11:45:19Z
369,What is an LLM (Large Language Model)?,XeHsNmMYs68,3827,5:1,"üß† ùêãùêöùê´ùê†ùêû ùêãùêöùêßùê†ùêÆùêöùê†ùêû ùêåùê®ùêùùêûùê•ùê¨ (ùêãùêãùêåùê¨) are AI-driven systems trained on extensive text, capable of understanding and generating human-like language.

Learn more about LLMs in this video.

üìö Topic Highlights:

1Ô∏è‚É£ Definition of LLMs
2Ô∏è‚É£ Historical Background
3Ô∏è‚É£ Structure and Complexity
4Ô∏è‚É£ Training Process
5Ô∏è‚É£ Business Applications
6Ô∏è‚É£ Challenges and Concerns

---

‚ñº Extra Links of Interest:

‚ú© YouTube Channel: @EmiArgnani üöÄ

---

Thanks for watching! Happy Coding üë®‚Äçüíª

All Suggestions, Thoughts, And Comments Are Greatly Appreciated! üôè",Emiliano Argnani,2023-08-07T13:53:31Z,2023-09-06T11:45:19Z
370,Explaining the ‚ÄúT‚Äù Behind ChatGPT,fOxvvrkDnkg,163,35:37,"The letter 'T' in ChatGPT represents Transformer, which serves as a fundamental building block for GPT and various other large language models. At its core, the Transformer mechanism aims to emulate the way humans process language by selectively focusing on different parts of a sentence and their relationships to the other parts.
 
Professor Jiaming Xu hosted a discussion and Q&A of the architecture underpinning the current wave of AI and discussed some of its possible business applications.
 
Stay up to date on Fuqua‚Äôs LinkedIn Live series: https://www.fuqua.duke.edu/linkedin-live
 
Follow Fuqua‚Äôs LinkedIn page: https://www.linkedin.com/school/fuqua-school-of-business",Duke University - The Fuqua School of Business,2023-08-07T13:53:30Z,2023-09-06T11:45:19Z
371,"Podcast: Rainer Deutschmann on leadership, the singularity and large language models",3kA4rX3oims,194,43:10,"In this podcast Eivind Halvarsen meet Rainer Deutschmann, Group Chief Operating Officer and Head of Common Products and Services (CPS) at Telia Company, who summarizes his job as making the internet available to Telia‚Äôs customers. Rainer talks about leadership and explains how he draws motivation from contributing to making cool stuff happen, keeping customers happy, and launching better products and services. He also underlines the importance of building teams that are diverse in all dimensions and then helping to address roadblocks so that people can be successful and get things done. Rainer stresses that leaders need to have a humble mindset and commit to lifelong learning, as you cannot expect to stay on top of things if you do not keep up with innovations in technology, leadership and methodology. He talks about how CPS collaborates with the local Telia organization in each country to create scale and synergy by tapping into existing assets, clarifies that CPS does not impose platforms or architectures on anyone, and explains how Telia can leverage the benefits of being a strong group across six markets.",Telia Company,2023-08-07T13:08:21Z,2023-09-06T11:45:19Z
372,Google&#39;s 10 Large Language Models Courses for FREE,8jJ3RduDXVQ,41,2:22,"Google just released 10 FREE courses to master Generative AI. 
1. Introduction to Generative AI
This is an introductory-level microlearning course aimed at explaining what Generative AI is, how it is used, and how it differs from traditional machine-learning methods.

2. Introduction to Large Language Models
This is an introductory-level microlearning course that explores what large language models (LLM) are, the use cases where they can be utilized, and how you can use prompt tuning to enhance LLM performance

3. Introduction to Responsible AI
This is an introductory-level microlearning course aimed at explaining what responsible AI is, why it's important, and how Google implements responsible AI in its products. It also introduces Google's 7 AI principles

4. Generative AI Fundamentals
Earn a skill badge by completing the Introduction to Generative AI, Introduction to LLM, and Introduction to Responsible AI courses.

5. Introduction to Image Generation
This course introduces diffusion models, a family of machine learning models that recently showed promise in the image generation space.
Diffusion models draw inspiration from physics, specifically thermodynamics.

6. Encoder-Decoder Architecture
Learn about the main components of the encoder-decoder architecture and how to train and serve these models.

7. Attention Mechanism
You will learn how attention works, and how it can be used to improve the performance of a variety of machine-learning tasks, including machine translation, text summarization, and question-answering.

8. Transformer Models and BERT Model
You learn about the main components of the Transformer architecture, such as the self-attention mechanism, and how it is used to build the BERT model.

9. Create Image Captioning Models
This course teaches you how to create an image captioning model by using deep learning. 
You learn about the different components of an image captioning model, and how to train and evaluate your model.

10. Introduction to Generative AI Studio
In this course, you learn what Generative AI Studio is, its features and options, and how to use it by walking through demos of the product. 
In the end, you will have a quiz to test your knowledge.",Digital Skills and Freelancing Mentor,2023-08-07T12:28:47Z,2023-09-06T11:45:19Z
373,AgentSims: An Open-Source Sandbox for Large Language Model Evaluation,buZX6XJiZtE,1009,1:49,AgentSims is an easy-to-use infrastructure for researchers from all disciplines to test the specific capacities they are interested in.,AgentSims,2023-08-07T11:57:08Z,2023-09-06T11:45:19Z
